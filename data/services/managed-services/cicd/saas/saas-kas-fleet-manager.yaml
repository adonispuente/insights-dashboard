---
$schema: /app-sre/saas-file-1.yml

labels:
  service: kas-fleet-manager

name: saas-kas-fleet-manager
description: 'SaaS tracking file for Kafka Service Fleet Manager'

app:
  $ref: /services/managed-services/app.yml

instance:
  $ref: /dependencies/ci-int/ci-int.yml

slack:
  workspace:
    $ref: /dependencies/slack/coreos.yml
  channel: managed-services-api

managedResourceTypes:
- Deployment
- Service
- ConfigMap

imagePatterns:
- quay.io/rhoas/kas-fleet-manager
- quay.io/centos/centos

authentication:
  image:
    path: managed-services/quay-org-accounts/rhoas/robots/rhoas-pull
    field: all

resourceTemplates:
- name: kas-fleet-manager
  url: https://gitlab.cee.redhat.com/service/kas-fleet-manager
  path: /templates/service-template.yml
  parameters:
    IMAGE_REGISTRY: quay.io
    IMAGE_REPOSITORY: rhoas/kas-fleet-manager
    JWKS_URL: https://sso.redhat.com/auth/realms/redhat-external/protocol/openid-connect/certs
    REPLICAS: 6
    CLUSTER_OPENSHIFT_VERSION: ""
    CLUSTER_COMPUTE_MACHINE_TYPE: m5.4xlarge
    # Enforce instance limit control
    ENABLE_INSTANCE_LIMIT_CONTROL: true
    # The default maximum number of instances that can be created by a user/organisation.
    # Takes effect if `ENABLE_INSTANCE_LIMIT_CONTROL` is set to true
    MAX_ALLOWED_INSTANCES: 1
    # Change this to false if you want to disable the deny list feature feature
    ENABLE_DENY_LIST: true
    # Change this to false to disable sentry
    ENABLE_SENTRY: true
    # Enable ManagedKafkaCR generation
    ENABLE_MANAGED_KAFKA_CR: true
    # Disable quota service integration for now
    ENABLE_QUOTA_SERVICE: false
    # Enable the external Kafka certificate for all Kafka clusters
    ENABLE_KAFKA_EXTERNAL_CERTIFICATE: true
    # Enable the dedicate Ingress on the data plane clusters which all Kafka Clusters will use
    ENABLE_DEDICATED_INGRESS: true
    #The public HTTP host URL of the service
    SERVICE_PUBLIC_HOST_URL: ${OCM_BASE_URL} 
    # Image tags for sub components
    KAFKA_ADMIN_SERVER_IMAGE: quay.io/sknot/kafka-admin-api:0.0.4
    # Log level
    GLOG_V: 5   
    # Which channel (directory) within the config repo the Observability Operator should consume from
    OBSERVABILITY_CONFIG_CHANNEL: resources   
    # This value is the lifespan a kafka will have with the lifespan flag enabled. In hours.
    KAFKA_LIFE_SPAN: 48
  targets:
  - namespace:
      $ref: /services/managed-services/namespaces/managed-services-stage.yml
    ref: master
    upstream: service-kas-fleet-manager-gl-build-master
    parameters:
      ENVIRONMENT: stage
      SENTRY_URL: sentry.stage.devshift.net
      SENTRY_PROJECT: 21
      MAS_SSO_BASE_URL: https://keycloak-mas-sso-stage.apps.app-sre-stage-0.k3s7.p1.openshiftapps.com
      MAS_SSO_REALM: rhoas
      OSD_IDP_MAS_SSO_REALM: rhoas-kafka-sre
      # Dex identity service url
      DEX_URL: http://dex-dex.apps.pbraun-observatorium.observability.rhmw.io
      # Dex identity service username
      DEX_USERNAME: admin@example.com
      # A URL to an Observatorium instance where observability metrics will sent to.
      OBSERVATORIUM_GATEWAY: https://observatorium-observatorium.apps.pbraun-observatorium.observability.rhmw.io
      # Observatorium tenant where observability metrics will sent to.
      OBSERVATORIUM_TENANT: test
      # A URL to repository containing external Kafka Observability configuration info for Obs. Operator to consume
      OBSERVABILITY_CONFIG_REPO: https://api.github.com/repos/bf2fc6cc711aee1a0c2a/observability-resources-mk/contents
      # MAXIMUM NUMBER OF ALLOWED KAFKAs
      KAFKA_CAPACITY_MAX_CAPACITY: 150
      # Changing this to true will delete all kafkas after their lifespan expired. The default is 48 hours.
      ENABLE_KAFKA_LIFE_SPAN: false
      MAS_SSO_ENABLE_AUTH: true
      # Enable using ths synchronizer module for kas-fleetshard-operator
      ENABLE_KAS_FLEETSHARD_OPERATOR_SYNC: true
      # Only allow those who are listed in `ALLOWED_SERVICE_ACCOUNTS` and `ALLOWED_USERS_PER_ORGANISATION` to access the service
      ALLOW_ANY_REGISTERED_USERS: false
      # A list of allowed users in yaml format irrespective of their organisation.
      ALLOWED_SERVICE_ACCOUNTS:
          # RHOSAK PM
        - username: rhn-gps-ddoyle
          max_allowed_instances: 2
        - username: kbabo1@redhat.com
          max_allowed_instances: 2

          # ODH: Demos and PoCs for Managed ODH and Managed Kafka integration
        - username: cchase@redhat.com
          max_allowed_instances: 1

          # Andrea Tarocchi: Testing Camel Kafka Connectors
        - username: atarocch@redhat.com
          max_allowed_instances: 1

          # Daniele Zonca: Business Automation as a Service
        - username: dzonca@redhat.com
          max_allowed_instances: 1

          # Clement Escoffier: Quarkus integration
        - username: cescoffi
          max_allowed_instances: 2

          # Matthias Wessendorf: KNative Eventing's Kafka components
        - username: mwessend@redhat.com
          max_allowed_instances: 1

          # Ruben Romero Montes: BAaaS
        - username: rhn-support-rromerom
          max_allowed_instances: 1

          # Fred Bricon: VS Code tools support
        - username: fbricon@redhat.com
          max_allowed_instances: 3

          # Nicola Ferraro: Camel K interop and integration
        - username: nicolaferraro
          max_allowed_instances: 1

          # Ben Hardesty: Testing and documentation
        - username: behardesty
          max_allowed_instances: 1

          # Luca Burgazzoli: Connector Service development
        - username: lburgazz@redhat.com
          max_allowed_instances: 1

          # Paul Mellor: CCS
        - username: ccs-amq-account
          max_allowed_instances: 1

          # Dhiraj Bokde: Managed Connector Service development
        - username: dbokde
          max_allowed_instances: 1

          # Evan Shortis: Summit demo
        - username: eshortis
          max_allowed_instances: 1

          # Luis Garcia Acosta: Connector Service development
        - username: lgarciaac
          max_allowed_instances: 1

          # Scott Creeley: project collaboration with OCTO and exploring the service and evaluating
        - username: screeley@redhat.com
          max_allowed_instances: 1

          # René Kerner: MGDSTRM-1043: Creating a demo/example of using Managed Kafka with Debezium on OpenShift with AMQ Streams
        - username: rk3rn3r
          max_allowed_instances: 1

          # Tim Sawicki: Production data ETL work for Red Hat Marketing Operations
        - username: tsawicki
          max_allowed_instances: 3

          # Christina Lin: Kicking the tires, gives feedback and see how it can work with current product (RHI)
        - username: clin@redhat.com
          max_allowed_instances: 1

          # Juan Hernández: Member of Service Delivery, needs access to help diagnose an issue
        - username: jhernand-rh
          max_allowed_instances: 1

          # Jaivardhan Kumar: Dev Console team, Kafka Sources usecases in KNative Eventing
        - username: jakumar
          max_allowed_instances: 1

          # Guy Margalit: OCTO, Managed Data Replication based on the Scribe project.
        - username: gmargali
          max_allowed_instances: 1

          # Riccardo Forina: FUSE for MK
        - username: rforina
          max_allowed_instances: 1

          # Martin Murphy: Training/practice/reproducer environment for CEE/support delivery
        - username: rhn-plm-mmurphy
          max_allowed_instances: 1

          # Kamesh Sampath: Managed and Developer Services Product Manager for APAC
        - username: ksampath@redhat.com
          max_allowed_instances: 1

          # Hugo Guerrero: TMM, demo's and stuff
        - username: hguerrer
          max_allowed_instances: 1

          # Clayton Coleman
        - username: ccoleman1@redhat.com
          max_allowed_instances: 3

          # Vikram Raj: OpenShift Developer Console
        - username: viraj-1
          max_allowed_instances: 1

          # Gabor Burges: I will be working on getting the MK service to work with the Insights platform (and Clowder) environments
        - username: gburges@redhat.com
          max_allowed_instances: 1

          # Lukas Berk: Helping support a summit demo and ensuring I can properly reproduce the serverless eventing setup with a kafka backed broker
        - username: lberk
          max_allowed_instances: 1

          # Ashique Ansari: Working with Debezium team and I need Kafka Cluster to use https://gitlab.cee.redhat.com/mk-ci-cd/application-services-ui as per the documentation https://docs.google.com/document/d/1MuHZU93X4PdtsI76VGiM8zmgbG-0sqV3F-LHZg0QNBE/
        - username: asansari@redhat.com
          max_allowed_instances: 1

          # Mark Drilling: debezium ui development
        - username: mdrillin1@redhat.com
          max_allowed_instances: 1

          # Jason Sherman: Product Experience/Support Readiness
        - username: rhn-support-jsherman
          max_allowed_instances: 1

          # Ben Turner: Insights Platform Messaging
        - username: rhn-support-bturner
          max_allowed_instances: 1

          # Indra Raj Shukla: I am working with Debezium team and I need this to test Control Plane UI
        - username: ishukla
          max_allowed_instances: 1

          # Kabir Khan: I am working on the Red Hat JBoss Enterprise Platform integration with RHOSAK
        - username: kkhan1@redhat.com
          max_allowed_instances: 1

          # Edward Brennan: Marketing operations development and troubleshooting
        - username: ebrennan@redhat.com
          max_allowed_instances: 1

          # Bernard Tison: TMM Cloud Services BU
        - username: btison
          max_allowed_instances: 1

          # Andrea Cosentino: For MCS and testing connector
        - username: acosenti
          max_allowed_instances: 1

          # Pete TNC
        - username: pmuir_tnc
          max_allowed_instances: 1

          # Joe O'Reilly
        - username: joreilly
          max_allowed_instances: 1

          # Scaling testing user
        - username: test_kafka_service
          max_allowed_instances: 1500

          # Burr Sutter
        - username: burrzinga
          max_allowed_instances: 2

      # A list of allowed users per organisation in yaml format.
      ALLOWED_USERS_PER_ORGANISATION:
          # The Workshop Test org
        - id: 14463039
          max_allowed_instances: 150
          allow_all: true
          allowed_users: []

          # The Control Plane team
        - id: 13640203
          max_allowed_instances: 1500 # increased for pre-Summit scale testing
          allow_all: true
          # Empty for now meaning all users allowed since "allow_all" is set to true.
          allowed_users: []

          # The App SRE team
        - id: 12147054
          max_allowed_instances: 5
          allow_all: true
          # Empty for now meaning all users allowed since "allow_all" is set to true.
          allowed_users: []

          # The Bin Packing team
        - id: 13639843
          max_allowed_instances: 3
          allow_all: false
          allowed_users:
            - username: kwall_mk-bin-packing
            - username: obabec_mk-bin-packing
            - username: dkornel_mk-bin-packing
            - username: mwagner_mk-bin-packing
            - username: sknot_mk-bin-packing
            - username: jstejska_mk-bin-packing
            - username: vbusch_mk-bin-packing
            - username: vkapalav_mk-bin-packing
            - username: grdryn_mk-bin-packing
            - username: jscholz_mk-bin-packing
            - username: stethoma_mk-bin-packing
            - username: trdoyle_mk-bin-packing
            - username: skaleta_mk-bin-packing
            - username: rareddy_mk-kafka
            - username: shawkins_mk-kafka
            - username: ppatiern_mk-kafka-instances

          # The Consoles & Developer Experience team
        - id: 13838614
          max_allowed_instances: 8
          allow_all: false
          allowed_users:
            - username: wtrocki_kafka_devexp
            - username: ephelan_kafka_devexp
            - username: pemuir_kafka_devexp
            - username: jgiardin_kafka_devexp
            - username: sanjekum_kafka_devexp
            - username: apratap_kafka_devexp
            - username: anujha_kafka_devexp
            - username: dbizzarr_kafka_devexp
            - username: rkubis_kafka_devexp
            - username: supittma_kafka_devexp
            - username: mmclaugh_kafka_devexp
            - username: eshortis_kafka_devexp
            - username: jciroli_kafka_devexp
            - username: crobson_kafka_devexp
            - username: tnolan_kafka_devexp
            - username: ldimaggi_kafka_devexp
            - username: cmolloy_kafka_devexp
            - username: aglass_kafka_devexp
            - username: jschuler_kafka_devexp
            - username: dffrench_kafka_devexp
            - username: jawright_kafka_devexp
            - username: dlabaj_kafka_devexp
            - username: dgutride_kafka_devexp
            - username: rpattnai_kafka_devexp
            - username: mmusil_kafka_devexp
            - username: sterobin_kafka_devexp
            - username: rpetrie_kafka_devexp
            - username: pantinor_kafka_devexp
            - username: sisharma_kafka_devexp
            - username: jbyrne_kafka_devexp
            - username: bmozaffa_kafka_devexp
            - username: srambach_kafka_devexp
            - username: oasaf_kafka_devexp
            - username: mdawson_kafka_devexp
            - username: dhawkins_kafka_devexp

          # Red Hat Managed Application Services
        - id: 13645369
          max_allowed_instances: 4
          allow_all: false
          allowed_users:
            - username: davmarti_kafka_sre
            - username: damurphy_kafka_sre
            - username: rshelly_kafka_sre
            - username: tdavidso_kafka_sre
            - username: stobin_rhmi
            - username: rarangan_rhmi
            - username: kkakarla_kafka_sre
            - username: mmikhail_kafka_sre
            - username: rlawton_kafka_sre
            - username: robrien_kafka_sre
            - username: agullon_kafka_sre

          # Red Hat Application Services TMMs
        - id: 14410788
          max_allowed_instances: 4
          allow_all: false
          allowed_users:
            - username: ddoyle_kafka_tmm
            - username: clin_kafka_tmm
            - username: hguerrer_kafka_tmm
            - username: kvarela_kafka_tmm
            - username: edeandrea_kafka_tmm
            - username: eshortis_kafka_tmm
            - username: btison_kafka_tmm
            - username: doh_kafka_tmm
            - username: sshaaf_kafka_tmm
            - username: sjayanti_kafka_tmm
            - username: rmarins_kafka_tmm

          # Insights team
        - id: 7770862
          max_allowed_instances: 2
          allow_all: false
          allowed_users:
            - username: klape-insights
          # MK Test
        - id: 14014161
          max_allowed_instances: 8
          allow_all: false
          allowed_users:
            - username: mk-test-user
            - username: mk-test-user-e2e-primary
            - username: mk-test-user-e2e-secondary

          # The Security team
        - id: 13785172
          allow_all: true
          max_allowed_instances: 1
          allowed_users: []

          # CS-SRE
        - id: 12961970
          allow_all: false
          max_allowed_instances: 3
          allowed_users:
            - username: mciccone-openshift
            - username: mfreer-openshift

          # RHN Support
        - id: 1979710
          allow_all: false
          max_allowed_instances: 3
          allowed_users:
            - username: rhn-support-kboone
            - username: rhn-support-aboucham
            - username: rhn-support-fvaleri

      # A list of usernames representing users who do not have access to the service
      DENIED_USERS: []

      SUPPORTED_CLOUD_PROVIDERS:
        - name: aws
          default: true
          regions:
            - name: us-east-1
              default: true

      #manual: use data plane config file, auto: use kas-fleet-shard
      DATAPLANE_CLUSTER_SCALING_TYPE: manual

      # cluster list if dataplane cluster scaling type is set to manual
      CLUSTER_LIST:
        - name: Stage Cluster
          cluster_id: 1ieq35mpf26sq2r246sbffuvg9s380sp
          cloud_provider: aws
          region: us-east-1
          multi_az: true
          schedulable: true
          kafka_instance_limit: 150

  - namespace:
      $ref: /services/managed-services/namespaces/managed-services-production.yml
    # This commit sha will need to replaced to reference the latest working commit.
    # Make sure that we've a docker image for this before it can be changed.
    # When change this, make sure to also change the `IMAGE_TAG` to reference the first seven characters of the sha1.
    # Commits can be found here https://gitlab.cee.redhat.com/service/kas-fleet-manager/-/commits/master
    # Inspect the recent merged MR from https://gitlab.cee.redhat.com/service/kas-fleet-manager/-/merge_requests?scope=all&utf8=%E2%9C%93&state=merged to get the latest commit that has a docker image built from it. 
    # e.g if we take https://gitlab.cee.redhat.com/service/kas-fleet-manager/-/merge_requests/356/commits, the commit with a docker image in it will be 
    # the very first commit i.e https://gitlab.cee.redhat.com/service/kas-fleet-manager/-/merge_requests/356/commits?commit_id=f0fd63740464c5fa4bda395d5d31f675eff049ac 
    # If in doubt, see with the control plane team.
    # We are exploring into using automating this.
    ref: 30f4c123c3c1ab06e72c15d7ce26ddaaa7be69e1 
    parameters:
      ENVIRONMENT: production
      # The image tag is the first seven characters of the #ref commit sha parameter. 
      # Verify in https://quay.io/repository/rhoas/kas-fleet-manager?tab=tags to see if the tag exists.
      IMAGE_TAG: 30f4c12
      SENTRY_URL: sentry.devshift.net
      SENTRY_PROJECT: 16
      MAS_SSO_BASE_URL: https://identity.api.openshift.com
      MAS_SSO_REALM: rhoas
      OSD_IDP_MAS_SSO_REALM: rhoas-kafka-sre
      # Dex identity service url
      DEX_URL: http://dex-dex.apps.pbraun-observatorium.observability.rhmw.io
      # Dex identity service username
      DEX_USERNAME: admin@example.com
      # A URL to an Observatorium instance where observability metrics will sent to.
      OBSERVATORIUM_GATEWAY: https://observatorium-observatorium.apps.pbraun-observatorium.observability.rhmw.io
      # Observatorium tenant where observability metrics will sent to.
      OBSERVATORIUM_TENANT: test
      # A URL to repository containing external Kafka Observability configuration info for Obs. Operator to consume
      OBSERVABILITY_CONFIG_REPO: https://api.github.com/repos/bf2fc6cc711aee1a0c2a/observability-resources-mk/contents
      # MAXIMUM NUMBER OF ALLOWED KAFKAs
      KAFKA_CAPACITY_MAX_CAPACITY: 1000
      # A list of usernames representing users who do not have access to the service
      DENIED_USERS: []
      # Setting to false for now, will need to update to true once we're ready to open this to external users
      ALLOW_ANY_REGISTERED_USERS: false
      # A list of allowed users in yaml format irrespective of their organisation.
      # If `ALLOW_ANY_REGISTERED_USERS` is set to true, the list will only be used to determine the `max_allowed_instances` each user can create.
      ALLOWED_SERVICE_ACCOUNTS: []
      # A list of allowed users per organisation in yaml format.
      # If `ALLOW_ANY_REGISTERED_USERS` is set to true, the list will only be used to determine the `max_allowed_instances` each organisation can create.
      ALLOWED_USERS_PER_ORGANISATION:
          # The Control Plane team
        - id: 13640203
          max_allowed_instances: 5
          allow_all: true
          # Empty for now meaning all users allowed since "allow_all" is set to true.
          allowed_users: []
      # A list of supported cloud providers and region    
      SUPPORTED_CLOUD_PROVIDERS:
        - name: aws
          default: true
          regions:
            - name: us-east-1
              default: true
      # Changing this to true will delete all kafkas after their lifespan expired. The default is 48 hours.
      ENABLE_KAFKA_LIFE_SPAN: true

      #manual: use data plane config file, auto: use kas-fleet-shard
      DATAPLANE_CLUSTER_SCALING_TYPE: manual

      # cluster list if dataplane cluster scaling type is set to manual
      CLUSTER_LIST: []
