---
$schema: /app-sre/saas-file-2.yml

labels:
  service: kas-fleet-manager

name: saas-kas-fleet-manager
description: 'SaaS tracking file for Kafka Service Fleet Manager'

app:
  $ref: /services/managed-services/app.yml

pipelinesProvider:
  $ref: /services/managed-services/pipelines/tekton.kas-fleet-manager-pipelines.appsrep05ue1.yaml

deployResources:
  requests:
    cpu: 300m
    memory: 600Mi
  limits:
    cpu: 300m
    memory: 600Mi

slack:
  workspace:
    $ref: /dependencies/slack/redhat-internal.yml
  channel: mk-kas-fleet-manager

managedResourceTypes:
- Deployment
- Service
- ConfigMap
- Frontend

imagePatterns:
- quay.io/rhoas/kas-fleet-manager
- quay.io/centos/centos
- quay.io/rhoas/envoyproxy
- quay.io/observatorium/token-refresher
- quay.io/rhoas/mk-token-refresher
- quay.io/rhoas/application-services-ui-frontend-container
- quay.io/rhoas/rhosak-ui

authentication:
  image:
    path: managed-services/quay-org-accounts/rhoas/robots/rhoas-pull
    field: all

resourceTemplates:
- name: observatorium-token-refresher
  url: https://gitlab.cee.redhat.com/service/kas-fleet-manager
  path: /templates/observatorium-token-refresher.yml
  targets:
  - namespace:
      $ref: /services/managed-services/namespaces/managed-services-stage.yml
    ref: 372dd00f51977e4e2a16e4bfd036d989bfb74214
    parameters:
      ISSUER_URL: ${SSO_BASE_URL}
      OBSERVATORIUM_URL: https://observatorium-mst.api.stage.openshift.com/api/metrics/v1/managedkafka
      OBSERVATORIUM_TOKEN_REFRESHER_IMAGE: quay.io/rhoas/mk-token-refresher
      OBSERVATORIUM_TOKEN_REFRESHER_IMAGE_TAG: 0b54d2e
      OBSERVATORIUM_TOKEN_REFRESHER_REPLICAS: 3
  - namespace:
      $ref: /services/managed-services/namespaces/managed-services-production.yml
    # Please note the following before updating this 'ref' property:
    # - The commit sha specified here should always be the same commit sha specified for the kas-fleet-manager ref in production.
    #   e.g. If the kas-fleet-manager version was updated in production, the value of this ref property must also be updated to match the new commit hash.
    # - Commits can be found here: https://gitlab.cee.redhat.com/service/kas-fleet-manager/-/commits/main
    # If in doubt, please check with the MK Control Plane team.
    # We are exploring how to automate this in the future.
    ref: ca691caae0f48ffb9c7eb31ecc324ebebaede0a9
    parameters:
      ISSUER_URL: ${SSO_BASE_URL}
      OBSERVATORIUM_URL: https://observatorium-mst.api.openshift.com/api/metrics/v1/managedkafka
      OBSERVATORIUM_TOKEN_REFRESHER_IMAGE: quay.io/rhoas/mk-token-refresher
      OBSERVATORIUM_TOKEN_REFRESHER_IMAGE_TAG: 0b54d2e
      OBSERVATORIUM_TOKEN_REFRESHER_REPLICAS: 3
- name: kas-fleet-manager
  url: https://gitlab.cee.redhat.com/service/kas-fleet-manager
  path: /templates/service-template.yml
  parameters:
    # Global parameter - Affects Production and Stage
    IMAGE_REGISTRY: quay.io
    # Global parameter - Affects Production and Stage
    IMAGE_REPOSITORY: rhoas/kas-fleet-manager
    # Global parameter - Affects Production and Stage
    # SSO_BASE_URL is defined at the environment parameters level
    JWKS_URL: ${SSO_BASE_URL}/protocol/openid-connect/certs
    # Global parameter - Affects Production and Stage
    # Change this to false if you want the users to be able to use the service without accepting any terms
    ENABLE_TERMS_ACCEPTANCE: true
    # Global parameter - Affects Production and Stage
    # Change this to false if you want to disable the deny list feature feature
    ENABLE_DENY_LIST: true
    # Global parameter - Affects Production and Stage
    # Change this to false to disable sentry
    ENABLE_SENTRY: true
    # Global parameter - Affects Production and Stage
    # Enable the external Kafka certificate for all Kafka clusters
    ENABLE_KAFKA_EXTERNAL_CERTIFICATE: true
    # Global parameter - Affects Production and Stage
    # Enable the registration of Kafka instance domain names, determined by value of KAFKA_DOMAIN_NAME
    ENABLE_KAFKA_CNAME_REGISTRATION: true
    # Global parameter - Affects Production and Stage
    #The public HTTP host URL of the service
    SERVICE_PUBLIC_HOST_URL: ${OCM_BASE_URL}
    # Global parameter - Affects Production and Stage
    # A URL to repository containing external Kafka Observability configuration info for Obs. Operator to consume
    OBSERVABILITY_CONFIG_REPO: https://api.github.com/repos/bf2fc6cc711aee1a0c2a/observability-resources-mk/contents
    # Global parameter - Affects Production and Stage
    # Which channel (directory) within the config repo the Observability Operator should consume from
    OBSERVABILITY_CONFIG_CHANNEL: resources
    # The tls certificate management must staple. Adds the must staple TLS extension to the certificate signing request.
    KAFKA_TLS_CERTIFICATE_MANAGEMENT_MUST_STAPLE: false
    # The tls certificate management strategy. Possible options are manual and automaitic.
    KAFKA_TLS_CERTIFICATE_MANAGEMENT_STRATEGY: manual
    # The tls certificate management storage type. Certificates are stored in secure-storage that uses AWS Secret Manager.
    KAFKA_TLS_CERTIFICATE_MANAGEMENT_STORAGE_TYPE: secure-storage
    # The tls certificate management email.
    KAFKA_TLS_CERTIFICATE_MANAGEMENT_EMAIL: mk-service-api@redhat.com
    # The tls certificate management renewal window ratio i.e how much of a certificate's lifetime becomes the renewal window.
    KAFKA_TLS_CERTIFICATE_MANAGEMENT_RENEWAL_WINDOW_RATIO: 0.3333333333

  targets:
  - namespace:
      $ref: /services/managed-services/namespaces/managed-services-stage.yml
    ref: 372dd00f51977e4e2a16e4bfd036d989bfb74214
    parameters:
      DB_SSLMODE: verify-full
      ENVIRONMENT: stage
      REPLICAS: 6
      SENTRY_URL: glitchtip.devshift.net
      SENTRY_PROJECT: 23
      MAS_SSO_BASE_URL: https://identity.api.stage.openshift.com
      MAS_SSO_REALM: rhoas
      OSD_IDP_MAS_SSO_REALM: rhoas-kafka-sre
      OCM_URL: https://api.openshift.com
      # The browser url for the Stage Streams for Apache Kafka console
      BROWSER_URL: ${CONSOLE_BASE_URL}/application-services/streams/kafkas/
      # Log level
      GLOG_V: 10
      # Image to be used by Envoy sidecar container
      ENVOY_IMAGE: quay.io/rhoas/envoyproxy:v1.20.2
      # AMS
      AMS_URL: ${OCM_BASE_URL}
      # Use the ams based quota management service
      QUOTA_TYPE: ams
      # Dex identity service url
      DEX_URL: http://dex-dex.apps.pbraun-observatorium.observability.rhmw.io
      # Dex identity service username
      DEX_USERNAME: admin@example.com
      # A URL to an Observatorium instance where observability metrics will sent to.
      OBSERVATORIUM_GATEWAY: https://observatorium-observatorium.apps.pbraun-observatorium.observability.rhmw.io
      # Observatorium tenant where observability metrics will sent to.
      OBSERVATORIUM_TENANT: test
      # The value of this auth type ( "dex" or "redhat" ) will determine the auth type ( Dex or Red Hat SSO) implemented for the observability stack
      OBSERVATORIUM_AUTH_TYPE: redhat
      # Token Refresher URL
      OBSERVATORIUM_TOKEN_REFRESHER_URL: http://token-refresher.managed-services-stage.svc.cluster.local
      # Release tag within Config Repo to use for pulling index information
      OBSERVABILITY_CONFIG_TAG: v1.49.1
      # Observatorium Red Hat SSO tenant for observability stack
      OBSERVATORIUM_RHSSO_TENANT: managedkafka
      # Red Hat SSO Observability gateway
      OBSERVATORIUM_RHSSO_GATEWAY: https://observatorium-mst.api.stage.openshift.com
      # Red Hat SSO Observability realm
      OBSERVATORIUM_RHSSO_REALM: redhat-external
      # Red Hat SSO Observability auth server url
      OBSERVATORIUM_RHSSO_AUTH_SERVER_URL: https://sso.redhat.com/auth
      # Changing this to true will delete all kafkas after their lifespan expired
      ENABLE_KAFKA_LIFE_SPAN: true
      MAS_SSO_ENABLE_AUTH: true
      # Block creation of Kafka Clusters
      ENABLE_ACCESS_LIST: false
      # Change this to enable/disable forwarding logs to cloudwatch
      OBSERVABILITY_ENABLE_CLOUDWATCHLOGGING: true
      # Orgs allowed to created Kafka
      ACCEPTED_ORGANISATIONS:
        - "13640203"
        - "13838614"
        - "14221005"
        - "16144209"
        - "16141777"
        - "13888347"
        - "16145549"
        - "15230873"
      # Max allowed service accounts created by an organization
      MAX_ALLOWED_SERVICE_ACCOUNTS: 50
      # Max limit for the fetching the clients from mas-sso
      MAX_LIMIT_FOR_SSO_GET_CLIENTS: 100
      # Set domain name for Kafka instances
      KAFKA_DOMAIN_NAME: "bf2.kafka-stage.rhcloud.com"
      REDHAT_SSO_BASE_URL: https://sso.redhat.com
      SSO_PROVIDER_TYPE: redhat_sso
      STRIMZI_OPERATOR_ADDON_ID: managed-kafka-qe
      KAS_FLEETSHARD_ADDON_ID: kas-fleetshard-operator-qe
      # The Cluster Logging Operator ID. An empty string indicates that the operator should not be installed.
      CLUSTER_LOGGING_OPERATOR_ADDON_ID: ""
      # Index image used for Observability Operator
      OBSERVABILITY_OPERATOR_INDEX_IMAGE: "quay.io/rhoas/observability-operator-index:v4.1.1"
      # Starting CSV used for Observability Operator
      OBSERVABILITY_OPERATOR_STARTING_CSV: "observability-operator.v4.1.1"
      # As a user, one can only 1 developer instance if they do not have quota to create standard instances
      MAX_ALLOWED_DEVELOPER_INSTANCES: 1
      # A list of usernames representing users who do not have access to the service
      DENIED_USERS: []
      # A list of users with read-only permissions for data plane clusters
      READ_ONLY_USERS:
        - "cgorman"   # Managed ACS developer
        - "ebenshet"  # Managed ACS developer
        - "jrodrig"   # Managed ACS developer
        - "sbaumer"   # Managed ACS developer
        - "schaudhr"  # Managed ACS developer
        - "shesselm"  # Managed ACS developer
        - "vwilson"   # Managed ACS developer
     # A list of kafka-sre users with cluster-admin permissions for data plane clusters
      KAFKA_SRE_USERS:
        - "agullon"
        - "davmarti"
        - "rlawton"
        - "robrien"
        - "rshelly"
        - "stobin"
        - "tdavidso"
        - "tdalton"
        - "dffrench"
        - "jbriones"
        - "mziccard"
        - "akoserwa"
        - "ppaszki"
        - "pbraun"
        - "msoriano"
        - "mchitimb"
        - "npecka"
        - "ppatiern"
        - "shawkins"
        - "kwall"
        - "gryan"
        - "fvila"
        - "xiwu"
        - "sbarker"
        - "rareddy"
        - "medgar"
        - "tcooper"
        - "mfreer"
        - "crarobin"
        - "pcremin"
        - "hlipsig"
        - "sclarkso"
        - "jsarnovs"
        - "vbommana"
        - "ves"
        - "cabeywar"
        - "jcueto"
        - "swoodman"
        - "srbiswas"
        - "vbusch"
        - "lukchen"
        - "kstanley"
        - "ebernard"
        - "aabdelre"
        - "ihutchin"
        - "hzrncik"
        - "robeyoun"
        - "raryan"
        - "vmanley"
        - "gselenge"

      # parameters for SUPPORTED_INSTANCE_TYPES
      SUPPORTED_INSTANCE_TYPES:
      - id: developer
        display_name: "Trial"
        supported_billing_models:
          - id: standard
            ams_resource: rhosak
            ams_product: RHOSAKTrial
            ams_billing_models:
              - standard
        sizes:
          - id: x1
            display_name: "1"
            ingressThroughputPerSec: "1Mi"
            egressThroughputPerSec: "1Mi"
            totalMaxConnections: 100
            maxDataRetentionSize: "10Gi"
            maxPartitions: 100
            maxDataRetentionPeriod: "P14D"
            maxConnectionAttemptsPerSec: 50
            maxMessageSize: "1Mi"
            minInSyncReplicas: 1
            replicationFactor: 1
            quotaConsumed: 1
            quotaType: "RHOSAKTrial"
            capacityConsumed: 1
            supportedAZModes:
            - single
            lifespanSeconds: 7200
            maturityStatus: stable
      - id: standard
        display_name: "Standard"
        supported_billing_models:
          - id: standard
            grace_period_days: 4
            ams_resource: rhosak
            ams_product: RHOSAK
            ams_billing_models:
              - standard
          - id: marketplace
            grace_period_days: 4
            ams_resource: rhosak
            ams_product: RHOSAK
            ams_billing_models:
              - marketplace # legacy. Remove when we don't send it anymore
              - marketplace-rhm
              - marketplace-aws
          - id: eval
            grace_period_days: 4
            ams_resource: rhosak
            ams_product: RHOSAKEval
            ams_billing_models:
              - standard
          - id: enterprise
            grace_period_days: 4
            ams_resource: rhosak
            ams_product: RHOSAKCC
            ams_billing_models:
              - standard
        sizes:
          - id: x1
            display_name: "1"
            ingressThroughputPerSec: "50Mi"
            egressThroughputPerSec: "100Mi"
            totalMaxConnections: 9000
            maxDataRetentionSize: "1000Gi"
            maxPartitions: 1500
            maxDataRetentionPeriod: "P14D"
            maxConnectionAttemptsPerSec: 100
            maxMessageSize: "1Mi"
            minInSyncReplicas: 2
            replicationFactor: 3
            quotaConsumed: 1
            quotaType: "RHOSAK"
            capacityConsumed: 1
            supportedAZModes:
            - multi
            maturityStatus: stable
          - id: x2
            display_name: "2"
            ingressThroughputPerSec: "100Mi"
            egressThroughputPerSec: "200Mi"
            totalMaxConnections: 18000
            maxDataRetentionSize: "2000Gi"
            maxPartitions: 3000
            maxDataRetentionPeriod: "P14D"
            maxConnectionAttemptsPerSec: 200
            maxMessageSize: "1Mi"
            minInSyncReplicas: 2
            replicationFactor: 3
            quotaConsumed: 2
            quotaType: "RHOSAK"
            capacityConsumed: 2
            supportedAZModes:
            - multi
            maturityStatus: preview

      SUPPORTED_CLOUD_PROVIDERS:
        - name: aws
          default: true
          regions:
            - name: us-east-1
              default: true
              supported_instance_type:
                standard:
                  limit: 7
                developer:
                  limit: 30
        - name: gcp
          default: false
          regions:
            - name: us-east1
              default: true
              supported_instance_type:
                standard:
                  limit: 7
                developer:
                  limit: 30


      #manual: use data plane config file, auto: use kas-fleet-shard
      DATAPLANE_CLUSTER_SCALING_TYPE: auto
      DYNAMIC_SCALING_CONFIG:
        new_data_plane_openshift_version: openshift-v4.10.15
        enable_dynamic_data_plane_scale_up: false # temporarily disabled until https://issues.redhat.com/browse/MGDSTRM-10047 is fixed
        enable_dynamic_data_plane_scale_down: false # temporarily disabled until https://issues.redhat.com/browse/MGDSTRM-10047 is fixed
        compute_machine_per_cloud_provider:
          aws:
            cluster_wide_workload:
              compute_machine_type:  m5.2xlarge
              compute_node_autoscaling:
                min_compute_nodes: 3
                max_compute_nodes: 18
            kafka_workload_per_instance_type:
              standard:
                compute_machine_type: r5.xlarge
                compute_node_autoscaling:
                  min_compute_nodes: 3
                  max_compute_nodes: 21
              developer:
                compute_machine_type: m5.2xlarge
                compute_node_autoscaling:
                  min_compute_nodes: 3
                  max_compute_nodes: 3
          gcp:
            cluster_wide_workload:
              compute_machine_type: custom-8-32768
              compute_node_autoscaling:
                min_compute_nodes: 3
                max_compute_nodes: 18
            kafka_workload_per_instance_type:
              standard:
                compute_machine_type: custom-4-32768-ext
                compute_node_autoscaling:
                  min_compute_nodes: 3
                  max_compute_nodes: 21
              developer:
                compute_machine_type: custom-8-32768
                compute_node_autoscaling:
                  min_compute_nodes: 3
                  max_compute_nodes: 3

      # cluster list if dataplane cluster scaling type is set to manual
      CLUSTER_LIST:
        - name: Stage Cluster (In GCP Prod)
          cluster_id: 20j0bm8rbqedso2qbvn5vvguthulsoci
          cloud_provider: gcp
          region: us-east1
          multi_az: true
          schedulable: true
          kafka_instance_limit: 37
          supported_instance_type: standard,developer
        - name: Stage Cluster (In OSD Prod)
          cluster_id: 1lfl3g1vdea86ghh26vkmbqjkain900q
          cloud_provider: aws
          region: us-east-1
          multi_az: true
          schedulable: true
          kafka_instance_limit: 37
          supported_instance_type: standard,developer


      SSO_SPECIAL_MANAGEMENT_ORG_ID: 13640203

      # Worker node prewarming configuration
      NODE_PREWARMING_CONFIG:
        standard: # the instance type. It must exist in SUPPORTED_INSTANCE_TYPES
          # The number of reserved kafka instances of the size specified in "base_streaming_unit_size".
          # 1 guarantee that we'll always have hot capacity (3 worker nodes) prewarmed for 1 standard instance of size x1.
          num_reserved_instances: 1
          base_streaming_unit_size: x1
        developer: # The instance type. It must exist in SUPPORTED_INSTANCE_TYPES.
          # The number of reserved kafka instances of the size specified in "base_streaming_unit_size".
          # 1 guarantee that we'll always hot capacity for one developer instance which should be enough for Stage cluster usage.
          num_reserved_instances: 1
          base_streaming_unit_size: x1

      # admin endpoins API configuration
      ADMIN_API_SSO_BASE_URL: https://auth.redhat.com
      ADMIN_API_SSO_ENDPOINT_URI: /auth/realms/EmployeeIDP
      ADMIN_API_SSO_REALM: EmployeeIDP
      ADMIN_AUTHZ_CONFIG:
        - method: GET
          roles:
            - kas-fleet-manager-admin-full-stage
            - kas-fleet-manager-admin-read-stage
            - kas-fleet-manager-admin-write-stage
        - method: POST # needed for the Kafka certification endpoint 
          roles:
            - kas-fleet-manager-admin-full-stage
        - method: PATCH
          roles:
            - kas-fleet-manager-admin-full-stage
            - kas-fleet-manager-admin-write-stage
        - method: DELETE
          roles:
            - kas-fleet-manager-admin-full-stage

  - namespace:
      $ref: /services/managed-services/namespaces/managed-services-production.yml
    # This commit sha will need to replaced to reference the latest working commit.
    # Make sure that we've a docker image for this before it can be changed.
    # Commits can be found here https://gitlab.cee.redhat.com/service/kas-fleet-manager/-/commits/main
    # Inspect the recent merged MR from https://gitlab.cee.redhat.com/service/kas-fleet-manager/-/merge_requests?scope=all&utf8=%E2%9C%93&state=merged to get the latest commit that has a docker image built from it.
    # e.g if we take https://gitlab.cee.redhat.com/service/kas-fleet-manager/-/merge_requests/356/commits, the commit with a docker image in it will be
    # the very first commit i.e https://gitlab.cee.redhat.com/service/kas-fleet-manager/-/merge_requests/356/commits?commit_id=f0fd63740464c5fa4bda395d5d31f675eff049ac
    # If in doubt, see with the control plane team.
    # We are exploring into using automating this.
    ref: ca691caae0f48ffb9c7eb31ecc324ebebaede0a9
    parameters:
      DB_SSLMODE: verify-full
      ENVIRONMENT: production
      QUOTA_TYPE: ams
      STRIMZI_OPERATOR_ADDON_ID: managed-kafka
      KAS_FLEETSHARD_ADDON_ID: kas-fleetshard-operator
      SENTRY_URL: glitchtip.devshift.net
      SENTRY_PROJECT: 27
      MAS_SSO_BASE_URL: https://identity.api.openshift.com
      MAS_SSO_REALM: rhoas
      OSD_IDP_MAS_SSO_REALM: rhoas-kafka-sre
      REDHAT_SSO_BASE_URL: https://sso.redhat.com
      SSO_PROVIDER_TYPE: redhat_sso
      # Log level
      GLOG_V: 5
      # Image to be used by Envoy sidecar container
      ENVOY_IMAGE: quay.io/rhoas/envoyproxy:v1.20.2
      # The Cluster Logging Operator ID. An empty string indicates that the operator should not be installed.
      CLUSTER_LOGGING_OPERATOR_ADDON_ID: ""
      OCM_URL: ${OCM_BASE_URL}
      AMS_URL: ${OCM_BASE_URL}
      # The browser url for the Streams for Apache Kafka console
      BROWSER_URL: ${CONSOLE_BASE_URL}/application-services/streams/kafkas/
      # Max allowed service accounts created by an organization
      MAX_ALLOWED_SERVICE_ACCOUNTS: 50
      # As a user, one can only 1 developer instance if they do not have quota to create standard instances
      MAX_ALLOWED_DEVELOPER_INSTANCES: 1
       # Max limit for the fetching the clients from mas-sso
      MAX_LIMIT_FOR_SSO_GET_CLIENTS: 100
      REPLICAS: 6
      # Dex identity service url
      DEX_URL: https://dex-dex.apps.mk-observe.trii.p1.openshiftapps.com
      # Dex identity service username
      DEX_USERNAME: admin@example.com
      # A URL to an Observatorium instance where observability metrics will sent to.
      OBSERVATORIUM_GATEWAY: https://observatorium-observatorium.apps.mk-observe.trii.p1.openshiftapps.com
      # Observatorium tenant where observability metrics will sent to.
      OBSERVATORIUM_TENANT: kasdataplane
      # The value of this auth type ( "dex" or "redhat" ) will determine the auth type ( Dex or Red Hat SSO) implemented for the observability
      OBSERVATORIUM_AUTH_TYPE: redhat
      # Token Refresher URL
      OBSERVATORIUM_TOKEN_REFRESHER_URL: http://token-refresher.managed-services-production.svc.cluster.local
      # Observatorium Red Hat SSO tenant for observability stack
      OBSERVATORIUM_RHSSO_TENANT: managedkafka
      # Red Hat SSO Observability gateway
      OBSERVATORIUM_RHSSO_GATEWAY: https://observatorium-mst.api.openshift.com
      # Red Hat SSO Observability realm
      OBSERVATORIUM_RHSSO_REALM: redhat-external
      # Red Hat SSO Observability auth server url
      OBSERVATORIUM_RHSSO_AUTH_SERVER_URL: https://sso.redhat.com/auth
      # Release tag within Config Repo to use for pulling index information
      OBSERVABILITY_CONFIG_TAG: v1.49.1
      # Index image used for Observability Operator
      OBSERVABILITY_OPERATOR_INDEX_IMAGE: "quay.io/rhoas/observability-operator-index:v4.1.1"
      # Starting CSV used for Observability Operator
      OBSERVABILITY_OPERATOR_STARTING_CSV: "observability-operator.v4.1.1"
      # A list of usernames representing users who do not have access to the service
      DENIED_USERS: []
      # A list of users with read-only permissions for data plane clusters
      READ_ONLY_USERS:
        - "dffrench"
        - "dimaggio"
        - "dingham"
        - "ebernard"
        - "gryan"
        - "jmadigan"
        - "jmernin"
        - "kwall"
        - "mchitimb"
        - "medgar"
        - "msoriano"
        - "pbraun"
        - "pemuir"
        - "ppaszki"
        - "ppatiern"
        - "rareddy"
        - "rgodfrey"
        - "shawkins"
        - "swoodman"
        - "tcooper"
        - "xiwu"
        - "sbarker"
        - "srbiswas"
        - "vbusch"
        - "lukchen"
        - "kstanley"
        - "aabdelre"
        - "agullon"
        - "rlawton"
        - "robrien"
        - "stobin"
        - "tdavidso"
        - "fvila"
        - "tdalton"
        - "robeyoun"
        - "raryan"
        - "gselenge"
      # CEE Engineers
        - "aboucham"
        - "agagliar"
        - "asouza"
        - "cpandey"
        - "dhawkins"
        - "fvaleri"
        - "hnaram"
        - "jsherman"
        - "kboone"
        - "kkakarla"
        - "mmurphy"
        - "qluo"
        - "shiggs"
        - "toross"
      # A list of kafka-sre users with cluster-admin permissions for data plane clusters
      KAFKA_SRE_USERS:
        - "rshelly"
        - "npecka"
        - "mfreer"
        - "crarobin"
        - "pcremin"
        - "deepshar"
        - "hlipsig"
        - "sclarkso"
        - "jsarnovs"

      # parameters for SUPPORTED_INSTANCE_TYPES
      SUPPORTED_INSTANCE_TYPES:
      - id: developer
        display_name: "Trial"
        supported_billing_models:
          - id: standard
            ams_resource: rhosak
            ams_product: RHOSAKTrial
            ams_billing_models:
              - standard
        sizes:
          - id: x1
            display_name: "1"
            ingressThroughputPerSec: "1Mi"
            egressThroughputPerSec: "1Mi"
            totalMaxConnections: 100
            maxDataRetentionSize: "10Gi"
            maxPartitions: 100
            maxDataRetentionPeriod: "P14D"
            maxConnectionAttemptsPerSec: 50
            maxMessageSize: "1Mi"
            minInSyncReplicas: 1
            replicationFactor: 1
            quotaConsumed: 1
            quotaType: "RHOSAKTrial"
            capacityConsumed: 1
            supportedAZModes:
              - single
            lifespanSeconds: 172800
            maturityStatus: stable
      - id: standard
        display_name: "Standard"
        supported_billing_models:
          - id: standard
            grace_period_days: 30
            ams_resource: rhosak
            ams_product: RHOSAK
            ams_billing_models:
              - standard
          - id: marketplace
            grace_period_days: 30
            ams_resource: rhosak
            ams_product: RHOSAK
            ams_billing_models:
              - marketplace # legacy. Remove when we don't send it anymore
              - marketplace-rhm
              - marketplace-aws
          - id: eval
            grace_period_days: 4
            ams_resource: rhosak
            ams_product: RHOSAKEval
            ams_billing_models:
              - standard
          - id: enterprise
            grace_period_days: 30
            ams_resource: rhosak
            ams_product: RHOSAKCC
            ams_billing_models:
              - standard
        sizes:
          - id: x1
            display_name: "1"
            ingressThroughputPerSec: "50Mi"
            egressThroughputPerSec: "100Mi"
            totalMaxConnections: 9000
            maxDataRetentionSize: "1000Gi"
            maxPartitions: 1500
            maxDataRetentionPeriod: "P14D"
            maxConnectionAttemptsPerSec: 100
            maxMessageSize: "1Mi"
            minInSyncReplicas: 2
            replicationFactor: 3
            quotaConsumed: 1
            quotaType: "RHOSAK"
            capacityConsumed: 1
            supportedAZModes:
              - multi
            maturityStatus: stable
          - id: x2
            display_name: "2"
            ingressThroughputPerSec: "100Mi"
            egressThroughputPerSec: "200Mi"
            totalMaxConnections: 18000
            maxDataRetentionSize: "2000Gi"
            maxPartitions: 3000
            maxDataRetentionPeriod: "P14D"
            maxConnectionAttemptsPerSec: 200
            maxMessageSize: "1Mi"
            minInSyncReplicas: 2
            replicationFactor: 3
            quotaConsumed: 2
            quotaType: "RHOSAK"
            capacityConsumed: 2
            supportedAZModes:
              - multi
            maturityStatus: preview

      # Set domain name for Kafka instances
      KAFKA_DOMAIN_NAME: "bf2.kafka.rhcloud.com"

      # A list of supported cloud providers and region
      SUPPORTED_CLOUD_PROVIDERS:
        - name: aws
          default: true
          regions:
            - name: us-east-1
              default: true
              supported_instance_type:
                standard: {}
                developer:
                  limit: 100
            - name: eu-west-1
              default: false
              supported_instance_type:
                standard: {}
                developer:
                  limit: 100
        - name: gcp
          default: false
          regions:
            - name: us-east1
              default: true
              supported_instance_type:
                developer:
                  limit: 100

      # admin endpoins API configuration
      ADMIN_API_SSO_BASE_URL: https://auth.redhat.com
      ADMIN_API_SSO_ENDPOINT_URI: /auth/realms/EmployeeIDP
      ADMIN_API_SSO_REALM: EmployeeIDP
      ADMIN_AUTHZ_CONFIG:
        - method: GET
          roles:
            - kas-fleet-manager-admin-full-prod
            - kas-fleet-manager-admin-read-prod
            - kas-fleet-manager-admin-write-prod
        - method: PATCH
          roles:
            - kas-fleet-manager-admin-full-prod
            - kas-fleet-manager-admin-write-prod
        - method: POST # needed for the Kafka certification endpoint 
          roles:
            - kas-fleet-manager-admin-full-prod
        - method: DELETE
          roles:
            - kas-fleet-manager-admin-full-prod

      # Changing this to true will delete all kafkas after their lifespan expired.
      ENABLE_KAFKA_LIFE_SPAN: true

      #"auto": use kas-fleet-shard capacity reporting and the DYNAMIC_SCALING_CONFIG parameter.
      #"manual": use data plane config file via the CLUSTER_LIST parameter.
      DATAPLANE_CLUSTER_SCALING_TYPE: auto

      # dynamic scaling configuration is used only when DATAPLANE_CLUSTER_SCALING_TYPE is set to "auto".
      DYNAMIC_SCALING_CONFIG:
        new_data_plane_openshift_version: openshift-v4.10.15
        enable_dynamic_data_plane_scale_up: true
        enable_dynamic_data_plane_scale_down: true
        compute_machine_per_cloud_provider:
          aws:
            cluster_wide_workload:
              compute_machine_type:  m5.2xlarge
              compute_node_autoscaling:
                min_compute_nodes: 3
                max_compute_nodes: 18
            kafka_workload_per_instance_type:
              standard:
                compute_machine_type: r5.xlarge
                compute_node_autoscaling:
                  min_compute_nodes: 3
                  max_compute_nodes: 150
              developer:
                compute_machine_type: m5.2xlarge
                compute_node_autoscaling:
                  min_compute_nodes: 1
                  max_compute_nodes: 150
          gcp:
            cluster_wide_workload:
              compute_machine_type: custom-8-32768
              compute_node_autoscaling:
                min_compute_nodes: 3
                max_compute_nodes: 18
            kafka_workload_per_instance_type:
              standard:
                compute_machine_type: custom-4-32768-ext
                compute_node_autoscaling:
                  min_compute_nodes: 3
                  max_compute_nodes: 150
              developer:
                compute_machine_type: custom-8-32768
                compute_node_autoscaling:
                  min_compute_nodes: 1
                  max_compute_nodes: 150

      # cluster list if dataplane cluster scaling type is set to manual
      CLUSTER_LIST:
        - name: mk-0419-204008
          cluster_id: 1k5ot6e86c6itcqqsrs019bngqc7cjin
          cloud_provider: aws
          region: us-east-1
          multi_az: true
          schedulable: true # change this to false if you do not want the cluster to be schedulable
          kafka_instance_limit: 38 # change this to match any value of configuration
          supported_instance_type: standard
        - name: mk-1006-115633
          cluster_id: 1nlj5j786fsg44srlj7f2kep5htakcp7
          cloud_provider: aws
          region: eu-west-1
          multi_az: true
          schedulable: true # change this to false if you do not want the cluster to be schedulable
          kafka_instance_limit: 6 # change this to match any value of configuration
          supported_instance_type: standard
        - name: mk-0503-013202
          cluster_id: 1rv3g4iu2m4jqsh8agh5lphl9cgqbb0p
          cloud_provider: aws
          region: us-east-1
          multi_az: false
          schedulable: true # change this to false if you do not want the cluster to be schedulable
          kafka_instance_limit: 100 # change this to match any value of configuration
          supported_instance_type: developer
        - name: mk-0727-163232
          cluster_id: 1tngp49ofbg8h7l26d8b6bhqbanv0l4f
          cloud_provider: aws
          region: eu-west-1
          multi_az: false
          schedulable: true # change this to false if you do not want the cluster to be schedulable
          kafka_instance_limit: 100 # change this to match any value of configuration
          supported_instance_type: developer

      SSO_SPECIAL_MANAGEMENT_ORG_ID: 14410147

      # Skip list for Org IDs  for whom "MAX_ALLOWED_SERVICE_ACCOUNTS" limits dont apply
      SERVICE_ACCOUNT_LIMIT_CHECK_SKIP_ORG_ID_LIST:
        - "1979710"
        - "6340056"
        - "11009103"
      # Block creation of Kafka Clusters
      # Blocking set to - "false" , service is open for wider audience
      ENABLE_ACCESS_LIST: false
      # Change this to enable/disable forwarding logs to cloudwatch
      OBSERVABILITY_ENABLE_CLOUDWATCHLOGGING: true
      # Orgs allowed to created Kafka
      # Not taken into account when "ENABLE_ACCESS_LIST" is set to "false"
      # An empty list here and "ENABLE_ACCESS_LIST" set to "true" - Service is blocked for EVERYONE
      # "ENABLE_ACCESS_LIST" set to "true" - Service is blocked for everyone expect the ones in below list
      ACCEPTED_ORGANISATIONS:
        - "13640203"
        - "13838614"
        - "14221005"
        - "16144209"
        - "16141777"
        - "13888347"
        - "16145549"
      # Worker node prewarming configuration
      NODE_PREWARMING_CONFIG:
        standard: # the instance type. It must exist in SUPPORTED_INSTANCE_TYPES
          # The number of reserved kafka instances of the size specified in "base_streaming_unit_size".
          # 0 means that prewarming is disabled for standard instance.
          num_reserved_instances: 0
          base_streaming_unit_size: x1
        developer: # The instance type. It must exist in SUPPORTED_INSTANCE_TYPES.
          # The number of reserved kafka instances of the size specified in "base_streaming_unit_size".
          # 20 guarantee that we'll always have one worker node prewarmed for 20 developer instances of size x1.
          num_reserved_instances: 20
          base_streaming_unit_size: x1

## MAS new front end deployments

- name: application-services-ui-frontend
  path: /deploy/frontend.yml
  url: https://gitlab.cee.redhat.com/mk-ci-cd/application-services-ui
  targets:
    - namespace:
        $ref: /services/insights/ephemeral/namespaces/ephemeral-base.yml
      disable: true  # do not create an app-sre deploy job for ephemeral namespace
      ref: internal  # populated by bonfire
    - namespace:
        $ref: /services/insights/ephemeral/namespaces/consoledot-frontend-stage.yml
      ref: 6f7d7fea4698379c4f7903f869cf9a20946dd51b
      parameters:
        ENV_NAME: env-stage

- name: rhosak-ui
  path: /deploy/frontend.yml
  url: https://gitlab.cee.redhat.com/mk-ci-cd/rhosak-ui
  targets:
    - namespace:
        $ref: /services/insights/ephemeral/namespaces/ephemeral-base.yml
      disable: true  # do not create an app-sre deploy job for ephemeral namespace
      ref: internal  # populated by bonfire
    - namespace:
        $ref: /services/insights/ephemeral/namespaces/consoledot-frontend-stage.yml
      ref: e14c3d43c0cf11650ee004645d0f2e2e1f8e4a8d
      parameters:
        ENV_NAME: env-stage
