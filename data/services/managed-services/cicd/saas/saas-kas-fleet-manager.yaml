---
$schema: /app-sre/saas-file-2.yml

labels:
  service: kas-fleet-manager

name: saas-kas-fleet-manager
description: 'SaaS tracking file for Kafka Service Fleet Manager'

app:
  $ref: /services/managed-services/app.yml

pipelinesProvider:
  $ref: /services/managed-services/pipelines/tekton.kas-fleet-manager-pipelines.appsrep05ue1.yaml

deployResources:
  requests:
    cpu: 300m
    memory: 600Mi
  limits:
    cpu: 300m
    memory: 600Mi

slack:
  workspace:
    $ref: /dependencies/slack/coreos.yml
  channel: mk-kas-fleet-manager

managedResourceTypes:
- Deployment
- Service
- ConfigMap

imagePatterns:
- quay.io/rhoas/kas-fleet-manager
- quay.io/centos/centos
- quay.io/rhoas/envoyproxy
- quay.io/observatorium/token-refresher
- quay.io/rhoas/mk-token-refresher

authentication:
  image:
    path: managed-services/quay-org-accounts/rhoas/robots/rhoas-pull
    field: all

resourceTemplates:
- name: observatorium-token-refresher
  url: https://gitlab.cee.redhat.com/service/kas-fleet-manager
  path: /templates/observatorium-token-refresher.yml
  targets:
  - namespace:
      $ref: /services/managed-services/namespaces/managed-services-stage.yml
    ref: main
    parameters:
      ISSUER_URL: ${SSO_BASE_URL}
      OBSERVATORIUM_URL: https://observatorium-mst.api.stage.openshift.com/api/metrics/v1/managedkafka
      OBSERVATORIUM_TOKEN_REFRESHER_IMAGE: quay.io/rhoas/mk-token-refresher
      OBSERVATORIUM_TOKEN_REFRESHER_IMAGE_TAG: 0b54d2e
  - namespace:
      $ref: /services/managed-services/namespaces/managed-services-production.yml
    # Please note the following before updating this 'ref' property:
    # - The commit sha specified here should always be the same commit sha specified for the kas-fleet-manager ref in production.
    #   e.g. If the kas-fleet-manager version was updated in production, the value of this ref property must also be updated to match the new commit hash.
    # - Commits can be found here: https://gitlab.cee.redhat.com/service/kas-fleet-manager/-/commits/main
    # If in doubt, please check with the MK Control Plane team.
    # We are exploring how to automate this in the future.
    ref: 3bb6b78b4ae5254353aec0d92ebf69898cd8e030
    parameters:
      ISSUER_URL: ${SSO_BASE_URL}
      OBSERVATORIUM_URL: https://observatorium-mst.api.openshift.com/api/metrics/v1/managedkafka
      OBSERVATORIUM_TOKEN_REFRESHER_IMAGE: quay.io/rhoas/mk-token-refresher
      OBSERVATORIUM_TOKEN_REFRESHER_IMAGE_TAG: 0b54d2e
- name: kas-fleet-manager
  url: https://gitlab.cee.redhat.com/service/kas-fleet-manager
  path: /templates/service-template.yml
  parameters:
    # Global parameter - Affects Production and Stage
    IMAGE_REGISTRY: quay.io
    # Global parameter - Affects Production and Stage
    IMAGE_REPOSITORY: rhoas/kas-fleet-manager
    # Global parameter - Affects Production and Stage
    # SSO_BASE_URL is defined at the environment parameters level
    JWKS_URL: ${SSO_BASE_URL}/protocol/openid-connect/certs
    # Global parameter - Affects Production and Stage
    CLUSTER_OPENSHIFT_VERSION: ""
    # Global parameter - Affects Production and Stage
    CLUSTER_COMPUTE_MACHINE_TYPE: m5.2xlarge
    # Global parameter - Affects Production and Stage
    # Global parameter - Affects Production and Stage
    # Change this to false if you want the users to be able to use the service without accepting any terms
    ENABLE_TERMS_ACCEPTANCE: true
    # Global parameter - Affects Production and Stage
    # Change this to false if you want to disable the deny list feature feature
    ENABLE_DENY_LIST: true
    # Global parameter - Affects Production and Stage
    # Change this to false to disable sentry
    ENABLE_SENTRY: true
    # Global parameter - Affects Production and Stage
    # Enable the external Kafka certificate for all Kafka clusters
    ENABLE_KAFKA_EXTERNAL_CERTIFICATE: true
    # Global parameter - Affects Production and Stage
    # Enable the dedicate Ingress on the data plane clusters which all Kafka Clusters will use
    ENABLE_DEDICATED_INGRESS: true
    # Global parameter - Affects Production and Stage
    #The public HTTP host URL of the service
    SERVICE_PUBLIC_HOST_URL: ${OCM_BASE_URL}
    # Global parameter - Affects Production and Stage
    # A URL to repository containing external Kafka Observability configuration info for Obs. Operator to consume
    OBSERVABILITY_CONFIG_REPO: https://api.github.com/repos/bf2fc6cc711aee1a0c2a/observability-resources-mk/contents
    # Global parameter - Affects Production and Stage
    # Which channel (directory) within the config repo the Observability Operator should consume from
    OBSERVABILITY_CONFIG_CHANNEL: resources
    # Global parameters - Affects Production and Stage
    # Capacity settings for the base Kafka type
    KAFKA_CAPACITY_INGRESS_THROUGHPUT: "30Mi"
    KAFKA_CAPACITY_TOTAL_MAX_CONNECTIONS: "3000"
    KAFKA_CAPACITY_MAX_DATA_RETENTION_SIZE: "1000Gi"
    KAFKA_CAPACITY_MAX_DATA_RETENTION_PERIOD: "P14D"
    KAFKA_CAPACITY_MAX_CONNECTION_ATTEMPTS_PER_SEC: "100"
    # Global parameter - Affects Production and Stage
    # Image to be used by Envoy sidecar container
    ENVOY_IMAGE: quay.io/rhoas/envoyproxy:v1.16.1
  targets:
  - namespace:
      $ref: /services/managed-services/namespaces/managed-services-stage.yml
    ref: main
    upstream:
      instance:
        $ref: /dependencies/ci-int/ci-int.yml
      name: service-kas-fleet-manager-gl-build-main
    parameters:
      DB_SSLMODE: verify-full
      ENVIRONMENT: stage
      REPLICAS: 6
      SENTRY_URL: sentry.stage.devshift.net
      SENTRY_PROJECT: 21
      MAS_SSO_BASE_URL: https://identity.api.stage.openshift.com
      MAS_SSO_REALM: rhoas
      OSD_IDP_MAS_SSO_REALM: rhoas-kafka-sre
      OCM_URL: https://api.openshift.com
      # Log level
      GLOG_V: 10
      # AMS
      AMS_URL: ${OCM_BASE_URL}
      # Use the ams based quota management service
      QUOTA_TYPE: ams
      # Dex identity service url
      DEX_URL: http://dex-dex.apps.pbraun-observatorium.observability.rhmw.io
      # Dex identity service username
      DEX_USERNAME: admin@example.com
      # A URL to an Observatorium instance where observability metrics will sent to.
      OBSERVATORIUM_GATEWAY: https://observatorium-observatorium.apps.pbraun-observatorium.observability.rhmw.io
      # Observatorium tenant where observability metrics will sent to.
      OBSERVATORIUM_TENANT: test
      # The value of this auth type ( "dex" or "redhat" ) will determine the auth type ( Dex or Red Hat SSO) implemented for the observability stack
      OBSERVATORIUM_AUTH_TYPE: redhat
      # Token Refresher URL
      OBSERVATORIUM_TOKEN_REFRESHER_URL: http://token-refresher.managed-services-stage.svc.cluster.local
      # Release tag within Config Repo to use for pulling index information
      OBSERVABILITY_CONFIG_TAG: v1.26.0
      # Observatorium Red Hat SSO tenant for observability stack
      OBSERVATORIUM_RHSSO_TENANT: managedkafka
      # Red Hat SSO Observability gateway
      OBSERVATORIUM_RHSSO_GATEWAY: https://observatorium-mst.api.stage.openshift.com
      # Red Hat SSO Observability realm
      OBSERVATORIUM_RHSSO_REALM: redhat-external
      # Red Hat SSO Observability auth server url
      OBSERVATORIUM_RHSSO_AUTH_SERVER_URL: https://sso.redhat.com/auth
      # Maximum number of partitions per cluster
      KAFKA_CAPACITY_MAX_PARTITIONS: "1000"
      # Changing this to true will delete all kafkas after their lifespan expired. The default is 48 hours.
      ENABLE_KAFKA_LIFE_SPAN: true
      # This value is the lifespan a kafka will have with the lifespan flag enabled. In hours.
      KAFKA_LIFE_SPAN: 2
      MAS_SSO_ENABLE_AUTH: true
      # Max allowed service accounts created by users
      MAX_ALLOWED_SERVICE_ACCOUNTS: 50
      # Max limit for the fetching the clients from mas-sso
      MAX_LIMIT_FOR_SSO_GET_CLIENTS: 100
      # Set domain name for Kafka instances
      KAFKA_DOMAIN_NAME: "bf2.kafka-stage.rhcloud.com"
      STRIMZI_OPERATOR_ADDON_ID: managed-kafka-qe
      KAS_FLEETSHARD_ADDON_ID: kas-fleetshard-operator-qe
      # The Cluster Logging Operator ID. An empty string indicates that the operator should not be installed.
      CLUSTER_LOGGING_OPERATOR_ADDON_ID: "cluster-logging-operator"
      # A list of usernames representing users who do not have access to the service
      DENIED_USERS: []
      # A list of users with read-only permissions for data plane clusters
      READ_ONLY_USERS:
        - "cgorman"   # Managed ACS developer
        - "ebenshet"  # Managed ACS developer
        - "jrodrig"   # Managed ACS developer
        - "sbaumer"   # Managed ACS developer
        - "schaudhr"  # Managed ACS developer
        - "shesselm"  # Managed ACS developer
        - "vwilson"   # Managed ACS developer
     # A list of kafka-sre users with cluster-admin permissions for data plane clusters
      KAFKA_SRE_USERS:
        - "agullon"
        - "davmarti"
        - "rlawton"
        - "robrien"
        - "rshelly"
        - "stobin"
        - "tdavidso"
        - "tdalton"
        - "kchernou"
        - "dffrench"
        - "jbriones"
        - "mziccard"
        - "akoserwa"
        - "ppaszki"
        - "pbraun"
        - "msoriano"
        - "mchitimb"
        - "npecka"
        - "ppatiern"
        - "shawkins"
        - "kwall"
        - "gryan"
        - "fvila"
        - "xiwu"
        - "lclarkeh"
        - "sbarker"
        - "rareddy"
        - "medgar"
        - "tcooper"
        - "mfreer"
        - "crarobin"
        - "pcremin"
        - "deepshar"
        - "hlipsig"
        - "raananda"
        - "sclarkso"
        - "jsarnovs"
        - "vbommana"
        - "jcueto"
        - "swoodman"
        - "srbiswas"
        - "vbusch"
        - "lukchen"
        - "kstanley"

      # parameters for SUPPORTED_INSTANCE_TYPES - should be moved into prod on next release
      SUPPORTED_INSTANCE_TYPES:
      - id: eval
        sizes:
        - id: x1
          ingressThroughputPerSec: "30Mi"
          egressThroughputPerSec: "30Mi"
          totalMaxConnections: 3000
          maxDataRetentionSize: "1000Gi"
          maxPartitions: 1000
          maxDataRetentionPeriod: "P14D"
          maxConnectionAttemptsPerSec: 100
          quotaConsumed: 1
          quotaType: "rhosak"
          capacityConsumed: 1
      - id: standard
        sizes:
        - id: x1
          ingressThroughputPerSec: "50Mi"
          egressThroughputPerSec: "100Mi"
          totalMaxConnections: 3000
          maxDataRetentionSize: "1000Gi"
          maxPartitions: 1500
          maxDataRetentionPeriod: "P14D"
          maxConnectionAttemptsPerSec: 100
          quotaConsumed: 1
          quotaType: "rhosak"
          capacityConsumed: 1
        - id: x2
          ingressThroughputPerSec: "100Mi"
          egressThroughputPerSec: "200Mi"
          totalMaxConnections: 4000
          maxDataRetentionSize: "2000Gi"
          maxPartitions: 3000
          maxDataRetentionPeriod: "P14D"
          maxConnectionAttemptsPerSec: 200
          quotaConsumed: 2
          quotaType: "rhosak"
          capacityConsumed: 2

      SUPPORTED_CLOUD_PROVIDERS:
        - name: aws
          default: true
          regions:
            - name: us-east-1
              default: true
              supported_instance_type:
                standard: {}
                eval: {}

      #manual: use data plane config file, auto: use kas-fleet-shard
      DATAPLANE_CLUSTER_SCALING_TYPE: manual

      # cluster list if dataplane cluster scaling type is set to manual
      CLUSTER_LIST:
        - name: Stage Cluster (In OSD Prod)
          cluster_id: 1lfl3g1vdea86ghh26vkmbqjkain900q
          cloud_provider: aws
          region: us-east-1
          multi_az: true
          schedulable: true
          kafka_instance_limit: 8
          supported_instance_type: standard,eval

  - namespace:
      $ref: /services/managed-services/namespaces/managed-services-production.yml
    # This commit sha will need to replaced to reference the latest working commit.
    # Make sure that we've a docker image for this before it can be changed.
    # When change this, make sure to also change the `IMAGE_TAG` to reference the first seven characters of the sha1.
    # Commits can be found here https://gitlab.cee.redhat.com/service/kas-fleet-manager/-/commits/main
    # Inspect the recent merged MR from https://gitlab.cee.redhat.com/service/kas-fleet-manager/-/merge_requests?scope=all&utf8=%E2%9C%93&state=merged to get the latest commit that has a docker image built from it.
    # e.g if we take https://gitlab.cee.redhat.com/service/kas-fleet-manager/-/merge_requests/356/commits, the commit with a docker image in it will be
    # the very first commit i.e https://gitlab.cee.redhat.com/service/kas-fleet-manager/-/merge_requests/356/commits?commit_id=f0fd63740464c5fa4bda395d5d31f675eff049ac
    # If in doubt, see with the control plane team.
    # We are exploring into using automating this.
    ref: 3bb6b78b4ae5254353aec0d92ebf69898cd8e030
    parameters:
      DB_SSLMODE: verify-full
      ENVIRONMENT: production
      KAFKA_LIFE_SPAN: 48
      QUOTA_TYPE: ams
      # The image tag is the first seven characters of the #ref commit sha parameter.
      # Verify in https://quay.io/repository/rhoas/kas-fleet-manager?tab=tags to see if the tag exists.
      IMAGE_TAG: 3bb6b78
      STRIMZI_OPERATOR_ADDON_ID: managed-kafka
      KAS_FLEETSHARD_ADDON_ID: kas-fleetshard-operator
      SENTRY_URL: sentry.devshift.net
      SENTRY_PROJECT: 16
      MAS_SSO_BASE_URL: https://identity.api.openshift.com
      MAS_SSO_REALM: rhoas
      OSD_IDP_MAS_SSO_REALM: rhoas-kafka-sre
      # Log level
      GLOG_V: 5
      # The Cluster Logging Operator ID. An empty string indicates that the operator should not be installed.
      CLUSTER_LOGGING_OPERATOR_ADDON_ID: "cluster-logging-operator"
      OCM_URL: ${OCM_BASE_URL}
      AMS_URL: ${OCM_BASE_URL}
      # Max allowed service accounts created by users
      MAX_ALLOWED_SERVICE_ACCOUNTS: 5
       # Max limit for the fetching the clients from mas-sso
      MAX_LIMIT_FOR_SSO_GET_CLIENTS: 100
      REPLICAS: 6
      # Dex identity service url
      DEX_URL: https://dex-dex.apps.mk-observe.trii.p1.openshiftapps.com
      # Dex identity service username
      DEX_USERNAME: admin@example.com
      # A URL to an Observatorium instance where observability metrics will sent to.
      OBSERVATORIUM_GATEWAY: https://observatorium-observatorium.apps.mk-observe.trii.p1.openshiftapps.com
      # Observatorium tenant where observability metrics will sent to.
      OBSERVATORIUM_TENANT: kasdataplane
      # The value of this auth type ( "dex" or "redhat" ) will determine the auth type ( Dex or Red Hat SSO) implemented for the observability
      OBSERVATORIUM_AUTH_TYPE: redhat
      # Token Refresher URL
      OBSERVATORIUM_TOKEN_REFRESHER_URL: http://token-refresher.managed-services-production.svc.cluster.local
      # Observatorium Red Hat SSO tenant for observability stack
      OBSERVATORIUM_RHSSO_TENANT: managedkafka
      # Red Hat SSO Observability gateway
      OBSERVATORIUM_RHSSO_GATEWAY: https://observatorium-mst.api.openshift.com
      # Red Hat SSO Observability realm
      OBSERVATORIUM_RHSSO_REALM: redhat-external
      # Red Hat SSO Observability auth server url
      OBSERVATORIUM_RHSSO_AUTH_SERVER_URL: https://sso.redhat.com/auth
      # Release tag within Config Repo to use for pulling index information
      OBSERVABILITY_CONFIG_TAG: v1.26.0
      # Maximum number of partitions per cluster
      KAFKA_CAPACITY_MAX_PARTITIONS: "1000"
      # A list of usernames representing users who do not have access to the service
      DENIED_USERS: []
      # A list of users with read-only permissions for data plane clusters
      READ_ONLY_USERS:
        - "dffrench"
        - "dimaggio"
        - "dingham"
        - "ebernard"
        - "gryan"
        - "jmadigan"
        - "jmernin"
        - "kwall"
        - "mchitimb"
        - "medgar"
        - "msoriano"
        - "pbraun"
        - "pemuir"
        - "ppaszki"
        - "ppatiern"
        - "rareddy"
        - "rgodfrey"
        - "shawkins"
        - "swoodman"
        - "tcooper"
        - "xiwu"
        - "lclarkeh"
        - "sbarker"
        - "kchernou"
        - "srbiswas"
        - "vbusch"
        - "lukchen"
        - "kstanley"
      # CEE Engineers
        - "aboucham"
        - "agagliar"
        - "asouza"
        - "cpandey"
        - "dhawkins"
        - "fvaleri"
        - "hnaram"
        - "jsherman"
        - "kboone"
        - "kkakarla"
        - "mmurphy"
        - "qluo"
        - "shiggs"
        - "toross"
      # A list of kafka-sre users with cluster-admin permissions for data plane clusters
      KAFKA_SRE_USERS:
        - "agullon"
        - "davmarti"
        - "rlawton"
        - "robrien"
        - "rshelly"
        - "stobin"
        - "tdavidso"
        - "npecka"
        - "fvila"
        - "mfreer"
        - "crarobin"
        - "pcremin"
        - "deepshar"
        - "hlipsig"
        - "raananda"
        - "sclarkso"
        - "jsarnovs"

      # Set domain name for Kafka instances
      KAFKA_DOMAIN_NAME: "bf2.kafka.rhcloud.com"

      # A list of supported cloud providers and region
      SUPPORTED_CLOUD_PROVIDERS:
        - name: aws
          default: true
          regions:
            - name: us-east-1
              default: true
              supported_instance_type:
                standard: {}
                eval: {}
            - name: eu-west-1
              default: false
              supported_instance_type:
                standard: {}

      # Changing this to true will delete all kafkas after their lifespan expired. The default is 48 hours.
      ENABLE_KAFKA_LIFE_SPAN: true

      #manual: use data plane config file, auto: use kas-fleet-shard
      DATAPLANE_CLUSTER_SCALING_TYPE: manual

      # cluster list if dataplane cluster scaling type is set to manual
      CLUSTER_LIST:
        - name: mk-0419-204008
          cluster_id: 1k5ot6e86c6itcqqsrs019bngqc7cjin
          cloud_provider: aws
          region: us-east-1
          multi_az: true
          schedulable: true # change this to false if you do not want the cluster to be schedulable
          kafka_instance_limit: 28 # change this to match any value of configuration
          supported_instance_type: standard
        - name: mk-1006-115633
          cluster_id: 1nlj5j786fsg44srlj7f2kep5htakcp7
          cloud_provider: aws
          region: eu-west-1
          multi_az: true
          schedulable: true # change this to false if you do not want the cluster to be schedulable
          kafka_instance_limit: 3 # change this to match any value of configuration
          supported_instance_type: standard
        - name: mk-1201-144802
          cluster_id: 1oqjq8qup5vhhn4seg03al8k34kdc8lj
          cloud_provider: aws
          region: us-east-1
          multi_az: true
          schedulable: true # change this to false if you do not want the cluster to be schedulable
          kafka_instance_limit: 30 # change this to match any value of configuration
          supported_instance_type: eval

