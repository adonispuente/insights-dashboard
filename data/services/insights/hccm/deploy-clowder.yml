---
$schema: /app-sre/saas-file-2.yml

labels:
  service: hccm
  platform: insights

name: hccm-clowder
description: hccm app on the Insights Platform deployed with Clowder

app:
  $ref: /services/insights/hccm/app.yml

pipelinesProvider:
  $ref: /services/insights/pipelines/tekton.crc-pipelines.appsrep05ue1.yaml

slack:
  workspace:
    $ref: /dependencies/slack/redhat-internal.yml
  channel: cost-mgmt-bots

managedResourceTypes:
- ClowdApp
- ConfigMap
- ClowdJobInvocation
- Frontend

imagePatterns:
- quay.io/cloudservices
- quay.io/app-sre

authentication:
  image:
    path: insights/quay/cloudservices-push
    field: all
    version: 3

parameters:
  CLOWDER_ENABLED: true
  ACCOUNT_ENHANCED_METRICS: False

resourceTemplates:
- name: koku-cji
  # repo deploy file: https://github.com/project-koku/koku/blob/main/deploy/koku-cji.yaml
  # container image: quay.io/cloudservices/koku
  # container repo:  https://quay.io/repository/cloudservices/koku
  path: /deploy/koku-cji.yaml
  url: https://github.com/project-koku/koku
  targets:
  # Staging:
  - namespace:
      $ref: /services/insights/hccm/namespaces/stage-hccm-stage.yml
    ref: 74d1de63c8e66e10899b4086a394260f8bcbdacd
    parameters:
      CJI_INVOCATION: "01"

  # Production:
  - namespace:
      $ref: /services/insights/hccm/namespaces/hccm-prod.yml
    ref: dbfe096de9624982d8c80db8cbce7da6312681f9
    parameters:
      CJI_INVOCATION: "01"

- name: koku
  # repo deploy file: https://github.com/project-koku/koku/blob/main/deploy/clowdapp.yaml
  # container image: quay.io/cloudservices/koku
  # container repo:  https://quay.io/repository/cloudservices/koku
  path: /deploy/clowdapp.yaml
  url: https://github.com/project-koku/koku
  targets:

  # Ephemeral
  - namespace:
      $ref: /services/insights/ephemeral/namespaces/ephemeral-base.yml
    disable: true # tells app-sre to not actually run the deploy job for this target
    ref: internal # altered by bonfire
    parameters:
      ENABLE_HCS_DEBUG: True
      ENABLE_S3_ARCHIVING: True
      AUTO_DATA_INGEST: True
      RETAIN_NUM_MONTHS: 4
      PARQUET_PROCESSING_BATCH_SIZE: "500000"
      TRINO_DATE_STEP: 31
      PRESTO_HOST: trino-coordinator
      TRINO_HOST: trino-coordinator
      # Deployment specific variables:
      # nginx
      NGINX_REPLICAS: 2
      # koku-api
      KOKU_REPLICAS: 1
      # listener
      LISTENER_REPLICAS: 2
      # masu
      MASU_REPLICAS: 1
      # scheduler
      SCHEDULER_REPLICAS: 1
      # sources-client
      SOURCES_CLIENT_REPLICAS: 1
      # sources-listener
      SOURCES_LISTENER_REPLICAS: 1
      # worker-celery
      WORKER_CELERY_REPLICAS: 1
      # worker-cost-model
      WORKER_COST_MODEL_REPLICAS: 1
      # worker-download
      WORKER_DOWNLOAD_REPLICAS: 2
      # worker-ocp
      WORKER_OCP_REPLICAS: 2
      # worker-priority
      WORKER_PRIORITY_REPLICAS: 2
      # worker-refresh
      WORKER_REFRESH_REPLICAS: 1
      # worker-summary
      WORKER_SUMMARY_REPLICAS: 2
      # worker-cost-model-xl
      WORKER_COST_MODEL_XL_REPLICAS: 0
      # worker-download-xl
      WORKER_DOWNLOAD_XL_REPLICAS: 0
      # worker-ocp-xl
      WORKER_OCP_XL_REPLICAS: 0
      # worker-priority-xl
      WORKER_PRIORITY_XL_REPLICAS: 0
      # worker-refresh-xl
      WORKER_REFRESH_XL_REPLICAS: 0
      # worker-summary-xl
      WORKER_SUMMARY_XL_REPLICAS: 0
      # worker-hcs
      WORKER_HCS_REPLICAS: 1
      # Change these settings when deploying migrations to Ephemeral
      # Migrations Image Tag
      # DBM_IMAGE_TAG: x
      # Migrations Invocation
      # DBM_INVOCATION: "00"
      # Migration directive is optional and should be in the form of:
      # <app>[:<migration>][,<app>[:<migration>]...]
      # Ex: "reporting:0200,api:0050"
      # Ex: "reporting:0200"
      # Ex: "reporting"
      # Ex: ""
      # _MIGRATION_DIRECTIVE: ""
      # Enhanced Org Admin
      ENHANCED_ORG_ADMIN: True
      UNLEASH_LOG_LEVEL: "ERROR"

      KOKU_MIGRATIONS_CPU_REQUEST: "200m"
      KOKU_MIGRATIONS_CPU_LIMIT: "500m"

      TAG_ENABLED_LIMIT: -1  # Disable the limit for testing


  # Staging:
  - namespace:
      $ref: /services/insights/hccm/namespaces/stage-hccm-stage.yml
    ref: main
    upstream:
      instance:
        $ref: /dependencies/ci-ext/ci-ext.yml
      name: project-koku-koku-gh-build-main
    parameters:
      ############# MIGRATIONS #############
      # Change these settings when deploying migrations to Staging
      # Migrations Image Tag
      DBM_IMAGE_TAG: 76c0d76
      # Migrations Invocation
      DBM_INVOCATION: "01"
      # Migration directive is optional and should be in the form of:
      # <app>[:<migration>][,<app>[:<migration>]...]
      # Ex: "reporting:0200,api:0050"
      # Ex: "reporting:0200"
      # Ex: "reporting"
      # Ex: ""
      _MIGRATION_DIRECTIVE: "reporting:0282"
      ######################################
      APP_DOMAIN: apps.crcs02ue1.urby.p1.openshiftapps.com
      ROS_OCP_API: ros-ocp-backend-api.ros-stage.svc.cluster.local
      S3_BUCKET_NAME: hccm-stage-s3
      S3_ROS_BUCKET_NAME: hccm-ros-stage-s3
      S3_SUBS_BUCKET_NAME: hccm-subs-stage-s3
      KOKU_SENTRY_ENV: stage
      ENABLE_API_SENTRY: True
      ENABLE_CELERY_SENTRY: True
      DEMO_ACCOUNTS: '{"6193296":{"arn:aws:iam::589173575009:role/NisePopulatorAccessRole":{"source_type": "AWS", "report_prefix":"cur","report_name":"awscost"},"5d4eb34d-43c7-4b06-8257-1cb599b48d1e":{"source_type": "Azure", "report_prefix":"cur","report_name":"azurecost","container_name":"cur"}}, "1290557":{"arn:aws:iam::589173575009:role/NisePopulatorAccessRole":{"source_type": "AWS", "report_prefix":"cur","report_name":"awscost"},"5d4eb34d-43c7-4b06-8257-1cb599b48d1e":{"source_type": "Azure", "report_prefix":"cur","report_name":"azurecost","container_name":"cur"}}}'
      ENABLE_PARQUET_PROCESSING: True
      ENABLE_S3_ARCHIVING: True
      ENABLE_TRINO_SOURCES: ''
      ENABLE_TRINO_SOURCE_TYPE: 'GCP'
      ENABLE_TRINO_ACCOUNTS: 'acct6193296'
      TRINO_DATE_STEP: 31
      AUTO_DATA_INGEST: True
      UPDATE_TIMEOUT: 14400
      RETAIN_NUM_MONTHS: 4
      VACUUM_DATA_DAY_OF_WEEK: 0
      REPORT_DOWNLOAD_SCHEDULE: "0 0,5,15,22 * * *" # 4 times a day avoiding QE test runs
      POLLING_TIMER: 72000 # 20 hours
      POLLING_BATCH_SIZE: 25 # Polling provider count
      PARQUET_PROCESSING_BATCH_SIZE: "500000"
      TRINO_HOST: trino-coordinator
      RBAC_CACHE_TIMEOUT: 1
      CACHE_TIMEOUT: 1
      TAG_ENABLED_LIMIT: -1  # Disable the limit for testing
      # Deployment specific variables:
      # koku-api
      KOKU_REPLICAS: 3
      KOKU_CPU_REQUEST: 300m
      KOKU_CPU_LIMIT: 600m
      KOKU_MEMORY_REQUEST: 768Mi
      KOKU_MEMORY_LIMIT: 1536Mi
      # clowder-api nginx
      NGINX_REPLICAS: 2
      NGINX_CPU_REQUEST: 100m
      NGINX_CPU_LIMIT: 200m
      NGINX_MEMORY_REQUEST: 100Mi
      NGINX_MEMORY_LIMIT: 200Mi
      # listener
      LISTENER_REPLICAS: 3
      LISTENER_CPU_REQUEST: 200m
      LISTENER_CPU_LIMIT: 400m
      LISTENER_MEMORY_REQUEST: 300Mi
      LISTENER_MEMORY_LIMIT: 600Mi
      # masu
      MASU_REPLICAS: 1
      MASU_MEMORY_REQUEST: 600Mi
      MASU_MEMORY_LIMIT: 800Mi
      # scheduler
      SCHEDULER_REPLICAS: 1
      SCHEDULER_MEMORY_REQUEST: 256Mi
      SCHEDULER_MEMORY_LIMIT: 512Mi
      # sources-client
      SOURCES_CLIENT_REPLICAS: 3
      SOURCES_CLIENT_CPU_REQUEST: 50m
      SOURCES_CLIENT_CPU_LIMIT: 250m
      SOURCES_CLIENT_MEMORY_REQUEST: 256Mi
      SOURCES_CLIENT_MEMORY_LIMIT: 512Mi
      # sources-listener
      SOURCES_LISTENER_REPLICAS: 1
      SOURCES_LISTENER_CPU_REQUEST: 50m
      SOURCES_LISTENER_CPU_LIMIT: 250m
      SOURCES_LISTENER_MEMORY_REQUEST: 256Mi
      SOURCES_LISTENER_MEMORY_LIMIT: 512Mi
      # workers global
      WORKER_PROC_ALIVE_TIMEOUT: 8
      # worker-celery
      WORKER_CELERY_REPLICAS: 3
      WORKER_CELERY_CPU_REQUEST: 50m
      WORKER_CELERY_CPU_LIMIT: 250m
      WORKER_CELERY_MEMORY_REQUEST: 300Mi
      WORKER_CELERY_MEMORY_LIMIT: 600Mi
      # worker-cost-model
      WORKER_COST_MODEL_REPLICAS: 3
      WORKER_COST_MODEL_CPU_REQUEST: 50m
      WORKER_COST_MODEL_CPU_LIMIT: 200m
      WORKER_COST_MODEL_MEMORY_REQUEST: 300Mi
      WORKER_COST_MODEL_MEMORY_LIMIT: 600Mi
      # worker-download
      WORKER_DOWNLOAD_REPLICAS: 3
      WORKER_DOWNLOAD_CPU_REQUEST: 300m
      WORKER_DOWNLOAD_CPU_LIMIT: 600m
      WORKER_DOWNLOAD_MEMORY_REQUEST: 2Gi
      WORKER_DOWNLOAD_MEMORY_LIMIT: 4Gi
      # worker-ocp
      WORKER_OCP_REPLICAS: 3
      WORKER_OCP_CPU_REQUEST: 75m
      WORKER_OCP_CPU_LIMIT: 200m
      WORKER_OCP_MEMORY_REQUEST: 300Mi
      WORKER_OCP_MEMORY_LIMIT: 600Mi
      # worker-priority
      WORKER_PRIORITY_REPLICAS: 3
      WORKER_PRIORITY_CPU_REQUEST: 200m
      WORKER_PRIORITY_CPU_LIMIT: 400m
      WORKER_PRIORITY_MEMORY_REQUEST: 1Gi
      WORKER_PRIORITY_MEMORY_LIMIT: 2Gi
      # worker-refresh
      WORKER_REFRESH_REPLICAS: 3
      WORKER_REFRESH_CPU_REQUEST: 50m
      WORKER_REFRESH_CPU_LIMIT: 200m
      WORKER_REFRESH_MEMORY_REQUEST: 420Mi
      WORKER_REFRESH_MEMORY_LIMIT: 600Mi
      # worker-summary
      WORKER_SUMMARY_REPLICAS: 3
      WORKER_SUMMARY_CPU_REQUEST: 75m
      WORKER_SUMMARY_CPU_LIMIT: 200m
      WORKER_SUMMARY_MEMORY_REQUEST: 650Mi
      WORKER_SUMMARY_MEMORY_LIMIT: 800Mi
      # worker-cost-model-xl
      WORKER_COST_MODEL_XL_REPLICAS: 0
      # worker-download-xl
      WORKER_DOWNLOAD_XL_REPLICAS: 0
      # worker-ocp-xl
      WORKER_OCP_XL_REPLICAS: 0
      # worker-priority-xl
      WORKER_PRIORITY_XL_REPLICAS: 0
      # worker-refresh-xl
      WORKER_REFRESH_XL_REPLICAS: 0
      # worker-summary-xl
      WORKER_SUMMARY_XL_REPLICAS: 0
      # worker-hcs
      WORKER_HCS_REPLICAS: 3
      WORKER_HCS_CPU_REQUEST: 75m
      WORKER_HCS_CPU_LIMIT: 200m
      WORKER_HCS_MEMORY_REQUEST: 425Mi
      WORKER_HCS_MEMORY_LIMIT: 600Mi
      # worker-subs-extraction
      WORKER_SUBS_EXTRACTION_REPLICAS: 3
      WORKER_SUBS_EXTRACTION_CPU_REQUEST: 75m
      WORKER_SUBS_EXTRACTION_CPU_LIMIT: 200m
      WORKER_SUBS_EXTRACTION_MEMORY_REQUEST: 425Mi
      WORKER_SUBS_EXTRACTION_MEMORY_LIMIT: 600Mi
      # worker-subs-transmission
      WORKER_SUBS_TRANSMISSION_REPLICAS: 3
      WORKER_SUBS_TRANSMISSION_CPU_REQUEST: 75m
      WORKER_SUBS_TRANSMISSION_CPU_LIMIT: 200m
      WORKER_SUBS_TRANSMISSION_MEMORY_REQUEST: 425Mi
      WORKER_SUBS_TRANSMISSION_MEMORY_LIMIT: 600Mi


  # Production:
  - namespace:
      $ref: /services/insights/hccm/namespaces/hccm-prod.yml
    ref: 6d91ae84b3e6e6d8374e4bca085655fcae1467d4
    parameters:
      ############# MIGRATIONS #############
      # Change these settings when deploying migrations to Production
      # Migrations Image Tag
      DBM_IMAGE_TAG: cfddb9d
      # Migrations Invocation
      DBM_INVOCATION: "00"
      # Migration directive is optional and should be in the form of:
      # <app>[:<migration>][,<app>[:<migration>]...]
      # Ex: "reporting:0200,api:0050"
      # Ex: "reporting:0200"
      # Ex: "reporting"
      # Ex: ""
      _MIGRATION_DIRECTIVE: ""
      ######################################
      APP_DOMAIN: apps.crcp01ue1.o9m8.p1.openshiftapps.com
      ROS_OCP_API: ros-ocp-backend-api.ros-prod.svc.cluster.local
      S3_BUCKET_NAME: hccm-prod-s3
      S3_ROS_BUCKET_NAME: hccm-ros-prod-s3
      S3_SUBS_BUCKET_NAME: hccm-subs-prod-s3
      KOKU_SENTRY_ENV: prod
      ENABLE_API_SENTRY: True
      ENABLE_CELERY_SENTRY: True
      DEMO_ACCOUNTS: '{"6193296":{"arn:aws:iam::589173575009:role/NisePopulatorAccessRole":{"source_type": "AWS", "report_prefix":"cur","report_name":"awscost"},"5d4eb34d-43c7-4b06-8257-1cb599b48d1e":{"source_type": "Azure", "report_prefix":"cur","report_name":"azurecost","container_name":"cur"}}}'
      ENABLE_PARQUET_PROCESSING: True
      ENABLE_S3_ARCHIVING: True
      ENABLE_TRINO_SOURCES: 'f71993c9-db47-4dcf-b375-c32d84502b13,118445f0-7304-4311-aa22-ed86b484f48d,79419ac3-cf38-450c-84cf-7d2accc2c293,889668d0-8bdc-4e96-84fe-4311b3514efb,b139babe-9f1a-4519-ae49-bfd4e06807a2,cbf2420e-ab4b-4ab3-b27c-d5a05d578262,d24bd391-fc65-4275-a7bb-174c91e1c9fe,f1eb8998-4984-4ee5-9bfb-f0370cb690a4,cc11e600-9888-4614-be92-634b132c0f44,a84c1928-4891-4ff0-b458-f4fd27a7218a,a6568967-155a-428f-a20c-3c5d46f45ad8,bfad1e15-91eb-478f-a600-ffb3b0ee1042'
      ENABLE_TRINO_SOURCE_TYPE: 'GCP'
      ENABLE_TRINO_ACCOUNTS: 'acct7049367'
      QE_SCHEMA: 'acct6089719'
      TRINO_DATE_STEP: 3  # 5
      AUTO_DATA_INGEST: True
      RETAIN_NUM_MONTHS: 5
      TAG_ENABLED_LIMIT: -1  # Disable the limit for testing
      # INITIAL_INGEST_OVERRIDE: 'True'
      # INITIAL_INGEST_NUM_MONTHS: 1
      SCHEDULE_CHECK_INTERVAL: 720
      SOURCE_STATUS_FREQUENCY_MINUTES: 60
      UPDATE_TIMEOUT: 14400
      VACUUM_DATA_DAY_OF_WEEK: 0

      TENANT_MULTIPROCESSING_MAX_PROCESSES: "6"
      TENANT_MULTIPROCESSING_CHUNKS: "1"

      REPORT_DOWNLOAD_SCHEDULE: "0 * * * *" # Every hour
      POLLING_TIMER: 82800 # 23Hrs between same provider polling
      POLLING_BATCH_SIZE: 27

      TRINO_HOST: trino-coordinator
      GUNICORN_THREADS: False
      GUNICORN_WORKERS: 2
      # Deployment specific variables:
      # koku-api
      KOKU_REPLICAS: 10
      KOKU_CPU_REQUEST: 250m
      KOKU_CPU_LIMIT: 1
      KOKU_MEMORY_REQUEST: 2Gi
      KOKU_MEMORY_LIMIT: 4Gi
      # clowder-api nginx
      NGINX_REPLICAS: 3
      NGINX_CPU_REQUEST: 150m
      NGINX_CPU_LIMIT: 300m
      NGINX_MEMORY_REQUEST: 200Mi
      NGINX_MEMORY_LIMIT: 400Mi
      # listener
      LISTENER_REPLICAS: 5  #5
      LISTENER_CPU_REQUEST: 200m
      LISTENER_CPU_LIMIT: 500m
      LISTENER_MEMORY_REQUEST: 1Gi
      LISTENER_MEMORY_LIMIT: 2Gi
      # masu
      MASU_REPLICAS: 1
      MASU_MEMORY_REQUEST: 512Mi
      MASU_MEMORY_LIMIT: 1Gi
      # scheduler
      SCHEDULER_REPLICAS: 1  #1
      SCHEDULER_MEMORY_REQUEST: 256Mi
      SCHEDULER_MEMORY_LIMIT: 512Mi
      # sources-client
      SOURCES_CLIENT_REPLICAS: 3
      SOURCES_CLIENT_CPU_REQUEST: 250m
      SOURCES_CLIENT_CPU_LIMIT: 500m
      SOURCES_CLIENT_MEMORY_REQUEST: 256Mi
      SOURCES_CLIENT_MEMORY_LIMIT: 512Mi
      # sources-listener
      SOURCES_LISTENER_REPLICAS: 1
      SOURCES_LISTENER_CPU_REQUEST: 250m
      SOURCES_LISTENER_CPU_LIMIT: 500m
      SOURCES_LISTENER_MEMORY_REQUEST: 256Mi
      SOURCES_LISTENER_MEMORY_LIMIT: 512Mi
      # workers global
      WORKER_PROC_ALIVE_TIMEOUT: 9
      # worker-celery
      WORKER_CELERY_REPLICAS: 3
      WORKER_CELERY_CPU_REQUEST: 200m
      WORKER_CELERY_CPU_LIMIT: 1
      WORKER_CELERY_MEMORY_REQUEST: 512Mi
      WORKER_CELERY_MEMORY_LIMIT: 1Gi
      # worker-cost-model
      WORKER_COST_MODEL_REPLICAS: 2 #2
      WORKER_COST_MODEL_CPU_REQUEST: 100m
      WORKER_COST_MODEL_CPU_LIMIT: 300m
      WORKER_COST_MODEL_MEMORY_REQUEST: 400Mi
      WORKER_COST_MODEL_MEMORY_LIMIT: 800Mi
      # worker-cost-model_xl
      WORKER_COST_MODEL_XL_REPLICAS: 2 #2
      WORKER_COST_MODEL_XL_CPU_REQUEST: 100m
      WORKER_COST_MODEL_XL_CPU_LIMIT: 300m
      WORKER_COST_MODEL_XL_MEMORY_REQUEST: 512Mi
      WORKER_COST_MODEL_XL_MEMORY_LIMIT: 1Gi
      # worker-download
      WORKER_DOWNLOAD_REPLICAS: 3  #3
      WORKER_DOWNLOAD_CPU_REQUEST: 700m
      WORKER_DOWNLOAD_CPU_LIMIT: 1500m
      WORKER_DOWNLOAD_MEMORY_REQUEST: 4Gi
      WORKER_DOWNLOAD_MEMORY_LIMIT: 8Gi
      # worker-download_xl
      WORKER_DOWNLOAD_XL_REPLICAS: 3  #3
      WORKER_DOWNLOAD_XL_CPU_REQUEST: 700m
      WORKER_DOWNLOAD_XL_CPU_LIMIT: 1500m
      WORKER_DOWNLOAD_XL_MEMORY_REQUEST: 4Gi
      WORKER_DOWNLOAD_XL_MEMORY_LIMIT: 8Gi
      # worker-ocp
      WORKER_OCP_REPLICAS: 3  #3
      WORKER_OCP_CPU_REQUEST: 200m
      WORKER_OCP_CPU_LIMIT: 400m
      WORKER_OCP_MEMORY_REQUEST: 400Mi
      WORKER_OCP_MEMORY_LIMIT: 800Mi
      # worker-ocp_xl
      WORKER_OCP_XL_REPLICAS: 3  #3
      WORKER_OCP_XL_CPU_REQUEST: 250m
      WORKER_OCP_XL_CPU_LIMIT: 500m
      WORKER_OCP_XL_MEMORY_REQUEST: 512Mi
      WORKER_OCP_XL_MEMORY_LIMIT: 1Gi
      # worker-priority
      WORKER_PRIORITY_REPLICAS: 1  #1
      WORKER_PRIORITY_CPU_REQUEST: 500m
      WORKER_PRIORITY_CPU_LIMIT: 1
      WORKER_PRIORITY_MEMORY_REQUEST: 2Gi
      WORKER_PRIORITY_MEMORY_LIMIT: 4Gi
      # worker-priority_xl
      WORKER_PRIORITY_XL_REPLICAS: 1  #1
      WORKER_PRIORITY_XL_CPU_REQUEST: 500m
      WORKER_PRIORITY_XL_CPU_LIMIT: 1
      WORKER_PRIORITY_XL_MEMORY_REQUEST: 3Gi
      WORKER_PRIORITY_XL_MEMORY_LIMIT: 6Gi
      # worker-refresh
      WORKER_REFRESH_REPLICAS: 2  #2
      WORKER_REFRESH_CPU_REQUEST: 100m
      WORKER_REFRESH_CPU_LIMIT: 200m
      WORKER_REFRESH_MEMORY_REQUEST: 300Mi
      WORKER_REFRESH_MEMORY_LIMIT: 600Mi
      # worker-refresh_xl
      WORKER_REFRESH_XL_REPLICAS: 2  #2
      WORKER_REFRESH_XL_CPU_REQUEST: 100m
      WORKER_REFRESH_XL_CPU_LIMIT: 200m
      WORKER_REFRESH_XL_MEMORY_REQUEST: 300Mi
      WORKER_REFRESH_XL_MEMORY_LIMIT: 600Mi
      # worker-summary
      WORKER_SUMMARY_REPLICAS: 3  #3
      WORKER_SUMMARY_CPU_REQUEST: 100m
      WORKER_SUMMARY_CPU_LIMIT: 200m
      WORKER_SUMMARY_MEMORY_REQUEST: 400Mi
      WORKER_SUMMARY_MEMORY_LIMIT: 800Mi
      # worker-summary_xl
      WORKER_SUMMARY_XL_REPLICAS: 5  #3
      WORKER_SUMMARY_XL_CPU_REQUEST: 100m
      WORKER_SUMMARY_XL_CPU_LIMIT: 200m
      WORKER_SUMMARY_XL_MEMORY_REQUEST: 512Mi
      WORKER_SUMMARY_XL_MEMORY_LIMIT: 1Gi
      # worker-hcs
      WORKER_HCS_REPLICAS: 3
      WORKER_HCS_CPU_REQUEST: 100m
      WORKER_HCS_CPU_LIMIT: 200m
      WORKER_HCS_MEMORY_REQUEST: 500Mi
      WORKER_HCS_MEMORY_LIMIT: 1Gi
      # worker-subs-extraction
      WORKER_SUBS_EXTRACTION_REPLICAS: 3
      WORKER_SUBS_EXTRACTION_CPU_REQUEST: 75m
      WORKER_SUBS_EXTRACTION_CPU_LIMIT: 200m
      WORKER_SUBS_EXTRACTION_MEMORY_REQUEST: 425Mi
      WORKER_SUBS_EXTRACTION_MEMORY_LIMIT: 600Mi


- name: hive-metastore
  # repo deploy file: https://github.com/RedHatInsights/ubi-hive/blob/main/deploy/clowdapp.yaml
  # container image: quay.io/cloudservices/ubi-hive
  # container repo:  https://quay.io/repository/cloudservices/ubi-hive
  path: /deploy/clowdapp.yaml
  url: https://github.com/RedHatInsights/ubi-hive
  targets:
  - namespace:
      $ref: /services/insights/ephemeral/namespaces/ephemeral-base.yml
    disable: true # tells app-sre to not actually run the deploy job for this target
    ref: internal # altered by bonfire
    parameters:
      IMAGE_TAG: 3.1.3-metastore-021
      S3_BUCKET_NAME: hccm-eph-s3
  - namespace:
      $ref: /services/insights/hccm/namespaces/stage-hccm-stage.yml
    ref: 9581ee241767cb01340d80ae1c80bb56291b8757
    parameters:
      IMAGE_TAG: 3.1.3-metastore-021
      S3_BUCKET_NAME: hccm-stage-s3
      CPU_REQUEST: 200m
      CPU_LIMIT: 500m
      MEMORY_REQUEST: 3Gi
      MEMORY_LIMIT: 5Gi
      MAX_HEAP_SIZE: 3G
  - namespace:
      $ref: /services/insights/hccm/namespaces/hccm-prod.yml
    ref: 9581ee241767cb01340d80ae1c80bb56291b8757
    parameters:
      IMAGE_TAG: 3.1.3-metastore-021
      MIN_REPLICAS: 1
      S3_BUCKET_NAME: hccm-prod-s3
      CPU_REQUEST: 200m
      CPU_LIMIT: 500m
      MEMORY_REQUEST: 6Gi
      MEMORY_LIMIT: 10Gi
      MAX_HEAP_SIZE: 6G

- name: presto
  # repo deploy file: https://github.com/RedHatInsights/ubi-trino/blob/main/deploy/clowdapp.yaml
  # container image: quay.io/cloudservices/ubi-trino
  # container repo:  https://quay.io/repository/cloudservices/ubi-trino
  path: /deploy/clowdapp.yaml
  url: https://github.com/RedHatInsights/ubi-trino
  targets:
  # Ephemeral
  - namespace:
      $ref: /services/insights/ephemeral/namespaces/ephemeral-base.yml
    disable: true # tells app-sre to not actually run the deploy job for this target
    ref: internal # altered by bonfire
    parameters:
      IMAGE_TAG: 418-005
      S3_BUCKET_NAME: hccm-eph-s3
      S3_SSE_ENABLED: 'False'
      S3_SELECT_PUSHDOWN_ENABLED: 'False'
      WORKER_REPLICAS: 2
      COORDINATOR_CPU_REQUEST: 200m
      COORDINATOR_CPU_LIMIT: 1
      COORDINATOR_MEMORY_REQUEST: 4Gi
      COORDINATOR_MEMORY_LIMIT: 8Gi
      WORKER_CPU_REQUEST: 200m
      WORKER_CPU_LIMIT: 1
      WORKER_MEMORY_REQUEST: 4Gi
      WORKER_MEMORY_LIMIT: 8Gi
      MAX_HEAP_SIZE: 6G
      LIVENESS_PROBE_PERIOD: 120
      LIVENESS_PROBE_TIMEOUT: 120
  # Staging
  - namespace:
      $ref: /services/insights/hccm/namespaces/stage-hccm-stage.yml
    ref: 6b61b8aaed4d336967279014ea8bc730e16d78f3
    parameters:
      CONFIGMAP_HASH: '000002' # when a `ref` update only contains changes to ConfigMaps, randomize this value to cause trino to redeploy
      IMAGE_TAG: 418-005
      S3_BUCKET_NAME: hccm-stage-s3
      MACHINE_POOL_OPTION: memory-optimized
      COORDINATOR_REPLICAS: 1
      WORKER_REPLICAS: 3
      COORDINATOR_CPU_REQUEST: 600m
      COORDINATOR_CPU_LIMIT: 2
      COORDINATOR_MEMORY_REQUEST: 12Gi
      COORDINATOR_MEMORY_LIMIT: 36Gi
      WORKER_CPU_REQUEST: 300m
      WORKER_CPU_LIMIT: 2
      WORKER_MEMORY_REQUEST: 6Gi
      WORKER_MEMORY_LIMIT: 10Gi
      QUERY_MAX_MEMORY_PER_NODE: 6.5GB # (jvm max - heap headroom)
      QUERY_MAX_MEMORY: 19.5GB # (max per node * worker count)
      QUERY_MAX_TOTAL_MEMORY: 39GB # (max-memory * 2)
      MEMORY_HEAP_HEADROOM_PER_NODE: 1GB
      MAX_HEAP_SIZE: 7680M
      LIVENESS_PROBE_PERIOD: 120
      LIVENESS_PROBE_TIMEOUT: 120
  # Production
  - namespace:
      $ref: /services/insights/hccm/namespaces/hccm-prod.yml
    ref: 0d7bda946ac6a0f964cd2a5ed4ed9f5e2439ffab
    parameters:
      CONFIGMAP_HASH: 'gffsf6' # when a `ref` update only contains changes to ConfigMaps, randomize this value to cause trino to redeploy
      IMAGE_TAG: 418-004
      S3_BUCKET_NAME: hccm-prod-s3
      MACHINE_POOL_OPTION: memory-optimized
      COORDINATOR_REPLICAS: 1 # 1
      WORKER_REPLICAS: 4 # 4
      COORDINATOR_CPU_REQUEST: 4
      COORDINATOR_CPU_LIMIT: 7800m
      COORDINATOR_MEMORY_REQUEST: 54Gi
      COORDINATOR_MEMORY_LIMIT: 56Gi
      WORKER_CPU_REQUEST: 4
      WORKER_CPU_LIMIT: 7800m
      WORKER_MEMORY_REQUEST: 54Gi
      WORKER_MEMORY_LIMIT: 56Gi
      QUERY_MAX_MEMORY_PER_NODE: 25GB # (jvm max - heap headroom)
      QUERY_MAX_MEMORY: 100GB # (max per node * worker count)
      QUERY_MAX_TOTAL_MEMORY: 200GB # (max-memory * 2)
      MEMORY_HEAP_HEADROOM_PER_NODE: 25GB
      MAX_HEAP_SIZE: 51200M # 51200 == 50 GiB
      LIVENESS_PROBE_PERIOD: 120
      LIVENESS_PROBE_TIMEOUT: 120

- name: cost-report-emailer-config
  path: /saas-templates/configmap.yml
  url: https://gitlab.cee.redhat.com/cost-management/cost-report-emailer-config
  targets:
  - namespace:
      $ref: /services/insights/ephemeral/namespaces/ephemeral-base.yml
    disable: true # tells app-sre to not actually run the deploy job for this target
    ref: internal # altered by bonfire
  - namespace:
      $ref: /services/insights/hccm/namespaces/stage-hccm-stage.yml
    ref: main

- name: koku-report-emailer
  # repo deploy file: https://github.com/project-koku/koku-report-emailer/blob/main/deploy/clowdapp.yaml
  # container image: quay.io/cloudservices/koku-report-emailer
  # container repo:  https://quay.io/repository/cloudservices/koku-report-emailer
  path: /deploy/clowdapp.yaml
  url: https://github.com/project-koku/koku-report-emailer
  targets:
  - namespace:
      $ref: /services/insights/ephemeral/namespaces/ephemeral-base.yml
    disable: true # tells app-sre to not actually run the deploy job for this target
    ref: internal # altered by bonfire
  - namespace:
      $ref: /services/insights/hccm/namespaces/stage-hccm-stage.yml
    ref: main
    upstream:
      instance:
        $ref: /dependencies/ci-ext/ci-ext.yml
      name: project-koku-koku-report-emailer-gh-build-main
    parameters:
      EMAIL_SCHEDULE: '0 13 * * 1,3,5'

- name: koku-daily
  # repo deploy file: https://github.com/project-koku/koku-daily/blob/main/deploy/clowdapp.yaml
  # container image: quay.io/cloudservices/koku-daily
  # container repo:  https://quay.io/repository/cloudservices/koku-daily
  path: /deploy/clowdapp.yaml
  url: https://github.com/project-koku/koku-daily
  targets:
  - namespace:
      $ref: /services/insights/hccm/namespaces/stage-hccm-stage.yml
    ref: main
    upstream:
      instance:
        $ref: /dependencies/ci-ext/ci-ext.yml
      name: project-koku-koku-daily-gh-build-main
    parameters:
      PROMETHEUS_PUSH_GATEWAY: ${PROMETHEUS_PUSHGATEWAY}
      REPLICAS: 1
      APP_URL_PREFIX: /api/cost-management/v1/koku-daily/
      CPU_REQUEST: 125m
      CPU_LIMIT: 250m
      MEMORY_REQUEST: 250Mi
      MEMORY_LIMIT: 500Mi
      EMAIL_GROUPS: {"engineering": "cost-mgmt-metrics-eng@redhat.com", "marketing": "cost-mgmt-metrics-mkt@redhat.com"}
      S3_BUCKET_NAME: hccm-stage-s3
  - namespace:
      $ref: /services/insights/hccm/namespaces/hccm-prod.yml
    ref: defb97d1c37bf27775649cf6f19a354c672e1731
    parameters:
      PROMETHEUS_PUSH_GATEWAY: ${PROMETHEUS_PUSHGATEWAY}
      REPLICAS: 1
      APP_URL_PREFIX: /api/cost-management/v1/koku-daily/
      CPU_REQUEST: 100m
      CPU_LIMIT: 250m
      MEMORY_REQUEST: 500Mi
      MEMORY_LIMIT: 1Gi
      EMAIL_GROUPS: {"engineering": "cost-mgmt-metrics-eng@redhat.com", "marketing": "cost-mgmt-metrics-mkt@redhat.com"}
      EMAIL_SCHEDULE: '0 17 * * *'
      S3_BUCKET_NAME: hccm-prod-s3
      S3_SCHEDULE: "0 19 * * *"
      WEEKLY_REPORT_SCHEDULED_DAY: "3"

- name: nise-populator
  # repo deploy file: https://github.com/project-koku/nise-populator/blob/main/deploy/clowdapp.yaml
  # container image: quay.io/cloudservices/nise-populator
  # container repo:  https://quay.io/repository/cloudservices/nise-populator
  path: /deploy/clowdapp.yaml
  url: https://github.com/project-koku/nise-populator
  targets:
  - namespace:
      $ref: /services/insights/hccm/namespaces/stage-hccm-stage.yml
    ref: main
    upstream:
      instance:
        $ref: /dependencies/ci-ext/ci-ext.yml
      name: project-koku-nise-populator-gh-build-main
    parameters:
      CPU_REQUEST: 250m
      CPU_LIMIT: 500m
      MEMORY_REQUEST: 1Gi
      MEMORY_LIMIT: 2Gi
  - namespace:
      $ref: /services/insights/hccm/namespaces/hccm-prod.yml
    ref: cccc446e9ef6ddf3b4b594ee3983fb74fead1fea
    parameters:
      CPU_REQUEST: 250m
      CPU_LIMIT: 500m
      POPULATE_SCHEDULE: "0 11 * * *"
      POPULATE_SOURCES: "ocp"

- name: nise-populator-hcs
  # repo deploy file: https://github.com/project-koku/nise-populator/blob/main/deploy/clowdapp.yaml
  # container image: quay.io/cloudservices/nise-populator
  # container repo:  https://quay.io/repository/cloudservices/nise-populator
  path: /deploy/clowdapp.yaml
  url: https://github.com/project-koku/nise-populator
  targets:
  - namespace:
      $ref: /services/insights/hccm/namespaces/stage-hccm-stage.yml
    ref: main
    upstream:
      instance:
        $ref: /dependencies/ci-ext/ci-ext.yml
      name: project-koku-nise-populator-gh-build-main
    parameters:
      CPU_REQUEST: 250m
      CPU_LIMIT: 500m
      MEMORY_REQUEST: 1Gi
      MEMORY_LIMIT: 2Gi
      POPULATE_SCHEDULE: "0 17 * * *"
      SECRET_NAME: nise-populator-hcs-secret
      NAME: nise-populator-hcs
      POPULATE_SOURCES: 'AWS,Azure,GCP,OCI'

- name: parquet-compactor
  # repo deploy file: https://github.com/project-koku/parquet-compactor/blob/main/deploy/clowdapp.yaml
  # container image: quay.io/cloudservices/parquet-compactor
  # container repo:  https://quay.io/repository/cloudservices/parquet-compactor
  path: /deploy/clowdapp.yaml
  url: https://github.com/project-koku/parquet-compactor
  targets:
  - namespace:
      $ref: /services/insights/hccm/namespaces/stage-hccm-stage.yml
    ref: main
    upstream:
      instance:
        $ref: /dependencies/ci-ext/ci-ext.yml
      name: project-koku-parquet-compactor-gh-build-main
    parameters:
      S3_BUCKET_NAME: hccm-stage-s3
      POPULATE_SCHEDULE: "0 13 * * *"
      MEMORY_REQUEST: 8Gi
      MEMORY_LIMIT: 14Gi
  - namespace:
      $ref: /services/insights/hccm/namespaces/hccm-prod.yml
    ref: d43b90d5d6e6d5d0705e30b7448f7442fb8e422f
    parameters:
      S3_BUCKET_NAME: hccm-prod-s3
      POPULATE_SCHEDULE: "0 14 * * 1,4"
      MEMORY_REQUEST: 16Gi
      MEMORY_LIMIT: 20Gi
      CPU_LIMIT: 2

- name: hccm-frontend
  # repo deploy file: https://github.com/project-koku/koku-ui/blob/main/deploy/frontend.yaml
  # container image: quay.io/cloudservices/....... TBD
  # container repo:  https://quay.io/repository/cloudservices/....... TBD
  path: /deploy/frontend.yaml
  url: https://github.com/project-koku/koku-ui
  targets:
  - namespace:
      $ref: /services/insights/ephemeral/namespaces/ephemeral-base.yml
    disable: true  # do not create an app-sre deploy job for ephemeral namespace
    ref: internal  # populated by bonfire
    # Stage Stable Deployment
  - namespace:
      $ref: /services/insights/frontend-operator/namespaces/stage-frontends.yml
    ref: 1139ca95fe4fd14f4eb3c0d064e9eb2aecb4c3f7
    parameters:
      ENV_NAME: "frontends"
      IMAGE: "quay.io/cloudservices/hccm-frontend"
    # Stage Beta Deployment
  - namespace:
      $ref: /services/insights/frontend-operator/namespaces/stage-beta-frontends.yml
    ref: main
    image:
      org:
        $ref: /dependencies/quay/cloudservices.yml
      name: hccm-frontend
    parameters:
      ENV_NAME: "frontends-beta"
      IMAGE: "quay.io/cloudservices/hccm-frontend"
    # Prod Stable Deployment
  - namespace:
      $ref: /services/insights/frontend-operator/namespaces/prod-frontends.yml
    ref: b0f98ad4baf9b484c67f0e993ada420668bfe54c
    parameters:
      ENV_NAME: "frontends"
      IMAGE: "quay.io/cloudservices/hccm-frontend"
    # Prod Beta Deployment
  - namespace:
      $ref: /services/insights/frontend-operator/namespaces/prod-beta-frontends.yml
    ref: ef481f63f39f7a800fe9de639f9e9f252047b73c
    parameters:
      ENV_NAME: "frontends-beta"
      IMAGE: "quay.io/cloudservices/hccm-frontend"

- name: cost-management-dashboards
  # dashboards directory: https://github.com/project-koku/koku/tree/main/dashboards
  url: https://github.com/project-koku/koku
  path: /dashboards
  provider: directory
  targets:
    - namespace:
        $ref: /services/observability/namespaces/app-sre-observability-stage-int.yml
      ref: main

    - namespace:
        $ref: /services/observability/namespaces/app-sre-observability-production-int.yml
      ref: a025da861ebf646c2253f4fcaf10f3d5214d5c16

