---
$schema: /app-sre/slo-document-1.yml

labels:
  service: ccx-data-pipeline

name: ccx-data-pipeline

app:
  $ref: /services/insights/ccx-data-pipeline/app.yml

namespaces:
- $ref: /services/insights/ccx-data-pipeline/namespaces/ccx-data-pipeline-prod.yml

slos:
- name: Archive Handler Kafka lag is too high
  dashboard: https://grafana.app-sre.devshift.net/d/ccxprocessingslo/ccx-processing-slo?orgId=1&viewPanel=6
  SLIType: throughput
  SLISpecification: Kafka lag for received archives from ingress
  SLOTarget: 95
  SLOTargetUnit: percent_0_1
  SLOParameters:
    window: 1d
  SLODetails: https://gitlab.cee.redhat.com/ccx/ccx-docs/-/blob/master/source/customer/sops/cdp_kafka_lag_gt_100.rst
  expr: |
    sum(kafka_consumergroup_group_lag{topic="platform.upload.announce",group="ccx_data_pipeline_app"}) > 200
  prometheusRules: /observability/prometheusrules/insights-ccx-processing-slo.prometheusrules.yaml

- name: DB Writer Kafka lag is too high
  dashboard: https://grafana.app-sre.devshift.net/d/ccxprocessingslo/ccx-processing-slo?orgId=1&viewPanel=6
  SLIType: throughput
  SLISpecification: The db-writer Kafka lag is too high
  SLOTarget: 95
  SLOTargetUnit: percent_0_1
  SLOParameters:
    window: 1d
  SLODetails: https://gitlab.cee.redhat.com/ccx/ccx-docs/-/blob/master/source/customer/sops/irdw_kafka_lag_gt_100.rst
  expr: |
    sum(kafka_consumergroup_group_lag{topic="ccx.ocp.results", group="ccx_data_pipeline_app"}) > 100
  prometheusRules: /observability/prometheusrules/insights-ccx-processing-slo.prometheusrules.yaml

- name: Archive processing is taking too long
  dashboard: https://grafana.app-sre.devshift.net/d/ccxprocessingslo/ccx-processing-slo?orgId=1&viewPanel=14
  SLIType: latency
  SLISpecification: The processing time of ccx-data-pipeline and db-writer is taking too long
  SLOTarget: 95
  SLOTargetUnit: percent_0_1
  SLOParameters:
    window: 1d
  SLODetails: https://gitlab.cee.redhat.com/ccx/ccx-docs/-/blob/master/source/customer/sops/archives_are_not_processed.rst
  expr: |
    (((((  
      sum(
          increase(successful_messages_processing_time_sum{namespace="ccx-data-pipeline-prod", service="ccx-insights-results-db-writer-prometheus-exporter"}[1m])
      ) /  
      sum(   
          increase(successful_messages_processing_time_count{namespace="ccx-data-pipeline-prod", service="ccx-insights-results-db-writer-prometheus-exporter"}[1m])
      )
    ) < 5) + 
    ((
        sum(    
            increase(ccx_process_duration_seconds_count{namespace="ccx-data-pipeline-prod", service="ccx-data-pipeline-prometheus-exporter"}[1m])  
        ) /  
        sum(   
            increase(ccx_process_duration_seconds_count{namespace="ccx-data-pipeline-prod", service="ccx-data-pipeline-prometheus-exporter"}[1m])
        )
    ) < 5))
    /
    ((  
        sum(
            increase(successful_messages_processing_time_sum{namespace="ccx-data-pipeline-prod", service="ccx-insights-results-db-writer-prometheus-exporter"}[1m])
        ) /  
        sum(   
            increase(successful_messages_processing_time_count{namespace="ccx-data-pipeline-prod", service="ccx-insights-results-db-writer-prometheus-exporter"}[1m])
        )
    )  + 
    (
        sum(    
            increase(ccx_process_duration_seconds_count{namespace="ccx-data-pipeline-stage", service="ccx-data-pipeline-prometheus-exporter"}[1m])  
        ) /  
        sum(   
            increase(ccx_process_duration_seconds_count{namespace="ccx-data-pipeline-stage", service="ccx-data-pipeline-prometheus-exporter"}[1m])
        )
    ))) OR on() vector(0)) < 0.95
  prometheusRules: /observability/prometheusrules/insights-ccx-processing-slo.prometheusrules.yaml

- name: API responses are taking too long
  dashboard: https://grafana.app-sre.devshift.net/d/ccxprocessingslo/ccx-processing-slo?orgId=1&viewPanel=8
  SLIType: latency
  SLISpecification: The response time of smart-proxy is taking too long
  SLOTarget: 95
  SLOTargetUnit: percent_0_1
  SLOParameters:
    window: 1d
  SLODetails: https://gitlab.cee.redhat.com/ccx/ccx-docs/-/blob/master/source/customer/sops/rest_api_gt_1_sec.rst
  expr: |
    (( count ( rate(api_endpoints_response_time_sum{namespace="ccx-data-pipeline-prod", service="ccx-smart-proxy"}[5m]) < 0.5 ) 
    /
    count(rate(api_endpoints_response_time_sum{namespace="ccx-data-pipeline-prod", service="ccx-smart-proxy"}[5m])) ) OR on() vector(0)) < 0.95
  prometheusRules: /observability/prometheusrules/insights-ccx-processing-slo.prometheusrules.yaml

- name: API 500 responses are too frequent
  dashboard: https://grafana.app-sre.devshift.net/d/ccxprocessingslo/ccx-processing-slo?orgId=1&viewPanel=12
  SLIType: availability
  SLISpecification: Too much 500 status code returned
  SLOTarget: 95
  SLOTargetUnit: percent_0_1
  SLOParameters:
    window: 1d
  SLODetails: https://gitlab.cee.redhat.com/ccx/ccx-docs/-/blob/master/source/customer/sops/too_much_500.rst
  expr: |
    (sum(rate(api_endpoints_status_codes{namespace="ccx-data-pipeline-prod", service="ccx-smart-proxy", status_code!="500"}[5m]))
    /
    sum(rate(api_endpoints_status_codes{namespace="ccx-data-pipeline-prod", service="ccx-smart-proxy"}[5m]))) < 0.95
  prometheusRules: /observability/prometheusrules/insights-ccx-processing-slo.prometheusrules.yaml
