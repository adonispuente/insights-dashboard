---
$schema: /openshift/prometheus-rule-1.yml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  labels:
    prometheus: app-sre
    role: alert-rules
  name: hive-stage-{{{shard_name}}}
spec:
  groups:
  - name: hive-stage-{{{shard_name}}}
    rules:
    - alert: HiveControllersDown - stage - {{{shard_name}}}
      annotations:
        message: "No targets found for hive-controllers in namespace {{ $labels.namespace }}. hive-controllers is down. <!subteam^SLRCTERUZ>"
        runbook: "https://github.com/openshift/hive-sops/blob/master/sop/HiveControllerDown.md"
        dashboard: "https://grafana.app-sre.devshift.net/d/hivemetrics/hive-metrics?orgId=1&var-datasource={{{grafana_datasource}}}&var-instance=hive-controllers-{{{shard_name}}}"
      expr: |
        absent(up{job="hive-controllers"} == 1)
      for: 10m
      labels:
        service: hive
        severity: high
    - alert: HiveClusterSyncDown - stage - {{{shard_name}}}
      annotations:
        message: "No targets found for hive-clustersync in namespace {{ $labels.namespace }}. hive-clustersync is down. <!subteam^SLRCTERUZ>"
        runbook: "https://github.com/openshift/hive-sops/blob/master/sop/HiveControllerDown.md"
        dashboard: "https://grafana.app-sre.devshift.net/d/hivemetrics/hive-metrics?orgId=1&var-datasource={{{grafana_datasource}}}&var-instance=hive-controllers-{{{shard_name}}}"
      expr: |
        absent(up{job="hive-clustersync"} == 1)
      for: 5m
      labels:
        service: hive
        severity: high
    - alert: HiveOperatorDown - stage - {{{shard_name}}}
      annotations:
        message: "No targets found for hive-operator in namespace {{ $labels.namespace }}. hive-operator is down. <!subteam^SLRCTERUZ>"
        runbook: "https://github.com/openshift/hive-sops/blob/master/sop/HiveOperatorDown.md"
        dashboard: "https://grafana.app-sre.devshift.net/d/hivemetrics/hive-metrics?orgId=1&var-datasource={{{grafana_datasource}}}&var-instance=hive-controllers-{{{shard_name}}}"
      expr: |
        absent(up{job="openshift-customer-monitoring/hive-operator"} == 1)
      for: 5m
      labels:
        service: hive
        severity: high
    - alert: HiveDeploymentFailed - stage - {{{shard_name}}}
      annotations:
        message: "hive deployment has failed. Condition/Reason: {{ $labels.condition }} / {{ $labels.reason }}. <!subteam^SLRCTERUZ>"
        runbook: "https://github.com/openshift/hive-sops/blob/master/sop/HiveDeploymentFailed.md"
        dashboard: "https://grafana.app-sre.devshift.net/d/hivemetrics/hive-metrics?orgId=1&var-datasource={{{grafana_datasource}}}&var-instance=hive-controllers-{{{shard_name}}}"
      expr: |
        absent(hive_hiveconfig_conditions{condition="Ready"} == 1)
      for: 5m
      labels:
        service: hive
        severity: high    
    - alert: InstallJobDelayHigh - stage - {{{shard_name}}}
      annotations:
        message: "Time to start an install job is taking greater than 5 minutes"
        runbook: "https://github.com/openshift/hive-sops/blob/master/sop/InstallJobDelayHigh.md"
        dashboard: "https://grafana.app-sre.devshift.net/d/hivemetrics/hive-metrics?orgId=1&var-datasource={{{grafana_datasource}}}&var-instance=hive-controllers-{{{shard_name}}}"
      expr: |
        rate(hive_cluster_deployment_install_job_delay_seconds_sum{job="hive-controllers"}[6h])
        /
        rate(hive_cluster_deployment_install_job_delay_seconds_count{job="hive-controllers"}[6h]) > 300
      for: 10m
      labels:
        service: hive
        severity: medium
    - alert: ControllerErrorsHigh - stage - {{{shard_name}}}
      annotations:
        message: "{{ $labels.controller }} controller is reporting a high error rate: {{ $value }}/s"
        runbook: "https://github.com/openshift/hive-sops/blob/master/sop/ControllerErrorsHigh.md"
        dashboard: "https://grafana.app-sre.devshift.net/d/hivemetrics/hive-metrics?orgId=1&var-datasource={{{grafana_datasource}}}&var-instance=hive-controllers-{{{shard_name}}}"
      expr: |
        rate(controller_runtime_reconcile_errors_total{job="hive-controllers"}[15m]) > 1
      for: 10m
      labels:
        service: hive
        severity: high
    - alert: LocalKubeClientRequestsHigh - POST requests - stage - {{{shard_name}}}
      annotations:
        message: "detected {{ $value }} {{ $labels.resource }} local POST API requests per second from controller {{ $labels.controller }}"
        runbook: "https://github.com/openshift/hive-sops/blob/master/sop/KubeClientRequestsHigh.md"
        dashboard: "https://grafana.app-sre.devshift.net/d/hivemetrics/hive-metrics?orgId=1&var-datasource={{{grafana_datasource}}}&var-instance=hive-controllers-{{{shard_name}}}"
      expr: |
        rate(hive_kube_client_requests_total{job="hive-controllers",remote="false",method="POST"}[5m]) > 15
      for: 1m
      labels:
        service: hive
        severity: high
    - alert: LocalKubeClientRequestsHigh - non-POST requests - stage - {{{shard_name}}}
      annotations:
        message: "detected {{ $value }} {{ $labels.resource }} local non-POST API requests per second from controller {{ $labels.controller }}"
        runbook: "https://github.com/openshift/hive-sops/blob/master/sop/KubeClientRequestsHigh.md"
        dashboard: "https://grafana.app-sre.devshift.net/d/hivemetrics/hive-metrics?orgId=1&var-datasource={{{grafana_datasource}}}&var-instance=hive-controllers-{{{shard_name}}}"
      expr: |
        rate(hive_kube_client_requests_total{job="hive-controllers",remote="false",method!~"POST"}[5m]) > 15
      for: 1m
      labels:
        service: hive
        severity: medium
    - alert: ClusterProvisioningDelaySREP - stage - {{{shard_name}}}
      annotations:
        message: "cluster {{ $labels.cluster_deployment }} in namespace {{ $labels.exported_namespace }} provisioning taking over 2 hours. Condition/Reason: {{ $labels.condition }} / {{ $labels.reason }}."
        runbook: "https://github.com/openshift/hive-sops/blob/master/sop/ClusterProvisioningDelay.md"
        dashboard: "https://grafana.app-sre.devshift.net/d/hivemetrics/hive-metrics?orgId=1&var-datasource={{{grafana_datasource}}}&var-instance=hive-controllers-{{{shard_name}}}"
      expr: |
        (2 < (max without(instance, pod, cluster_type) (hive_cluster_deployment_provision_underway_seconds{job="hive-controllers",reason!~"AWSAPIRateLimitExceeded|AWSEC2QuotaExceeded|AWSVPCLimitExceeded|S3BucketsLimitExceeded|InvalidCredentials|EIPAddressLimitExceeded|NoWorkerNodes|AWSNATGatewayLimitExceeded|InvalidInstallConfigSubnet|PendingVerification|GCPInstanceTypeNotFound|GCPPreconditionFailed|GCPQuotaSSDTotalGBExceeded|GCPComputeQuotaExceeded|GCPServiceAccountQuotaExceeded|InvalidAWSTags|MissingPublicSubnetForZone|PrivateSubnetInMultipleZones|ErrorDeletingIAMRole|AWSSubnetDoesNotExist|AWSInsufficientPermissions|VcpuLimitExceeded|UserInitiatedShutdown|LoadBalancerLimitExceeded|AWSAccessDeniedSLR|ProxyTimeout|ProxyInvalidCABundle|ErrorCreatingNetworkLoadBalancer|NATGatewayFailed"}) / 3600) < 168)
        or
        (2 < (max without(instance, pod, cluster_type) (max_over_time(hive_cluster_deployment_provision_underway_seconds{job="hive-controllers",reason!~"AWSAPIRateLimitExceeded|AWSEC2QuotaExceeded|AWSVPCLimitExceeded|S3BucketsLimitExceeded|InvalidCredentials|EIPAddressLimitExceeded|NoWorkerNodes|AWSNATGatewayLimitExceeded|InvalidInstallConfigSubnet|PendingVerification|GCPInstanceTypeNotFound|GCPPreconditionFailed|GCPQuotaSSDTotalGBExceeded|GCPComputeQuotaExceeded|GCPServiceAccountQuotaExceeded|InvalidAWSTags|MissingPublicSubnetForZone|PrivateSubnetInMultipleZones|ErrorDeletingIAMRole|AWSSubnetDoesNotExist|AWSInsufficientPermissions|VcpuLimitExceeded|UserInitiatedShutdown|LoadBalancerLimitExceeded|AWSAccessDeniedSLR|ProxyTimeout|ProxyInvalidCABundle|ErrorCreatingNetworkLoadBalancer|NATGatewayFailed"}[12h])) / 3600) < 168) * on() group_left absent(up{job="hive-controllers"} == 1)
      for: 5m
      labels:
        service: hive
        severity: medium
        team: srep
    - alert: SelectorSyncsetApplyFailures - stage - {{{shard_name}}}
      annotations:
        message: "The SelectorSyncset {{ $labels.name }} has more than 1 unapplied instances for 15 minutes"
        runbook: "https://github.com/openshift/ops-sop/tree/master/v4/alerts/SelectorSyncsetApplyFailures.md"
        dashboard: "https://grafana.app-sre.devshift.net/d/hivemetrics/hive-metrics?orgId=1&var-datasource={{{grafana_datasource}}}&var-instance=hive-controllers-{{{shard_name}}}"
      expr: |
        hive_selectorsyncset_clusters_unapplied_total{job="hive-controllers"} > 0
      for: 15m
      labels:
        service: hive
        severity: medium
        team: srep
    - alert: AWSAccountOperator AccountPool Depletion - {{{shard_name}}}
      annotations:
        message: "AWS Account Operator's AccountPool is nearing depletion."
        runbook: "https://github.com/openshift/ops-sop/blob/master/v4/alerts/AWSAccountOperatorAccountPoolDepleted.md"
        dashboard: "https://grafana.app-sre.devshift.net/explore?orgId=1&left=%5B%22now-7d%22,%22now%22,%22{{{shard_name}}}-prometheus%22,%7B%22expr%22:%22SUM(aws_account_operator_available_non_ccs_accounts%20%2B%20aws_account_operator_accounts_progressing)%20without%20(pod,instance)%5Cn%5Cn%22,%22requestId%22:%22Q-8ea2341f-51e8-4e34-aa3a-6469db5fcf6d-0A%22,%22format%22:%22time_series%22,%22instant%22:false,%22refId%22:%22A%22,%22exemplar%22:true,%22range%22:true%7D%5D"
      expr: |
        aws_account_operator_available_non_ccs_accounts + aws_account_operator_accounts_progressing < (aws_account_operator_account_pool_size / 10)
      labels:
        service: srep
        severity: high
        team: srep
    - alert: AWSAccountOperator AccountClaim Pending - stage - {{{shard_name}}}
      annotations:
        message: "AWS Account Operator AccountClaim pending for over 10 minutes."
        runbook: "https://github.com/openshift/ops-sop/blob/master/v4/howto/aws/aws-account-troubleshooting.md"
        dashboard: "https://grafana.app-sre.devshift.net/explore?orgId=1&left=%7B%22datasource%22:%22{{{shard_name}}}-prometheus%22,%22queries%22:%5B%7B%22refId%22:%22A%22,%22expr%22:%22sum(rate(aws_account_operator_account_claim_pending_duration_seconds_bucket%7Bname%3D%5C%22aws-account-operator%5C%22,le%3D%5C%22%2BInf%5C%22%7D%5B10m%5D))%20%3E%20sum(rate(aws_account_operator_account_claim_pending_duration_seconds_bucket%7Bname%3D%5C%22aws-account-operator%5C%22,le%3D%5C%22600%5C%22%7D%5B10m%5D))%20or%20sum(rate(aws_account_operator_account_claim_ccs_pending_duration_seconds_bucket%7Bname%3D%5C%22aws-account-operator%5C%22,le%3D%5C%22%2BInf%5C%22%7D%5B10m%5D))%20%3E%20sum(rate(aws_account_operator_account_claim_ccs_pending_duration_seconds_bucket%7Bname%3D%5C%22aws-account-operator%5C%22,le%3D%5C%22600%5C%22%7D%5B10m%5D))%22%7D%5D,%22range%22:%7B%22from%22:%22now-1h%22,%22to%22:%22now%22%7D%7D"
      expr: |
        sum(rate(aws_account_operator_account_claim_pending_duration_seconds_bucket{name="aws-account-operator",le="+Inf"}[10m])) > sum(rate(aws_account_operator_account_claim_pending_duration_seconds_bucket{name="aws-account-operator",le="600"}[10m])) or sum(rate(aws_account_operator_account_claim_ccs_pending_duration_seconds_bucket{name="aws-account-operator",le="+Inf"}[10m])) > sum(rate(aws_account_operator_account_claim_ccs_pending_duration_seconds_bucket{name="aws-account-operator",le="600"}[10m]))
      labels:
        service: srep
        severity: high
        team: srep
    - alert: AWSAccountOperator Target Down - stage - {{{shard_name}}}
      annotations:
        message: "No targets found for AWS Account Operator on hive-{{{shard_name}}}"
        runbook: "https://github.com/openshift/hive-sops/blob/master/sop/SREOperators.md"
        dashboard: "https://grafana.app-sre.devshift.net/d/hivemetrics/hive-metrics?orgId=1&var-datasource={{{grafana_datasource}}}&var-instance=hive-controllers-{{{shard_name}}}"
      expr: |
        absent(up{job="aws-account-operator"} == 1)
      for: 15m
      labels:
        severity: high
        service: srep
    - alert: CertmanOperator Target Down - stage - {{{shard_name}}}
      annotations:
        message: "No targets found for Certman Operator on hive-{{{shard_name}}}"
        runbook: "https://github.com/openshift/hive-sops/blob/master/sop/SREOperators.md"
        dashboard: "https://grafana.app-sre.devshift.net/d/hivemetrics/hive-metrics?orgId=1&var-datasource={{{grafana_datasource}}}&var-instance=hive-controllers-{{{shard_name}}}"
      expr: |
        absent(up{job="certman-operator"} == 1)
      for: 15m
      labels:
        severity: high
        service: srep
    - alert: DeadMansSnitchOperator Target Down - stage - {{{shard_name}}}
      annotations:
        message: "No targets found for Dead Mans Snitch Operator on hive-{{{shard_name}}}"
        runbook: "https://github.com/openshift/hive-sops/blob/master/sop/SREOperators.md"
        dashboard: "https://grafana.app-sre.devshift.net/d/hivemetrics/hive-metrics?orgId=1&var-datasource={{{grafana_datasource}}}&var-instance=hive-controllers-{{{shard_name}}}"
      expr: |
        absent(up{job="deadmanssnitch-operator"} == 1)
      for: 15m
      labels:
        severity: high
        service: srep
    - alert: PagerDutyOperator Target Down - stage - {{{shard_name}}}
      annotations:
        message: "No targets found for PagerDuty Operator on hive-{{{shard_name}}}"
        runbook: "https://github.com/openshift/hive-sops/blob/master/sop/SREOperators.md"
        dashboard: "https://grafana.app-sre.devshift.net/d/hivemetrics/hive-metrics?orgId=1&var-datasource={{{grafana_datasource}}}&var-instance=hive-controllers-{{{shard_name}}}"
      expr: |
        absent(up{job="pagerduty-operator"} == 1)
      for: 15m
      labels:
        severity: high
        service: srep
    - alert: AWS Account Shredder Crash Looping - stage - {{{shard_name}}}
      annotations:
        message: "AWS Account Shredder is crash looping more than 5 times in 15 minutes on hive-{{{shard_name}}}"
        runbook: "https://github.com/openshift/ops-sop/blob/master/v4/alerts/AwsAccountShredderCrashLooping.md"
      expr: |
        sum(rate(kube_pod_container_status_restarts_total{namespace="aws-account-shredder"}[15m])) > 5
      labels:
        severity: medium
        service: srep
    - alert: CertmanCertExpires5Days - stage - {{{shard_name}}}
      annotations:
        message: "certificate {{ $labels.cn }} from hive-{{{shard_name}}} expires in 5 days and has not renewed"
        runbook: "https://github.com/openshift/ops-sop/blob/master/v4/alerts/CertmanCertExpires5Days.md"
      expr: |
        certman_operator_certificate_valid_duration_days <= 5
      labels:
        severity: critical
        service: srep
