---
$schema: /openshift/prometheus-rule-1.yml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  labels:
    prometheus: app-sre
    role: alert-rules
  name: hive-production-{{{shard_name}}}
spec:
  groups:
  - name: hive-production-{{{shard_name}}}
    rules:
    # Hive team + AppSRE care about these:
    - alert: HiveControllersDown - production - {{{shard_name}}}
      annotations:
        message: "No targets found for hive-controllers in namespace {{ $labels.namespace }}. hive-controllers is down."
        runbook: "https://github.com/openshift/hive-sops/blob/master/sop"
        dashboard: "https://grafana.app-sre.devshift.net/d/hivemetrics/hive-metrics?orgId=1&var-datasource={{{grafana_datasource}}}&var-instance=hive-controllers-{{{shard_name}}}"
      expr: |
        absent(up{job="hive-controllers"} == 1)
      for: 5m
      labels:
        service: hive
        severity: critical
        team: appsre
    - alert: HiveClusterSyncDown - production - {{{shard_name}}}
      annotations:
        message: "No targets found for hive-clustersync in namespace {{ $labels.namespace }}. hive-clustersync is down."
        runbook: "https://github.com/openshift/hive-sops/blob/master/sop"
        dashboard: "https://grafana.app-sre.devshift.net/d/hivemetrics/hive-metrics?orgId=1&var-datasource={{{grafana_datasource}}}&var-instance=hive-controllers-{{{shard_name}}}"
      expr: |
        absent(up{job="hive-clustersync"} == 1)
      for: 5m
      labels:
        service: hive
        severity: critical
        team: appsre
    - alert: HiveOperatorDown - production - {{{shard_name}}}
      annotations:
        message: "No targets found for hive-operator in namespace {{ $labels.namespace }}. hive-operator is down."
        runbook: "https://github.com/openshift/hive-sops/blob/master/sop"
        dashboard: "https://grafana.app-sre.devshift.net/d/hivemetrics/hive-metrics?orgId=1&var-datasource={{{grafana_datasource}}}&var-instance=hive-controllers-{{{shard_name}}}"
      expr: |
        absent(up{job="openshift-customer-monitoring/hive-operator"} == 1)
      for: 5m
      labels:
        service: hive
        severity: critical
        team: appsre
    - alert: HiveDeploymentFailed - production - {{{shard_name}}}
      annotations:
        message: "hive deployment has failed. Condition/Reason: {{ $labels.condition }} / {{ $labels.reason }}."
        runbook: "https://github.com/openshift/hive-sops/blob/master/sop"
        dashboard: "https://grafana.app-sre.devshift.net/d/hivemetrics/hive-metrics?orgId=1&var-datasource={{{grafana_datasource}}}&var-instance=hive-controllers-{{{shard_name}}}"
      expr: |
        hive_hiveconfig_conditions{condition="Ready"} == 0
      for: 5m
      labels:
        service: hive
        severity: critical
        team: appsre  
    - alert: ClusterServiceVersionStuck - production - {{{shard_name}}}
      annotations:
        message: "ClusterServiceVersion {{ $labels.name }} stuck in abnormal state: {{ $labels.reason }}"
        runbook: "https://gitlab.cee.redhat.com/service/app-interface/-/blob/master/docs/hive/sop/hive-olm-dance.md"
        dashboard: "https://grafana.app-sre.devshift.net/d/hivemetrics/hive-metrics?orgId=1&var-datasource={{{grafana_datasource}}}&var-instance=hive-controllers-{{{shard_name}}}"
      expr: |
        csv_abnormal{exported_namespace="hive"}
      for: 10m
      labels:
        service: hive
        severity: medium
    - alert: InstallJobDelayHigh - production - {{{shard_name}}}
      annotations:
        message: "Time to start an install job is taking greater than 5 minutes"
        runbook: "https://github.com/openshift/hive-sops/blob/master/sop/InstallJobDelayHigh.md"
        dashboard: "https://grafana.app-sre.devshift.net/d/hivemetrics/hive-metrics?orgId=1&var-datasource={{{grafana_datasource}}}&var-instance=hive-controllers-{{{shard_name}}}"
      expr: |
        rate(hive_cluster_deployment_install_job_delay_seconds_sum{job="hive-controllers"}[6h])
        /
        rate(hive_cluster_deployment_install_job_delay_seconds_count{job="hive-controllers"}[6h]) > 300
      for: 10m
      labels:
        service: hive
        severity: high
    - alert: ControllerErrorsHigh - production - {{{shard_name}}}
      annotations:
        message: "{{ $labels.controller }} controller is reporting a high error rate: {{ $value }}/s"
        runbook: "https://github.com/openshift/hive-sops/blob/master/sop"
        dashboard: "https://grafana.app-sre.devshift.net/d/hivemetrics/hive-metrics?orgId=1&var-datasource={{{grafana_datasource}}}&var-instance=hive-controllers-{{{shard_name}}}"
      expr: |
        rate(controller_runtime_reconcile_errors_total{job="hive-controllers"}[15m]) > 1
      for: 10m
      labels:
        service: hive
        severity: critical
        team: appsre
    - alert: LocalKubeClientRequestsHigh - POST requests - production - {{{shard_name}}}
      annotations:
        message: "detected {{ $value }} {{ $labels.resource }} local POST API requests per second from controller {{ $labels.controller }}"
        runbook: "https://github.com/openshift/hive-sops/blob/master/sop/KubeClientRequestsHigh.md"
        dashboard: "https://grafana.app-sre.devshift.net/d/hivemetrics/hive-metrics?orgId=1&var-datasource={{{grafana_datasource}}}&var-instance=hive-controllers-{{{shard_name}}}"
      expr: |
        rate(hive_kube_client_requests_total{job="hive-controllers",remote="false",method="POST"}[5m]) > 15
      for: 1m
      labels:
        service: hive
        severity: critical
        team: appsre
    - alert: LocalKubeClientRequestsHigh - non-POST requests - production - {{{shard_name}}}
      annotations:
        message: "detected {{ $value }} {{ $labels.resource }} local non-POST API requests per second from controller {{ $labels.controller }}"
        runbook: "https://github.com/openshift/hive-sops/blob/master/sop/KubeClientRequestsHigh.md"
        dashboard: "https://grafana.app-sre.devshift.net/d/hivemetrics/hive-metrics?orgId=1&var-datasource={{{grafana_datasource}}}&var-instance=hive-controllers-{{{shard_name}}}"
      expr: |
        rate(hive_kube_client_requests_total{job="hive-controllers",remote="false",method!~"POST"}[5m]) > 15
      for: 1m
      labels:
        service: hive
        severity: medium
        team: appsre
    - alert: ClusterProvisioningDelayHive - production - {{{shard_name}}}
      annotations:
        message: "cluster {{ $labels.cluster_deployment }} in namespace {{ $labels.exported_namespace }} provisioning taking over 2 hours. Condition/Reason: {{ $labels.condition }} / {{ $labels.reason }}."
        runbook: "https://github.com/openshift/hive-sops/blob/master/sop/ClusterProvisioningDelay.md"
        dashboard: "https://grafana.app-sre.devshift.net/d/hivemetrics/hive-metrics?orgId=1&var-datasource={{{grafana_datasource}}}&var-instance=hive-controllers-{{{shard_name}}}"
      # TODO: for hive team we skip alerts if it's been going over 24h, and if a reason has been auto-detected
      expr: |
        (hive_cluster_deployment_provision_underway_seconds{job="hive-controllers",reason="Unknown"}/3600) > 2
        and
        (hive_cluster_deployment_provision_underway_seconds{job="hive-controllers",reason="Unknown"}/3600) < 24
      for: 5m
      labels:
        service: hive
        severity: medium
        team: hive
    # end hive + AppSRE section

    # SREP cares about the below alerts
    - alert: ClusterProvisioningDelaySREP - production - {{{shard_name}}}
      annotations:
        message: "cluster {{ $labels.cluster_deployment }} in namespace {{ $labels.exported_namespace }} provisioning taking over 2 hours. Condition/Reason: {{ $labels.condition }} / {{ $labels.reason }}. SOP: https://github.com/openshift/hive-sops/blob/master/sop/ClusterProvisioningDelay.md"
        runbook: "https://github.com/openshift/hive-sops/blob/master/sop/ClusterProvisioningDelay.md"
        dashboard: "https://grafana.app-sre.devshift.net/d/hivemetrics/hive-metrics?orgId=1&var-datasource={{{grafana_datasource}}}&var-instance=hive-controllers-{{{shard_name}}}"
      expr: |
        (hive_cluster_deployment_provision_underway_seconds{job="hive-controllers",cluster_type="managed"}/3600) > 2
      for: 5m
      labels:
        service: hive
        severity: medium
        team: srep
    - alert: ClusterProvisioningDelay - production CCS -
      annotations:
        message: "on shard {{ $labels.cluster }} cluster {{ $labels.cluster_deployment }} in namespace {{ $labels.exported_namespace }} provisioning taking over 2 hours"
        runbook: "https://github.com/openshift/hive-sops/blob/master/sop/ClusterProvisioningDelay.md"
        dashboard: "https://grafana.app-sre.devshift.net/d/hivemetrics/hive-metrics?orgId=1&var-datasource={{{grafana_datasource}}}&var-instance=hive-controllers-{{{shard_name}}}"
      expr: |
        (max without (instance,pod) (hive_cluster_deployment_provision_underway_seconds{job="hive-controllers",cluster_type="managed-byoc"} ) /3600) > 2
        and
        ( max without (instance,pod) (hive_cluster_deployment_provision_underway_seconds{job="hive-controllers",cluster_type="managed-byoc"} ) /3600) < 168
      for: 10m
      labels:
        service: hive
        severity: high
        team: srep
    - alert: ClusterDeprovisioningDelay - production - {{{shard_name}}}
      annotations:
        message: "cluster {{ $labels.cluster_deployment }} in namespace {{ $labels.namespace }} deprovision taking over 6 hours"
        runbook: "https://github.com/openshift/hive-sops/blob/master/sop/ClusterDeprovisioningDelay.md"
        dashboard: "https://grafana.app-sre.devshift.net/d/hivemetrics/hive-metrics?orgId=1&var-datasource={{{grafana_datasource}}}&var-instance=hive-controllers-{{{shard_name}}}"
      expr: |
        (hive_cluster_deployment_deprovision_underway_seconds{job="hive-controllers"} / 3600 ) > 6
      for: 10m
      labels:
        severity: medium
        service: hive
        team: srep
    - alert: SelectorSyncsetApplyFailures - production - {{{shard_name}}}
      annotations:
        message: "The SelectorSyncset {{ $labels.name }} has more than 1 unapplied instances for 15 minutes"
        runbook: "https://github.com/openshift/ops-sop/tree/master/v4/alerts/SelectorSyncsetApplyFailures.md"
        dashboard: "https://grafana.app-sre.devshift.net/d/hivemetrics/hive-metrics?orgId=1&var-datasource={{{grafana_datasource}}}&var-instance=hive-controllers-{{{shard_name}}}"
      expr: |
        hive_selectorsyncset_clusters_unapplied_total{job="hive-controllers"} > 0
      for: 15m
      labels:
        service: hive
        severity: medium
        team: srep
    - alert: SyncsetPausedTooLong - production - {{{shard_name}}}
      annotations:
        message: "Cluster {{ $labels.cluster_deployment }} in namespace {{ $labels.exported_namespace }} has paused Hive syncrhonization for longer than 48 hours"
        runbook: "https://github.com/openshift/ops-sop/tree/master/v4/alerts/SyncsetPausedTooLong.md"
        dashboard: "https://grafana.app-sre.devshift.net/d/hivemetrics/hive-metrics?orgId=1&var-datasource={{{grafana_datasource}}}&var-instance=hive-controllers-{{{shard_name}}}"
      expr: |
        hive_cluster_deployment_syncset_paused{cluster_type="managed"} > 0
      for: 48h
      labels:
        service: hive
        severity: medium
        team: srep
    - alert: AWSAccountLimit - production - {{{shard_name}}}
      annotations:
        message: "AWS Account Operator is about to reach account limit"
        runbook: "https://github.com/openshift/hive-sops/blob/master/sop/AWSAccountLimit.md"
        dashboard: "https://grafana.app-sre.devshift.net/d/WPRpa7HWz/aws-account-operator?orgId=1&var-datasource={{{grafana_datasource}}}&var-environment=hive-aws-account-operator-{{{shard_name}}}"
      expr: |
        aws_account_operator_aws_accounts{job="aws-account-operator"} > {{{aws_account_operator_accounts_threshold}}}
      labels:
        service: srep
        severity: high
        team: srep
    - alert: AWSAccountOperator Target Down - production - {{{shard_name}}}
      annotations:
        message: "No targets found for AWS Account Operator on hive-{{{shard_name}}}"
        runbook: "https://github.com/openshift/hive-sops/blob/master/sop/SREOperators.md"
        dashboard: "https://grafana.app-sre.devshift.net/d/hivemetrics/hive-metrics?orgId=1&var-datasource={{{grafana_datasource}}}&var-instance=hive-controllers-{{{shard_name}}}"
      expr: |
        absent(up{job="aws-account-operator"} == 1)
      for: 15m
      labels:
        severity: critical
        service: srep
    - alert: CertmanOperator Target Down - production - {{{shard_name}}}
      annotations:
        message: "No targets found for Certman Operator on hive-{{{shard_name}}}"
        runbook: "https://github.com/openshift/hive-sops/blob/master/sop/SREOperators.md"
        dashboard: "https://grafana.app-sre.devshift.net/d/hivemetrics/hive-metrics?orgId=1&var-datasource={{{grafana_datasource}}}&var-instance=hive-controllers-{{{shard_name}}}"
      expr: |
        absent(up{job="certman-operator"} == 1)
      for: 15m
      labels:
        severity: critical
        service: srep
    - alert: DeadMansSnitchOperator Target Down - production - {{{shard_name}}}
      annotations:
        message: "No targets found for Dead Mans Snitch Operator on hive-{{{shard_name}}}"
        runbook: "https://github.com/openshift/hive-sops/blob/master/sop/SREOperators.md"
        dashboard: "https://grafana.app-sre.devshift.net/d/hivemetrics/hive-metrics?orgId=1&var-datasource={{{grafana_datasource}}}&var-instance=hive-controllers-{{{shard_name}}}"
      expr: |
        absent(up{job="deadmanssnitch-operator"} == 1)
      for: 15m
      labels:
        severity: critical
        service: srep
    - alert: PagerDutyOperator Target Down - production - {{{shard_name}}}
      annotations:
        message: "No targets found for PagerDuty Operator on hive-{{{shard_name}}}"
        runbook: "https://github.com/openshift/hive-sops/blob/master/sop/SREOperators.md"
        dashboard: "https://grafana.app-sre.devshift.net/d/hivemetrics/hive-metrics?orgId=1&var-datasource={{{grafana_datasource}}}&var-instance=hive-controllers-{{{shard_name}}}"
      expr: |
        absent(up{job="pagerduty-operator"} == 1)
      for: 15m
      labels:
        severity: critical
        service: srep
    - alert: LetsEncryptIssuanceRateLimit - devshift.org - {{{shard_name}}}
      annotations:
        message: "Certman Operator is about to reach account limit for issued certificate in the last 7 days - devshift.org domain"
        runbook: "https://github.com/openshift/ops-sop/blob/master/v4/howto/lets-encrypt-rate-limit-adjustment.md"
        dashboard: "https://grafana.app-sre.devshift.net/d/sd-scale/service-delivery-scale?orgId=1"
      expr: |
        certman_operator_certs_in_last_week_devshift_org{job="certman-operator"} > {{{certman_operator_devshift_org_issuance_rate_threshold}}}
      labels:
        service: srep
        severity: high
        team: srep
    - alert: LetsEncryptIssuanceRateLimit - openshiftapps.com - {{{shard_name}}}
      annotations:
        message: "Certman Operator is about to reach account limit for issued certificate in the last 7 days - openshiftapps.com domain"
        runbook: "https://github.com/openshift/ops-sop/blob/master/v4/howto/lets-encrypt-rate-limit-adjustment.md"
        dashboard: "https://grafana.app-sre.devshift.net/d/sd-scale/service-delivery-scale?orgId=1"
      expr: |
        certman_operator_certs_in_last_week_openshift_apps_com{job="certman-operator"} > {{{certman_operator_openshift_apps_com_issuance_rate_threshold}}}
      labels:
        service: srep
        severity: high
        team: srep
    - alert: CertmanCertExpires5Days - {{{shard_name}}}
      annotations:
        message: "certificate {{ $labels.cn }} from hive-{{{shard_name}}} expires in 5 days and has not renewed"
        runbook: "https://github.com/openshift/ops-sop/blob/master/v4/alerts/CertmanCertExpires5Days.md"
      expr: |
        certman_operator_certificate_valid_duration_days <= 5
      labels:
        severity: critical
        service: srep
