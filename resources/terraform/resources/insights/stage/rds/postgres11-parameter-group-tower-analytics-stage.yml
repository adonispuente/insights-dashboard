family: postgres11
description: Parameter Group for PostgreSQL 11
parameters:
- name: log_statement
  value: none
  apply_method: immediate
- name: rds.force_ssl
  value: 0
  apply_method: immediate
- name: autovacuum_max_workers
  value: 4
  apply_method: pending-reboot
- name: autovacuum_vacuum_cost_limit
  value: 2400
  apply_method: immediate
- name: log_min_error_statement
  value: error
  apply_method: immediate
- name: log_min_duration_statement
  value: 4000
  apply_method: immediate
- name: shared_preload_libraries
  value: pg_stat_statements
  apply_method: pending-reboot
- name: pg_stat_statements.max
  value: 1000
  apply_method: pending-reboot
- name: pg_stat_statements.track
  value: TOP
  apply_method: immediate
- name: pg_stat_statements.track_utility
  value: 0
  apply_method: immediate
- name: track_activity_query_size
  value: 2048
  apply_method: pending-reboot

# Partitionwise join/group planning can use significantly more CPU time and memory during planning, the default is off.
# Observe the metrics once we introduce partitions
- name: enable_partitionwise_join
  value: on
  apply_method: pending-reboot
- name: enable_partitionwise_aggregate
  value: on
  apply_method: pending-reboot

# This won't be very effective until we increase the number of worker processes
- name: parallel_tuple_cost
  value: 0.01
  apply_method: pending-reboot

### Params based on pgconfig.org looking at DW (data warehouse)
- name: min_wal_size
  value: 2GB
  apply_method: pending-reboot
- name: max_wal_size
  value: 6GB
  apply_method: pending-reboot
- name: checkpoint_completion_target
  value: 0.9
  apply_method: pending-reboot
- name: wal_buffers
  value: 16MB
  apply_method: pending-reboot
- name: random_page_cost
  value: 1.1
  apply_method: pending-reboot
- name: effective_io_concurrency
  value: 200
  apply_method: pending-reboot

### Tweak these based on total memory, now 16GB using pgconfig.org looking at DW
### Keep on 25% of total memory
- name: shared_buffers
  value: 4GB
  apply_method: pending-reboot
### Keep on 75% of total memory
- name: effective_cache_size
  value: 12GB
  apply_method: immediate
### Keep as 1/16 of total memory take autovacuum_max_worker increase in count
- name: maintenance_work_mem
  value: 2GB
  apply_method: immediate
### Lets increase 41MB per each 8GB of total memory. Also based on number of workers we'll have 
- name: work_mem
  value: 82MB
  apply_method: immediate

### Worker Processes. Tweak these based on number of vcpus now 2
### Same as number of of vcpus
- name: max_worker_processes
  value: 2
  apply_method: pending-reboot
### Same as number of of vcpus / 2
- name: max_parallel_workers_per_gather
  value: 1
  apply_method: pending-reboot
### Same as number of of vcpus
- name: max_parallel_workers
  value: 2
  apply_method: pending-reboot
