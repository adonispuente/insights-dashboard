---
$schema: /app-interface/prometheus-rule-test-1.yml

rule_files:
- /insights-stage/cloudigrade-stage/cloudigrade.prometheusrules.yaml

evaluation_interval: 5m

tests:

  # cloudigrade-stage-5xx-errors
  - interval: 1m
    input_series:
    # 0m  - 9m    0% 5xx, 100% 2xx
    # 10m - 19m   1% 5xx, 99% 2xx
    # 20m - 29m   9% 5xx, 91% 2xx
    # 30m - 39m   15% 5xx, 85% 2xx  <-- we should see alerts start in here
    # 40m - 59m   0% 5xx, 100% 2xx  <-- we should see alerts stop in here
    - series: 'api_3scale_gateway_api_status{environment="stage",exported_service="cloudigrade",status="5xx"}'
      # these effectively expand to
      # (0..0)(0%) (1..10)(1%) (19..100)(9%) (115..250)(15%) (250..250)(0%)
      values: "0+0x9 1+1x9 19+9x9 115+15x9 250+0x9"
    - series: 'api_3scale_gateway_api_status{environment="stage",exported_service="cloudigrade",status="2xx"}'
      # these effectively expand to
      # (0..900)(100%) (999..1890)(99%) (1981..2800)(91%) (2885..3560)(85%) (3750..4650)(100%)
      values: "0+100x9 999+99x9 1981+91x9 2885+85x9 3750+100x9"

    alert_rule_test:
      - eval_time: 5m
        alertname: cloudigrade-stage-5xx-errors
        exp_alerts: []
      - eval_time: 10m
        alertname: cloudigrade-stage-5xx-errors
        exp_alerts: []
      - eval_time: 15m
        alertname: cloudigrade-stage-5xx-errors
        exp_alerts: []
      - eval_time: 20m
        alertname: cloudigrade-stage-5xx-errors
        exp_alerts: []
      - eval_time: 25m
        alertname: cloudigrade-stage-5xx-errors
        exp_alerts: []
      - eval_time: 30m
        alertname: cloudigrade-stage-5xx-errors
        exp_alerts:
          - exp_labels:
              severity: warning
              service: insights
              env: stage
              app_team: cloudigrade
            exp_annotations:
              dashboard: "https://grafana.stage.devshift.net/d/O6v4rMpizda/cloudigrade?orgId=1&var-datasource=crcs02ue1-prometheus&var-namespace=cloudigrade-stage"
              link_url: "https://console-openshift-console.apps.crcs02ue1.urby.p1.openshiftapps.com/k8s/ns/cloudigrade-stage/deployments/cloudigrade-api"
              message: "cloudigrade: 5xx responses observed; success rate < 95% for the last 5 minutes in stage environment."
              runbook: "https://gitlab.cee.redhat.com/service/app-interface/-/tree/master/docs/console.redhat.com/app-sops/cloudigrade/cloudigrade-alert-5xx.md"
      - eval_time: 50m
        alertname: cloudigrade-stage-5xx-errors
        exp_alerts: []

  # cloudigrade-stage-slow-responses
  - interval: 1m
    input_series:
    # 0m  - 9m    0% too slow, 100% ok
    # 10m - 19m   1% too slow, 99% ok
    # 20m - 29m   9% too slow, 91% ok
    # 30m - 39m   15% too slow, 85% ok  <-- we should see alerts start in here
    # 40m - 59m   0% too slow, 100% ok  <-- we should see alerts stop in here
    - series: 'api_3scale_gateway_api_time_bucket{environment="stage", exported_service="cloudigrade", le="+Inf"}'
      # Remember that the "+Inf" bucket is a superset of "4000.0", etc. and should always be "100%" of requests.
      # these effectively expand to
      # (0..900)(0%) (1000..1900)(100%) (2000..2900)(100%) (3000..3900)(100%) (4000..4900)(100%)
      values: "0+100x9 1000+100x9 2000+100x9 3000+100x9 4000+100x9"
    - series: 'api_3scale_gateway_api_time_bucket{environment="stage", exported_service="cloudigrade", le="4000.0"}'
      # these effectively expand to
      # (0..900)(100%) (999..1890)(99%) (1981..2800)(91%) (2885..3560)(85%) (3750..4650)(100%)
      values: "0+100x9 999+99x9 1981+91x9 2885+85x9 3750+100x9"

    alert_rule_test:
      - eval_time: 5m
        alertname: cloudigrade-stage-slow-responses
        exp_alerts: []
      - eval_time: 10m
        alertname: cloudigrade-stage-slow-responses
        exp_alerts: []
      - eval_time: 15m
        alertname: cloudigrade-stage-slow-responses
        exp_alerts: []
      - eval_time: 20m
        alertname: cloudigrade-stage-slow-responses
        exp_alerts: []
      - eval_time: 25m
        alertname: cloudigrade-stage-slow-responses
        exp_alerts: []
      - eval_time: 30m
        alertname: cloudigrade-stage-slow-responses
        exp_alerts:
          - exp_labels:
              severity: warning
              service: insights
              env: stage
              app_team: cloudigrade
            exp_annotations:
              dashboard: "https://grafana.stage.devshift.net/d/O6v4rMpizda/cloudigrade?orgId=1&var-datasource=crcs02ue1-prometheus&var-namespace=cloudigrade-stage"
              link_url: "https://console-openshift-console.apps.crcs02ue1.urby.p1.openshiftapps.com/k8s/ns/cloudigrade-stage/deployments/cloudigrade-api"
              message: "cloudigrade: slow responses observed; more than 5% of requests with response time > 4 seconds for the last 5 minutes in stage environment."
              runbook: "https://gitlab.cee.redhat.com/service/app-interface/-/tree/master/docs/console.redhat.com/app-sops/cloudigrade/cloudigrade-alert-slow.md"
      - eval_time: 50m
        alertname: cloudigrade-stage-slow-responses
        exp_alerts: []

  # cloudigrade-stage-no-ready-api-pods
  - interval: 1m
    input_series:
    # 0m  - 9m    3 pods
    # 10m - 19m   0 pods  <-- we should see alerts start in here
    # 20m - 29m   3 pods  <-- we should see alerts stop in here
    - series: 'kube_pod_container_status_ready{namespace="cloudigrade-stage", pod="cloudigrade-api.0123456789abcdef"}'
      values: "3+0x9 0+0x9 3+0x9"

    alert_rule_test:
      - eval_time: 5m
        alertname: cloudigrade-stage-no-ready-api-pods
        exp_alerts: []
      - eval_time: 10m
        alertname: cloudigrade-stage-no-ready-api-pods
        exp_alerts: []
      - eval_time: 15m
        alertname: cloudigrade-stage-no-ready-api-pods
        exp_alerts:
          - exp_labels:
              severity: warning
              service: insights
              env: stage
              app_team: cloudigrade
            exp_annotations:
              dashboard: "https://grafana.stage.devshift.net/d/O6v4rMpizda/cloudigrade?orgId=1&var-datasource=crcs02ue1-prometheus&var-namespace=cloudigrade-stage"
              link_url: "https://console-openshift-console.apps.crcs02ue1.urby.p1.openshiftapps.com/k8s/ns/cloudigrade-stage/deployments/cloudigrade-api"
              message: "cloudigrade: no api pods have been ready for the last 5 minutes in stage environment."
              runbook: "https://gitlab.cee.redhat.com/service/app-interface/-/tree/master/docs/console.redhat.com/app-sops/cloudigrade/cloudigrade-alert-no-api.md"
      - eval_time: 20m
        alertname: cloudigrade-stage-no-ready-api-pods
        exp_alerts: []
      - eval_time: 25m
        alertname: cloudigrade-stage-no-ready-api-pods
        exp_alerts: []

  # cloudigrade-stage-no-ready-beat-pods
  - interval: 1m
    input_series:
    # 0m  - 9m    1 pods
    # 10m - 19m   0 pods  <-- we should see alerts start in here
    # 20m - 29m   1 pods  <-- we should see alerts stop in here
    - series: 'kube_pod_container_status_ready{namespace="cloudigrade-stage", pod="cloudigrade-beat.0123456789abcdef"}'
      values: "1+0x9 0+0x9 1+0x9"

    alert_rule_test:
      - eval_time: 5m
        alertname: cloudigrade-stage-no-ready-beat-pods
        exp_alerts: []
      - eval_time: 10m
        alertname: cloudigrade-stage-no-ready-beat-pods
        exp_alerts: []
      - eval_time: 15m
        alertname: cloudigrade-stage-no-ready-beat-pods
        exp_alerts:
          - exp_labels:
              severity: warning
              service: insights
              env: stage
              app_team: cloudigrade
            exp_annotations:
              dashboard: "https://grafana.stage.devshift.net/d/O6v4rMpizda/cloudigrade?orgId=1&var-datasource=crcs02ue1-prometheus&var-namespace=cloudigrade-stage"
              link_url: "https://console-openshift-console.apps.crcs02ue1.urby.p1.openshiftapps.com/k8s/ns/cloudigrade-stage/deployments/cloudigrade-beat"
              message: "cloudigrade: no beat pods have been ready for the last 5 minutes in stage environment."
              runbook: "https://gitlab.cee.redhat.com/service/app-interface/-/tree/master/docs/console.redhat.com/app-sops/cloudigrade/cloudigrade-alert-no-beat.md"
      - eval_time: 20m
        alertname: cloudigrade-stage-no-ready-beat-pods
        exp_alerts: []
      - eval_time: 25m
        alertname: cloudigrade-stage-no-ready-beat-pods
        exp_alerts: []

  # cloudigrade-stage-too-many-ready-beat-pods
  - interval: 1m
    input_series:
    # 0m  - 9m    1 pods
    # 10m - 19m   2 pods  <-- we should see alerts start in here
    # 20m - 29m   1 pods  <-- we should see alerts stop in here
    - series: 'kube_pod_container_status_ready{namespace="cloudigrade-stage", pod="cloudigrade-beat.0123456789abcdef"}'
      values: "1+0x9 2+0x9 1+0x9"

    alert_rule_test:
      - eval_time: 5m
        alertname: cloudigrade-stage-too-many-ready-beat-pods
        exp_alerts: []
      - eval_time: 10m
        alertname: cloudigrade-stage-too-many-ready-beat-pods
        exp_alerts: []
      - eval_time: 15m
        alertname: cloudigrade-stage-too-many-ready-beat-pods
        exp_alerts:
          - exp_labels:
              severity: warning
              service: insights
              env: stage
              app_team: cloudigrade
            exp_annotations:
              dashboard: "https://grafana.stage.devshift.net/d/O6v4rMpizda/cloudigrade?orgId=1&var-datasource=crcs02ue1-prometheus&var-namespace=cloudigrade-stage"
              link_url: "https://console-openshift-console.apps.crcs02ue1.urby.p1.openshiftapps.com/k8s/ns/cloudigrade-stage/deployments/cloudigrade-beat"
              message: "cloudigrade: more than 1 beat pod has been ready for the last 5 minutes in stage environment."
              runbook: "https://gitlab.cee.redhat.com/service/app-interface/-/tree/master/docs/console.redhat.com/app-sops/cloudigrade/cloudigrade-alert-too-many-beats.md"
      - eval_time: 20m
        alertname: cloudigrade-stage-no-ready-beat-pods
        exp_alerts: []
      - eval_time: 25m
        alertname: cloudigrade-stage-no-ready-beat-pods
        exp_alerts: []

  # cloudigrade-stage-no-ready-listener-pods
  - interval: 1m
    input_series:
    # 0m  - 9m    1 pods
    # 10m - 19m   0 pods  <-- we should see alerts start in here
    # 20m - 29m   1 pods  <-- we should see alerts stop in here
    - series: 'kube_pod_container_status_ready{namespace="cloudigrade-stage", pod="cloudigrade-listener.0123456789abcdef"}'
      values: "1+0x9 0+0x9 1+0x9"

    alert_rule_test:
      - eval_time: 5m
        alertname: cloudigrade-stage-no-ready-listener-pods
        exp_alerts: []
      - eval_time: 10m
        alertname: cloudigrade-stage-no-ready-listener-pods
        exp_alerts: []
      - eval_time: 15m
        alertname: cloudigrade-stage-no-ready-listener-pods
        exp_alerts:
          - exp_labels:
              severity: warning
              service: insights
              env: stage
              app_team: cloudigrade
            exp_annotations:
              dashboard: "https://grafana.stage.devshift.net/d/O6v4rMpizda/cloudigrade?orgId=1&var-datasource=crcs02ue1-prometheus&var-namespace=cloudigrade-stage"
              link_url: "https://console-openshift-console.apps.crcs02ue1.urby.p1.openshiftapps.com/k8s/ns/cloudigrade-stage/deployments/cloudigrade-listener"
              message: "cloudigrade: no listener pods have been ready for the last 5 minutes in stage environment."
              runbook: "https://gitlab.cee.redhat.com/service/app-interface/-/tree/master/docs/console.redhat.com/app-sops/cloudigrade/cloudigrade-alert-no-listener.md"
      - eval_time: 20m
        alertname: cloudigrade-stage-no-ready-listener-pods
        exp_alerts: []
      - eval_time: 25m
        alertname: cloudigrade-stage-no-ready-listener-pods
        exp_alerts: []

  # cloudigrade-stage-no-ready-worker-pods
  - interval: 1m
    input_series:
    # 0m  - 9m    1 pods
    # 10m - 19m   0 pods  <-- we should see alerts start in here
    # 20m - 29m   1 pods  <-- we should see alerts stop in here
    - series: 'kube_pod_container_status_ready{namespace="cloudigrade-stage", pod="cloudigrade-worker.0123456789abcdef"}'
      values: "1+0x9 0+0x9 1+0x9"

    alert_rule_test:
      - eval_time: 5m
        alertname: cloudigrade-stage-no-ready-worker-pods
        exp_alerts: []
      - eval_time: 10m
        alertname: cloudigrade-stage-no-ready-worker-pods
        exp_alerts: []
      - eval_time: 15m
        alertname: cloudigrade-stage-no-ready-worker-pods
        exp_alerts:
          - exp_labels:
              severity: warning
              service: insights
              env: stage
              app_team: cloudigrade
            exp_annotations:
              dashboard: "https://grafana.stage.devshift.net/d/O6v4rMpizda/cloudigrade?orgId=1&var-datasource=crcs02ue1-prometheus&var-namespace=cloudigrade-stage"
              link_url: "https://console-openshift-console.apps.crcs02ue1.urby.p1.openshiftapps.com/k8s/ns/cloudigrade-stage/deployments/cloudigrade-worker"
              message: "cloudigrade: no worker pods have been ready for the last 5 minutes in stage environment."
              runbook: "https://gitlab.cee.redhat.com/service/app-interface/-/tree/master/docs/console.redhat.com/app-sops/cloudigrade/cloudigrade-alert-no-worker.md"
      - eval_time: 20m
        alertname: cloudigrade-stage-no-ready-worker-pods
        exp_alerts: []
      - eval_time: 25m
        alertname: cloudigrade-stage-no-ready-worker-pods
        exp_alerts: []


  # cloudigrade-stage-frequent-pod-restarting
  - interval: 1m
    input_series:
    # 0m  - 9m   0 restarts
    # 10m - 29m  15 restarts/minute  <-- we should see alerts start in here
    # 29m - 59m  0 restarts  <-- we should see alerts stop in here
    - series: 'kube_pod_container_status_restarts_total{namespace="cloudigrade-stage", container="cloudigrade-worker"}'
      values: "0+0x9 15+15x19 300+0x29"

    alert_rule_test:
      - eval_time: 5m
        alertname: cloudigrade-stage-frequent-pod-restarting
        exp_alerts: []
      - eval_time: 10m
        alertname: cloudigrade-stage-frequent-pod-restarting
        exp_alerts: []
      - eval_time: 15m
        alertname: cloudigrade-stage-frequent-pod-restarting
        exp_alerts: []
      - eval_time: 20m
        alertname: cloudigrade-stage-frequent-pod-restarting
        exp_alerts:
          - exp_labels:
              severity: warning
              service: insights
              env: stage
              app_team: cloudigrade
            exp_annotations:
              dashboard: "https://grafana.stage.devshift.net/d/O6v4rMpizda/cloudigrade?orgId=1&var-datasource=crcs02ue1-prometheus&var-namespace=cloudigrade-stage"
              link_url: "https://console-openshift-console.apps.crcs02ue1.urby.p1.openshiftapps.com/k8s/ns/cloudigrade-stage/deployments"
              message: "cloudigrade: pod restart has occurred more than 10x/10 minutes for the last 10 minutes in stage environment."
              runbook: "https://gitlab.cee.redhat.com/service/app-interface/-/tree/master/docs/console.redhat.com/app-sops/cloudigrade/cloudigrade-alert-pod-restarting.md"
      - eval_time: 40m
        alertname: cloudigrade-stage-frequent-pod-restarting
        exp_alerts: []
      - eval_time: 45m
        alertname: cloudigrade-stage-frequent-pod-restarting
        exp_alerts: []

  # cloudigrade-stage-too-many-unread-sqs-messages
  - interval: 1m
    input_series:
    # 0m  - 9m    100 messages
    # 10m - 19m  5000 messages  <-- query would start to trigger in here
    # 20m - 29m  5000 messages  <-- we should see alerts start in here
    # 30m - 39m  5000 messages  <-- we should see alerts continue through here
    # 40m - 49m   100 messages  <-- we should see alerts stop in here
    - series: 'cloudigrade_sqs_queue_length{namespace="cloudigrade-stage", queue_name="my-terrible-queue"}'
      values: "100+0x9 5000+0x9 5000+0x9 5000+0x9 100+0x9 100+0x9"

    alert_rule_test:
      - eval_time: 10m
        alertname: cloudigrade-stage-too-many-unread-sqs-messages
        exp_alerts: []
      - eval_time: 24m
        alertname: cloudigrade-stage-too-many-unread-sqs-messages
        exp_alerts: []
      - eval_time: 25m
        alertname: cloudigrade-stage-too-many-unread-sqs-messages
        exp_alerts:
          - exp_labels:
              severity: warning
              service: insights
              env: stage
              app_team: cloudigrade
            exp_annotations:
              dashboard: "https://grafana.stage.devshift.net/d/O6v4rMpizda/cloudigrade?orgId=1&var-datasource=crcs02ue1-prometheus&var-namespace=cloudigrade-stage"
              link_url: "https://console-openshift-console.apps.crcs02ue1.urby.p1.openshiftapps.com/k8s/ns/cloudigrade-stage/deployments/cloudigrade-worker"
              message: "cloudigrade: more than 1000 unread SQS messages."
              runbook: "https://gitlab.cee.redhat.com/service/app-interface/-/tree/master/docs/console.redhat.com/app-sops/cloudigrade/cloudigrade-alert-too-many-unread-sqs-messages.md"
      - eval_time: 39m
        alertname: cloudigrade-stage-too-many-unread-sqs-messages
        exp_alerts:
          - exp_labels:
              severity: warning
              service: insights
              env: stage
              app_team: cloudigrade
            exp_annotations:
              dashboard: "https://grafana.stage.devshift.net/d/O6v4rMpizda/cloudigrade?orgId=1&var-datasource=crcs02ue1-prometheus&var-namespace=cloudigrade-stage"
              link_url: "https://console-openshift-console.apps.crcs02ue1.urby.p1.openshiftapps.com/k8s/ns/cloudigrade-stage/deployments/cloudigrade-worker"
              message: "cloudigrade: more than 1000 unread SQS messages."
              runbook: "https://gitlab.cee.redhat.com/service/app-interface/-/tree/master/docs/console.redhat.com/app-sops/cloudigrade/cloudigrade-alert-too-many-unread-sqs-messages.md"
      - eval_time: 40m
        alertname: cloudigrade-stage-too-many-unread-sqs-messages
        exp_alerts: []

  # cloudigrade-stage-too-many-queued-celery-tasks
  - interval: 1m
    input_series:
    # 0m  - 9m    100 messages
    # 10m - 19m  5000 messages  <-- query would start to trigger in here
    # 20m - 29m  5000 messages  <-- we should see alerts start in here
    # 30m - 39m  5000 messages  <-- we should see alerts continue through here
    # 40m - 49m   100 messages  <-- we should see alerts stop in here
    - series: 'cloudigrade_celery_queue_length{namespace="cloudigrade-stage", queue_name="my-terrible-queue"}'
      values: "100+0x9 5000+0x9 5000+0x9 5000+0x9 100+0x9 100+0x9"

    alert_rule_test:
      - eval_time: 10m
        alertname: cloudigrade-stage-too-many-queued-celery-tasks
        exp_alerts: []
      - eval_time: 24m
        alertname: cloudigrade-stage-too-many-queued-celery-tasks
        exp_alerts: []
      - eval_time: 25m
        alertname: cloudigrade-stage-too-many-queued-celery-tasks
        exp_alerts:
          - exp_labels:
              severity: warning
              service: insights
              env: stage
              app_team: cloudigrade
            exp_annotations:
              dashboard: "https://grafana.stage.devshift.net/d/O6v4rMpizda/cloudigrade?orgId=1&var-datasource=crcs02ue1-prometheus&var-namespace=cloudigrade-stage"
              link_url: "https://console-openshift-console.apps.crcs02ue1.urby.p1.openshiftapps.com/k8s/ns/cloudigrade-stage/deployments/cloudigrade-worker"
              message: "cloudigrade: more than 2000 queued Celery tasks."
              runbook: "https://gitlab.cee.redhat.com/service/app-interface/-/tree/master/docs/console.redhat.com/app-sops/cloudigrade/cloudigrade-alert-too-many-queued-celery-tasks.md"
      - eval_time: 39m
        alertname: cloudigrade-stage-too-many-queued-celery-tasks
        exp_alerts:
          - exp_labels:
              severity: warning
              service: insights
              env: stage
              app_team: cloudigrade
            exp_annotations:
              dashboard: "https://grafana.stage.devshift.net/d/O6v4rMpizda/cloudigrade?orgId=1&var-datasource=crcs02ue1-prometheus&var-namespace=cloudigrade-stage"
              link_url: "https://console-openshift-console.apps.crcs02ue1.urby.p1.openshiftapps.com/k8s/ns/cloudigrade-stage/deployments/cloudigrade-worker"
              message: "cloudigrade: more than 2000 queued Celery tasks."
              runbook: "https://gitlab.cee.redhat.com/service/app-interface/-/tree/master/docs/console.redhat.com/app-sops/cloudigrade/cloudigrade-alert-too-many-queued-celery-tasks.md"
      - eval_time: 40m
        alertname: cloudigrade-stage-too-many-queued-celery-tasks
        exp_alerts: []
