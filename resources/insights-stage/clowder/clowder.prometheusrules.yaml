---
$schema: /openshift/prometheus-rule-1.yml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: clowder
  labels:
    prometheus: app-sre
    role: alert-rules
spec:
  groups:
  - name: clowder
    rules:
      - alert: Clowder-no-metrics
        expr: absent(up{service="clowder-controller-manager"}) or sum(up{service="clowder-controller-manager"}) == 0
        for: 5m
        labels:
          severity: medium
          service: clowder
          env: stage
          app_team: platform
        annotations:
          dashboard: "https://grafana.app-sre.devshift.net/d/VTSfF_0Gk/clowder-metrics"
          link_url: "https://console-openshift-console.apps.crcs02ue1.urby.p1.openshiftapps.com/k8s/ns/clowder/deployments"
          message: "Clowder metrics are no longer being scraped."
          runbook: "https://gitlab.cee.redhat.com/service/app-interface/-/tree/master/docs/cloud.redhat.com/app-sops/clowder/Clowder-no-metrics.md"
      - alert: ClowderReconciliationRate
        expr: rate(controller_runtime_reconcile_total[5m]) > 10
        for: 5m
        labels:
          severity: high
          service: clowder
          env: stage
        annotations:
          dashboard: https://grafana.stage.devshift.net/d/VTSfF_0Gk/clowder-metrics?viewPanel=6&orgId=1&var-datasource=crcs02ue1-prometheus
          message: "Clowder Reconciliation Rate too high"
      - alert: ClowderReconciliationErrorRate
        expr: sum(rate(controller_runtime_reconcile_total{controller=~"clowdenvironment|clowdapp",result="error"}[10m])) by (controller) > 0.05
        for: 10m
        labels:
          severity: high
          service: clowder
          env: stage
        annotations:
          dashboard: https://grafana.stage.devshift.net/d/VTSfF_0Gk/clowder-metrics?orgId=1&var-datasource=crcs02ue1-prometheus
          message: "Clowder Reconciliation Error Rate too high"
      - alert: ClowdAppsCount
        expr: sum(clowd_app_managed_apps) == 0
        for: 5m
        labels:
          severity: high
          service: clowder
          env: stage
        annotations:
          dashboard: https://grafana.stage.devshift.net/d/VTSfF_0Gk/clowder-metrics
          message: "ClowdApp not running"
      - alert: ClowderPodCount
        expr: kube_deployment_status_replicas_available{deployment="clowder-controller-manager"} != 1 or absent(kube_deployment_status_replicas_available{deployment="clowder-controller-manager"}) == 1
        for: 5m
        labels:
          severity: high
          service: clowder
          env: stage
        annotations:
          dashboard: https://grafana.stage.devshift.net/d/VTSfF_0Gk/clowder-metrics?viewPanel=17&orgId=1
          message: "Clowder pod not running for 5minutes"
      - alert: ClowderContainerRestartCount
        expr: sum(increase(kube_pod_container_status_restarts_total{namespace="clowder", container="manager"}[5m])) > 10
        for: 5m
        labels:
          severity: high
          service: clowder
          env: stage
        annotations:
          dashboard: https://grafana.stage.devshift.net/d/VTSfF_0Gk/clowder-metrics
          message: "Too many Clowder pod restarts"
      - alert: ClowderWorkQueueDepth
        expr: sum(workqueue_depth{service="clowder-controller-manager"}) by (name) > 20
        for: 5m
        labels:
          severity: high
          service: clowder
          env: stage
        annotations:
          dashboard: https://grafana.stage.devshift.net/d/VTSfF_0Gk/clowder-metrics
          message: "Clowder Work Queue depth too deep "
