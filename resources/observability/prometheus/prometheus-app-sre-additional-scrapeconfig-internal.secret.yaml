apiVersion: v1
kind: Secret
metadata:
  name: prometheus-additional-scrape-config
  annotations:
    qontract.ignore_reconcile_time: "true"
data:
  prometheus-app-sre-additional.yaml:
    {{% b64encode %}}
    # Scraping external services

    # Hive
    ## hive-stage-01
    - job_name: 'hive-controllers-hive-stage-01'
      scrape_interval: 60s
      metrics_path: /metrics
      static_configs:
      - targets: ['hive-controllers-metrics-hive.apps.hive-stage-01.n1u3.p1.openshiftapps.com']
      metric_relabel_configs:
      - source_labels: [__name__]
        regex: '^rest_client_.*'
        action: drop
      relabel_configs:
      - source_labels: [__address__]
        regex: (.*)
        separator: ;
        target_label: appsre_env
        replacement: staging
        action: replace
      # This `shard_status` label should match the actual hive shard status from data/services/ocm/shared-resources/stage.yml
      - target_label: shard_status
        replacement: active

    ## hives02ue1
    - job_name: 'hive-controllers-hives02ue1'
      scrape_interval: 60s
      metrics_path: /metrics
      static_configs:
      - targets: ['hive-controllers-metrics-hive.apps.hives02ue1.j5l5.p1.openshiftapps.com']
      metric_relabel_configs:
      - source_labels: [__name__]
        regex: '^rest_client_.*'
        action: drop
      relabel_configs:
      - source_labels: [__address__]
        regex: (.*)
        separator: ;
        target_label: appsre_env
        replacement: staging
        action: replace
      # This `shard_status` label should match the actual hive shard status from data/services/ocm/shared-resources/stage.yml
      - target_label: shard_status
        replacement: active

    ## hivep01ue1
    - job_name: 'hive-controllers-hivep01ue1'
      scrape_interval: 60s
      metrics_path: /metrics
      static_configs:
      - targets: ['hive-controllers-metrics-hive.apps.hivep01ue1.b6s7.p1.openshiftapps.com']
      metric_relabel_configs:
      - source_labels: [__name__]
        regex: '^rest_client_.*'
        action: drop
      relabel_configs:
      - source_labels: [__address__]
        regex: (.*)
        separator: ;
        target_label: appsre_env
        replacement: production
        action: replace
      # This `shard_status` label should match the actual hive shard status from data/services/ocm/shared-resources/production.yml
      - target_label: shard_status
        replacement: active

    ## hivep02ue1
    - job_name: 'hive-controllers-hivep02ue1'
      scrape_interval: 60s
      metrics_path: /metrics
      static_configs:
      - targets: ['hive-controllers-metrics-hive.apps.hivep02ue1.p0r5.p1.openshiftapps.com']
      metric_relabel_configs:
      - source_labels: [__name__]
        regex: '^rest_client_.*'
        action: drop
      relabel_configs:
      - source_labels: [__address__]
        regex: (.*)
        separator: ;
        target_label: appsre_env
        replacement: production
        action: replace
      # This `shard_status` label should match the actual hive shard status from data/services/ocm/shared-resources/production.yml
      - target_label: shard_status
        replacement: active

    ## hivep03uw1
    - job_name: 'hive-controllers-hivep03uw1'
      scrape_interval: 60s
      metrics_path: /metrics
      static_configs:
      - targets: ['hive-controllers-metrics-hive.apps.hivep03uw1.o2y3.p1.openshiftapps.com']
      metric_relabel_configs:
      - source_labels: [__name__]
        regex: '^rest_client_.*'
        action: drop
      relabel_configs:
      - source_labels: [__address__]
        regex: (.*)
        separator: ;
        target_label: appsre_env
        replacement: production
        action: replace
      # This `shard_status` label should match the actual hive shard status from data/services/ocm/shared-resources/production.yml
      - target_label: shard_status
        replacement: maintenance

    ## hivep04ew2
    - job_name: 'hive-controllers-hivep04ew2'
      scrape_interval: 60s
      metrics_path: /metrics
      static_configs:
      - targets: ['hive-controllers-metrics-hive.apps.hivep04ew2.byo5.p1.openshiftapps.com']
      metric_relabel_configs:
      - source_labels: [__name__]
        regex: '^rest_client_.*'
        action: drop
      relabel_configs:
      - source_labels: [__address__]
        regex: (.*)
        separator: ;
        target_label: appsre_env
        replacement: production
        action: replace
      # This `shard_status` label should match the actual hive shard status from data/services/ocm/shared-resources/production.yml
      - target_label: shard_status
        replacement: active

    ## hivep05ue1
    - job_name: 'hive-controllers-hivep05ue1'
      scrape_interval: 60s
      metrics_path: /metrics
      static_configs:
      - targets: ['hive-controllers-metrics-hive.apps.hivep05ue1.pfj0.p1.openshiftapps.com']
      metric_relabel_configs:
      - source_labels: [__name__]
        regex: '^rest_client_.*'
        action: drop
      relabel_configs:
      - source_labels: [__address__]
        regex: (.*)
        separator: ;
        target_label: appsre_env
        replacement: production
        action: replace
      # This `shard_status` label should match the actual hive shard status from data/services/ocm/shared-resources/production.yml
      - target_label: shard_status
        replacement: active

    ## hivep06uw2
    - job_name: 'hive-controllers-hivep06uw2'
      scrape_interval: 60s
      metrics_path: /metrics
      static_configs:
      - targets: ['hive-controllers-metrics-hive.apps.hivep06uw2.bjee.p1.openshiftapps.com']
      metric_relabel_configs:
      - source_labels: [__name__]
        regex: '^rest_client_.*'
        action: drop
      relabel_configs:
      - source_labels: [__address__]
        regex: (.*)
        separator: ;
        target_label: appsre_env
        replacement: production
        action: replace
      # This `shard_status` label should match the actual hive shard status from data/services/ocm/shared-resources/production.yml
      - target_label: shard_status
        replacement: active

    ## hivep07ue2
    - job_name: 'hive-controllers-hivep07ue2'
      scrape_interval: 60s
      metrics_path: /metrics
      static_configs:
      - targets: ['hive-controllers-metrics-hive.apps.hivep07ue2.vvyl.p1.openshiftapps.com']
      metric_relabel_configs:
      - source_labels: [__name__]
        regex: '^rest_client_.*'
        action: drop
      relabel_configs:
      - source_labels: [__address__]
        regex: (.*)
        separator: ;
        target_label: appsre_env
        replacement: production
        action: replace
      # This `shard_status` label should match the actual hive shard status from data/services/ocm/shared-resources/production.yml
      - target_label: shard_status
        replacement: maintenance

    # ci.int.devshift.net
    - job_name: 'jenkins_int'
      scrape_interval: 30s
      metrics_path: /prometheus
      basic_auth:
        username: {{{ vault('app-sre/ci-int/jjb-ini', 'username') }}}
        password: {{{ vault('app-sre/ci-int/jjb-ini', 'password') }}}
      static_configs:
      - targets: ['ci.int.devshift.net']
      scheme: https

    # Federation
    # This include a list of metrics that's currently being used in alerts' Prometheus rule as of July 19 2023
    # due to the limit of default machine pool of this cluster, more background info in APPSRE-7733
    - job_name: federate-cluster-monitoring-prometheus
      honor_labels: true
      params:
        match[]:
        - '{__name__=~"kube_pod_container_status_restarts_total"}'
        - '{__name__=~"kube_pod_info"}'
        - '{__name__=~"kube_pod_container_resource_limits"}'
        - '{__name__=~"kube_pod_status_ready"}'
        - '{__name__=~"kube_pod_container_status_ready"}'
        - '{__name__=~"kube_pod_container_resource_limits_cpu_cores"}'
        - '{__name__=~"kube_pod_container_resource_requests_cpu_cores"}'
        - '{__name__=~"kube_job_status_failed"}'
        - '{__name__=~"kube_replicationcontroller_status_ready_replicas"}'
        - '{__name__=~"kube_replicationcontroller_spec_replicas"}'
        - '{__name__=~"kube_pod_container_resource_limits_memory_bytes"}'
        - '{__name__=~"kube_pod_status_phase"}'
        - '{__name__=~"kube_deployment_status_replicas_available"}'
        - '{__name__=~"kube_pod_container_resource_requests_memory_bytes"}'
        - '{__name__=~"kube_pod_container_resource_requests"}'
        - '{__name__=~"kube_deployment_status_replicas_unavailable"}'
        - '{__name__=~"kube_node_labels"}'
        - '{__name__=~"kube_node_status_allocatable_memory_bytes"}'
        - '{__name__=~"kube_node_status_allocatable_cpu_cores"}'
        - '{__name__=~"kube_statefulset_status_replicas_updated"}'
        - '{__name__=~"kube_statefulset_status_replicas_ready"}'
        - '{__name__=~"kube_statefulset_status_replicas"}'
        - '{__name__=~"kube_resourcequota"}'
        - '{__name__=~"kube_pod_init_container_status_restarts_total"}'
        - '{__name__=~"kube_pod_container_status_last_terminated_reason"}'
        - '{__name__=~"node_namespace_pod:kube_pod_info:"}'
        - '{__name__=~"namespace:kube_pod_container_resource_requests_memory_bytes:sum"}'
        - '{__name__=~"namespace:kube_pod_container_resource_requests_cpu_cores:sum"}'
        - '{__name__=~"kube_pod_container_status_terminated_reason"}'
        - '{__name__=~"kube_persistentvolumeclaim_resource_requests_storage_bytes"}'
        - '{__name__=~":kube_persistentvolume_status_phase"}'
        - '{__name__=~":kube_job_status_succeeded"}'
        - '{__name__=~":kube_job_labels"}'
        - '{__name__=~":kube_deployment_status_replicas_updated"}'
        - '{__name__=~":kube_deployment_spec_replicas"}'
        - '{__name__=~":hive_kube_client_requests_total"}'
        - '{__name__=~":kube_pod_info_node_count:"}'
        - '{__name__=~"kube_node_status_allocatable"}'
        - '{__name__=~"kube_node_info"}'
        - '{__name__=~":job_cronjob:kube_job_status_start_time:max"}'
        - '{__name__=~"kube_persistentvolumeclaim_info"}'
        - '{__name__=~"kube_job_status_start_time"}'
        - '{__name__=~"namespace_cpu:kube_pod_container_resource_requests:sum"}'
        - '{__name__=~"namespace_cpu:kube_pod_container_resource_limits:sum"}'
        - '{__name__=~"kube_pod_resource_limit"}'
        - '{__name__=~"job_cronjob:kube_job_status_failed:sum"}'
        {{%- if is_tekton_cluster is defined and is_tekton_cluster %}}
        - '{__name__=~"tekton_pipelines_controller_pipelinerun_taskrun_duration_seconds"}'
        - '{__name__=~"tekton_pipelines_controller_pipelinerun_duration_seconds"}'
        {{%- endif %}}
      scrape_interval: 30s
      scrape_timeout: 10s
      metrics_path: /federate
      scheme: https
      tls_config:
        insecure_skip_verify: true
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      static_configs:
      - targets:
        - 'prometheus-k8s.openshift-monitoring.svc:9091'
    - job_name: 'blackbox_2xx_gitlab'
      scheme: http
      scrape_interval: 10s
      metrics_path: /probe
      params:
        module: [http_gitlab]
      static_configs:
      - targets:
          # External dependencies
          - https://gitlab.cee.redhat.com
          - https://gitlab.cee.redhat.com/-/health
      relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: blackbox-exporter.app-sre-observability-devshift:9115 # The blackbox exporter.
    - job_name: 'blackbox_2xx_ci_int'
      scheme: http
      scrape_interval: 10s
      metrics_path: /probe
      params:
        module: [http_2xx_ci-int]
      static_configs:
      - targets:
          - https://ci.int.devshift.net
      relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: blackbox-exporter.app-sre-observability-devshift:9115 # The blackbox exporter.
    - job_name: 'jenkins_controllers'
      scheme: http
      scrape_interval: 30s
      scrape_timeout: 30s
      metrics_path: /metrics
      static_configs:
      - targets:
        - ci.int.devshift.net:9100
        - stage.int.devshift.net:9100
    - job_name: 'ci_int_bastion'
      scheme: http
      scrape_interval: 30s
      scrape_timeout: 30s
      metrics_path: /metrics
      static_configs:
      - targets:
        - bastion.ci.int.devshift.net:9100
    - job_name: 'jenkins_worker'
      scheme: http
      scrape_interval: 30s
      scrape_timeout: 30s
      metrics_path: /metrics
      ec2_sd_configs:
      - region: us-east-1
        access_key: {{{ vault('app-sre/integrations-output/terraform-resources/app-sre-prod-01/app-sre-observability-production/jenkins-worker-sd-config', 'aws_access_key_id') }}}
        secret_key: {{{ vault('app-sre/integrations-output/terraform-resources/app-sre-prod-01/app-sre-observability-production/jenkins-worker-sd-config', 'aws_secret_access_key') }}}
        port: 9100
        filters:
        - name: instance-state-name
          values: ['running']
        - name: tag:jenkins_controller
          values: ['ci-int']
      relabel_configs:
      - source_labels: [__meta_ec2_instance_id]
        target_label: id
      - source_labels: [__meta_ec2_tag_Name]
        target_label: type
      - source_labels: [__meta_ec2_ami]
        target_label: ami
    {{% endb64encode %}}
