---
$schema: /openshift/prometheus-rule-1.yml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  labels:
    prometheus: app-sre
    role: alert-rules
  name: osd-fleet-manager-{{{ environment }}}
spec:
  groups:
    - name: osd-fleet-manager-{{{ environment }}}
      rules:
      {{% for sector in sectors %}}
        - alert: OSD Fleet Manager {{{ environment }}} down - {{{ sector }}} sector
          annotations:
            message: "No instances found for OSD Fleet Manager in {{{ sector }}} sector - OSD Fleet Manager {{{ environment }}} is down."
          expr: |
            absent(up{service="fleet-manager-metrics-{{{ sector }}}",namespace="{{{ namespace }}}"} == 1)
          for: 15m
          labels:
            severity: high
            team: osd
            namespace: {{{ namespace }}}
            service: osd-fleet-manager
            sector: {{{ sector }}}
      {{% endfor %}}
        - alert: OSD Fleet Manager is crashing
          annotations:
            message: OSD Fleet Manager container '{{ $labels.container }}' of pod '{{ $labels.pod }}' is crashing more than 2 times in 15 minutes in namespace '{{{ environment }}}' and sector '{{ $labels.sector }}'
          expr: |
            sum(label_replace(increase(kube_pod_container_status_restarts_total{namespace="{{{ namespace }}}", pod=~"^fleet-manager-metrics-.*"}[5m]),"sector", "$1", "service", "fleet-manager-metrics-(.*)")) by (sector,container,pod) > 2
          for: 15m
          labels:
            severity: high
            team: osd
            namespace: {{{ namespace }}}
            service: osd-fleet-manager

    - name: osd-fleet-manager-nonprod-api
      rules:
        - expr: |
            sum(rate(haproxy_backend_http_responses_total{route="osd-fleet-manager",exported_namespace="{{{ namespace }}}",code=~"5.."}[1h]))
            /
            sum(rate(haproxy_backend_http_responses_total{route="osd-fleet-manager",exported_namespace="{{{ namespace }}}"}[1h]))
          labels:
            service: osd-fleet-manager
            exported_namespace: {{{ namespace }}}
            route: osd-fleet-manager
          record: haproxy_backend_http_500_responses
        - alert: OSD Fleet Manager returning 5xx 
          annotations:
            message: 'OSD Fleet Manager is returning 5xx error codes in {{{ namespace }}} (current value: {{ $value | humanize }})'
            dashboard: "https://grafana.stage.devshift.net/d/osd_fleet_manager/osd-fleet-manager-metrics"
            runbook: ""
          expr: |
            sum(haproxy_backend_http_500_responses{route="osd-fleet-manager",exported_namespace="{{{ namespace }}}"}) > 1-0.99000
          for: 10m
          labels:
            service: osd-fleet-manager
            namespace: {{{ namespace }}}
            team: osd
            severity: medium
        - expr: |
            label_replace(sum(rate(api_outbound_request_count{path=~"/api/clusters_mgmt/v1/clusters/.*",namespace="{{{ namespace }}}",apiservice="ocm-clusters-service",code=~"4.."}[5m])) /
            sum(rate(api_outbound_request_count{path=~"/api/clusters_mgmt/v1/clusters/.*",namespace="{{{ namespace }}}",apiservice="ocm-clusters-service"}[5m])),"sector","$1","service","fleet-manager-metrics-(.*)")
          labels:
            namespace: {{{ namespace }}}
            sector: main
          record: outbound_http_responses_total
        - alert: OSD Fleet Manager outbound api response errors
          annotations:
            message: "OSD Fleet Manager is receiving 4xx error codes from OCM in sector {{ $labels.sector}} of namespace {{{ namespace }}} (current value: {{ $value }})"
            dashboard: "https://grafana.stage.devshift.net/d/osd_fleet_manager/osd-fleet-manager-metrics"
            runbook: ""
          expr: |
            sum(outbound_http_responses_total{namespace="{{{ namespace }}}"}) by (sector) > 1 - 0.99
          for: 15m
          labels:
            service: osd-fleet-manager
            namespace: {{{ namespace }}}
            team: osd
            severity: medium

    - name: osd-fleet-manager-nonprod-reconciler
      rules:
        - expr: |
            label_replace(sum by (worker_type, service, reconciliation_step, namespace) (rate(fleet_manager_reconciler_failure_count{namespace="{{{ namespace }}}"}[5m])), "sector", "$1", "service", "fleet-manager-metrics-(.*)")
          labels:
            job: fleet-manager-metrics
          record: reconciler:fleet_manager_reconciler_failure_count:rate5m
        - alert: OSD Fleet Manager reconciler failure
          annotations:
            message: The reconciler {{ $labels.worker_type }}/{{ $labels.reconciliation_step }} for sector {{ $labels.sector }} in {{{ environment }}} failed with a rate of {{ $value | printf "%.2f" }}/s over the last 15 minutes.
            dashboard: "https://grafana.stage.devshift.net/d/osd_fleet_manager/osd-fleet-manager-metrics"
            runbook: ""
          expr: |
            reconciler:fleet_manager_reconciler_failure_count:rate5m{namespace="{{{ namespace }}}"} > 0
          for: 15m
          labels:
            severity: medium
            team: osd
            service: osd-fleet-manager
            namespace: {{{ namespace }}}
        
    {{% for wt in worker_types %}}
        - expr: |
            label_replace(max by (worker_type, service, reconciliation_step, namespace) (fleet_manager_reconciler_duration_in_seconds{namespace="{{{ namespace }}}",worker_type="{{{ wt.name }}}"}), "sector", "$1", "service", "fleet-manager-metrics-(.*)")
          record: reconciler:fleet_manager_reconciler_duration_in_seconds:{{{ wt.name | replace("-","_") }}}:max
        - alert: OSD Fleet Manager {{{ wt.name }}} reconciler long duration
          annotations:
            message: "The maximum reconciler duration was {{ $value | humanizeDuration }} for reconciler {{{ wt.name }}} at step {{ $labels.reconciliation_step }} in sector {{ $labels.sector }} in {{{ namespace }}}"
            dashboard: "https://grafana.stage.devshift.net/d/osd_fleet_manager/osd-fleet-manager-metrics"
            runbook: ""
          expr: |
            reconciler:fleet_manager_reconciler_duration_in_seconds:{{{ wt.name | replace("-","_") }}}:max{namespace="{{{ namespace }}}"} > {{{ wt.reconciler_duration_threshold | default(30) }}}
          labels:
            severity: medium
            service: osd-fleet-manager
            worker_type: {{{ wt.name }}}
            namespace: {{{ namespace }}}
    {{% endfor %}}
        
    {{% for sector in sectors %}}
        - alert: OSD Fleet Manager cluster provision long duration
          annotations:
            message: "Long provision duration {{ $value | humanizeDuration }} for cluster {{ $labels.cluster_id }} of type {{ $labels.cluster_type }} in sector {{{ sector }}} in {{{ environment }}}"
            dashboard: "https://grafana.stage.devshift.net/d/osd_fleet_manager/osd-fleet-manager-metrics"
            runbook: ""
          expr: |
            fleet_manager_cluster_provisioning_elapsed_time_in_seconds{namespace="{{{ namespace }}}", service="fleet-manager-metrics-{{{ sector }}}"} > 18000
          labels:
            severity: medium
            service: osd-fleet-manager
            sector: {{{ sector }}}
    {{% endfor %}}

    - name: osd-fleet-manager-cluster-operation
      rules:
    {{% for sector in sectors %}}
        - alert: OSD Fleet Manager cluster failed operations
          annotations:
            message: "Cluster provision failed in sector {{{ sector }}} in environment {{{ environment }}}" 
            dashboard: "https://grafana.stage.devshift.net/d/osd_fleet_manager/osd-fleet-manager-metrics"
            runbook: ""
          expr: |
            sum(rate(fleet_manager_cluster_status_count{namespace="{{{ namespace }}}", service="fleet-manager-metrics-{{{ sector }}}", status="failed"}[1h])) > 0
          labels:
            severity: high
            service: osd-fleet-manager
            sector: {{{ sector }}}
            namespace: {{{ namespace }}}
    {{% endfor %}}

    - name: osd-fleet-manager-nonprod-saturation-level
      rules:
        - alert: OSD Fleet Manager saturation level exceeding 90% 
          annotations:
            message: 'High saturation level exceeding 90% for service cluster {{ $labels.service_cluster }} in region {{ $labels.region }} of {{{ environment }}} (current value: {{ $value }})'
            dashboard: "https://grafana.stage.devshift.net/d/osd_fleet_manager/osd-fleet-manager-metrics"
            runbook: ""
          expr: |
            fleet_manager_saturation_level{namespace="{{{ namespace }}}"} >= 0.9
          for: 15m
          labels:
            service: osd-fleet-manager
            namespace: {{{ namespace }}}
            severity: high
            team: osd
        - alert: OSD Fleet Manager saturation level exceeding 85%
          annotations:
            message: 'Saturation level exceeding 85% for service cluster {{ $labels.service_cluster }} in region {{ $labels.region }} of {{{ environment }}} (current value: {{ $value }})'
            dashboard: "https://grafana.stage.devshift.net/d/osd_fleet_manager/osd-fleet-manager-metrics"
            runbook: ""
          expr: |
            fleet_manager_saturation_level{namespace="{{{ namespace }}}"} >= 0.85
            and
            fleet_manager_saturation_level{namespace="{{{ namespace }}}"} < 0.9
          for: 15m
          labels:
            service: osd-fleet-manager
            namespace: {{{ namespace }}}
            team: osd
            severity: medium
        - expr: |
            label_replace((sum(fleet_manager_management_cluster_hosted_cluster_count{namespace="{{{ namespace }}}"}) by (service, region, service_cluster)) / (sum(fleet_manager_available_management_clusters_by_service_cluster_count{namespace="{{{ namespace }}}"}) by (service, region, service_cluster) * avg(fleet_manager_max_desired_hosted_cluster_count{namespace="{{{ namespace }}}"}) by (service, region, service_cluster)),"sector","$1","service","fleet-manager-metrics-(.*)")
          labels:
            service: osd-fleet-manager
            namespace: {{{ namespace }}}
          record: fleet_manager_saturation_level
