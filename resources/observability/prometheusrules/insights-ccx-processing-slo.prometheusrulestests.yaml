---
$schema: /app-interface/prometheus-rule-test-1.yml

rule_files:
- /observability/prometheusrules/insights-ccx-processing-slo.prometheusrules.yaml

evaluation_interval: 5m

tests:
- interval: 5m
  input_series:
  - series: sum(kafka_consumergroup_group_lag{topic="platform.upload.buckit",group="ccx_data_pipeline_app"})
    values: 10 50 100 200 300 400 500 600

  alert_rule_test:
  # Test the no alert case
  - eval_time: 5m
    alertname: Archive Handler Kafka lag is too high
    exp_alerts:

  # Test the up < 200 case
  - eval_time: 10m
    alertname: Archive Handler Kafka lag is too high
    exp_alerts:
    - exp_labels:
        service: ccx-data-pipeline
        severity: high
      exp_annotations:
        message: "The ccx-data-pipeline lag is too high."
        runbook: "https://ccx.pages.redhat.com/ccx-docs/customer/sops/cdp_kafka_lag_gt_100.html"
        # TODO: Update the link to the correct dashboard
        dashboard: "https://grafana.app-sre.devshift.net/d/Afpm4ku7k/ccx-processing-slo?orgId=1&viewPanel=6"

  # TODO: Test the missing metric case will require to use `absent` in the rule
  - eval_time: 15m
    alertname: Archive Handler Kafka lag is too high
    exp_alerts:
    - exp_labels:
        service: ccx-data-pipeline
        severity: high
      exp_annotations:
        message: "The ccx-data-pipeline lag is too high."
        runbook: "https://ccx.pages.redhat.com/ccx-docs/customer/sops/cdp_kafka_lag_gt_100.html"
        # TODO: Update the link to the correct dashboard
        dashboard: "https://grafana.app-sre.devshift.net/d/Afpm4ku7k/ccx-processing-slo?orgId=1&viewPanel=6"

- interval: 5m
  input_series:
  - series: sum(kafka_consumergroup_group_lag{topic="ccx.ocp.results", group="ccx_data_pipeline_app"})
    values: 10 50 100 200 300 400 500 600

  alert_rule_test:
  # Test the no alert case
  - eval_time: 5m
    alertname: DB Writer Kafka lag is too high
    exp_alerts:

  # Test the up < 200 case
  - eval_time: 10m
    alertname: DB Writer Kafka lag is too high
    exp_alerts:
    - exp_labels:
        service: db-writer
        severity: high
      exp_annotations:
        message: "The db-writer lag is too high."
        runbook: "https://ccx.pages.redhat.com/ccx-docs/customer/sops/irdw_kafka_lag_gt_100.html"
        # TODO: Update the link to the correct dashboard
        dashboard: "https://grafana.app-sre.devshift.net/d/Afpm4ku7k/ccx-processing-slo?orgId=1&viewPanel=6"

  # TODO: Test the missing metric case will require to use `absent` in the rule
  - eval_time: 15m
    alertname: DB Writer Kafka lag is too high
    exp_alerts:
    - exp_labels:
        service: db-writer
        severity: high
      exp_annotations:
        message: "The db-writer lag is too high."
        runbook: "https://ccx.pages.redhat.com/ccx-docs/customer/sops/irdw_kafka_lag_gt_100.html"
        # TODO: Update the link to the correct dashboard
        dashboard: "https://grafana.app-sre.devshift.net/d/Afpm4ku7k/ccx-processing-slo?orgId=1&viewPanel=6"

- interval: 5m
  input_series:
  - series: |
              (
                sum(
                  increase(successful_messages_processing_time_sum{service="ccx-insights-results-db-writer-prometheus-exporter",namespace="ccx-data-pipeline-prod"}[1m])
                )
                /
                sum(
                  increase(successful_messages_processing_time_count{service="ccx-insights-results-db-writer-prometheus-exporter",namespace="ccx-data-pipeline-prod"}[1m])
                )
              ) + (
                sum(
                  increase(ccx_process_duration_seconds_count{service="ccx-data-pipeline-prometheus-exporter",namespace="ccx-data-pipeline-prod"}[1m])
                )
                /
                sum(
                  increase(ccx_process_duration_seconds_count{service="ccx-data-pipeline-prometheus-exporter",namespace="ccx-data-pipeline-prod"}[1m])
                )
              )
    values: 10 50 100 200 300 400 500 600

  alert_rule_test:
  # Test the no alert case
  - eval_time: 5m
    alertname: "[PROD] Archive processing is taking too long"
    exp_alerts:

  # Test the up < 200 case
  - eval_time: 10m
    alertname: "[PROD] Archive processing is taking too long"
    exp_alerts:
    - exp_labels:
        service: ccx-data-pipeline
        severity: high
      exp_annotations:
        message: "The processing time of ccx-data-pipeline and db-writer is taking too long in production environment."
        runbook: "https://ccx.pages.redhat.com/ccx-docs/customer/sops/archives_are_not_processed.html"
        # TODO: Update the link to the correct dashboard
        dashboard: "https://grafana.app-sre.devshift.net/d/Afpm4ku7k/ccx-processing-slo?orgId=1&viewPanel=14"

  # TODO: Test the missing metric case will require to use `absent` in the rule
  - eval_time: 15m
    alertname: "[PROD] Archive processing is taking too long"
    exp_alerts:
    - exp_labels:
        service: ccx-data-pipeline
        severity: high
      exp_annotations:
        message: "The processing time of ccx-data-pipeline and db-writer is taking too long in production environment.."
        runbook: "https://ccx.pages.redhat.com/ccx-docs/customer/sops/archives_are_not_processed.html"
        # TODO: Update the link to the correct dashboard
        dashboard: "https://grafana.app-sre.devshift.net/d/Afpm4ku7k/ccx-processing-slo?orgId=1&viewPanel=14"

- interval: 5m
  input_series:
  - series: |
              (
                sum(
                  increase(successful_messages_processing_time_sum{service="ccx-insights-results-db-writer-prometheus-exporter",namespace="ccx-data-pipeline-stage"}[1m])
                )
                /
                sum(
                  increase(successful_messages_processing_time_count{service="ccx-insights-results-db-writer-prometheus-exporter",namespace="ccx-data-pipeline-stage"}[1m])
                )
              ) + (
                sum(
                  increase(ccx_process_duration_seconds_count{service="ccx-data-pipeline-prometheus-exporter",namespace="ccx-data-pipeline-stage"}[1m])
                )
                /
                sum(
                  increase(ccx_process_duration_seconds_count{service="ccx-data-pipeline-prometheus-exporter",namespace="ccx-data-pipeline-stage"}[1m])
                )
              )
    values: 10 50 100 200 300 400 500 600

  alert_rule_test:
  # Test the no alert case
  - eval_time: 5m
    alertname: "[STAGE] Archive processing is taking too long"
    exp_alerts:

  # Test the up < 200 case
  - eval_time: 10m
    alertname: "[STAGE] Archive processing is taking too long"
    exp_alerts:
    - exp_labels:
        service: ccx-data-pipeline
        severity: high
      exp_annotations:
        message: "The processing time of ccx-data-pipeline and db-writer is taking too long in stage environment."
        runbook: "https://ccx.pages.redhat.com/ccx-docs/customer/sops/archives_are_not_processed.html"
        # TODO: Update the link to the correct dashboard
        dashboard: "https://grafana.app-sre.devshift.net/d/Afpm4ku7k/ccx-processing-slo?orgId=1&viewPanel=14"

  # TODO: Test the missing metric case will require to use `absent` in the rule
  - eval_time: 15m
    alertname: "[STAGE] Archive processing is taking too long"
    exp_alerts:
    - exp_labels:
        service: ccx-data-pipeline
        severity: high
      exp_annotations:
        message: "The processing time of ccx-data-pipeline and db-writer is taking too long in stage environment.."
        runbook: "https://ccx.pages.redhat.com/ccx-docs/customer/sops/archives_are_not_processed.html"
        # TODO: Update the link to the correct dashboard
        dashboard: "https://grafana.app-sre.devshift.net/d/Afpm4ku7k/ccx-processing-slo?orgId=1&viewPanel=14"

- interval: 5m
  input_series:
  - series: |
              count ( rate(api_endpoints_response_time_sum{namespace="ccx-data-pipeline-prod", service="ccx-smart-proxy"}[1m]) > 0.5 ) 
              /
              sum(rate(api_endpoints_response_time_count{namespace="ccx-data-pipeline-prod", service="ccx-smart-proxy"}[1m]))
    values: 0.05 0.1 0.5 0.7

  alert_rule_test:
  # Test the no alert case
  - eval_time: 5m
    alertname: "[PROD] API responses are taking too long"
    exp_alerts:

  # Test the up < 200 case
  - eval_time: 10m
    alertname: "[PROD] API responses are taking too long"
    exp_alerts:
    - exp_labels:
        service: smart-proxy
        severity: critical
      exp_annotations:
        message: "The response time of smart-proxy ({{ $labels.exported_endpoint }} endpoint) is taking too long in production environment."
        runbook: "https://ccx.pages.redhat.com/ccx-docs/customer/sops/rest_api_gt_1_sec.html"
        # TODO: Update the link to the correct dashboard
        dashboard: "https://grafana.app-sre.devshift.net/d/Afpm4ku7k/ccx-processing-slo?orgId=1&viewPanel=8"

  # TODO: Test the missing metric case will require to use `absent` in the rule
  - eval_time: 15m
    alertname: "[PROD] API responses are taking too long"
    exp_alerts:
    - exp_labels:
        service: smart-proxy
        severity: critical
      exp_annotations:
        message: "The response time of smart-proxy ({{ $labels.exported_endpoint }} endpoint) is taking too long in production environment."
        runbook: "https://ccx.pages.redhat.com/ccx-docs/customer/sops/rest_api_gt_1_sec.html"
        # TODO: Update the link to the correct dashboard
        dashboard: "https://grafana.app-sre.devshift.net/d/Afpm4ku7k/ccx-processing-slo?orgId=1&viewPanel=8"

- interval: 5m
  input_series:
  - series: |
              count ( rate(api_endpoints_response_time_sum{namespace="ccx-data-pipeline-stage", service="ccx-smart-proxy"}[1m]) > 0.5 ) 
              /
              sum(rate(api_endpoints_response_time_count{namespace="ccx-data-pipeline-stage", service="ccx-smart-proxy"}[1m]))
    values: 0.05 0.1 0.5 0.7

  alert_rule_test:
  # Test the no alert case
  - eval_time: 5m
    alertname: "[STAGE] API responses are taking too long"
    exp_alerts:

  # Test the up < 200 case
  - eval_time: 10m
    alertname: "[STAGE] API responses are taking too long"
    exp_alerts:
    - exp_labels:
        service: smart-proxy
        severity: critical
      exp_annotations:
        message: "The response time of smart-proxy ({{ $labels.exported_endpoint }} endpoint) is taking too long in stage environment."
        runbook: "https://ccx.pages.redhat.com/ccx-docs/customer/sops/rest_api_gt_1_sec.html"
        # TODO: Update the link to the correct dashboard
        dashboard: "https://grafana.app-sre.devshift.net/d/Afpm4ku7k/ccx-processing-slo?orgId=1&viewPanel=8"

  # TODO: Test the missing metric case will require to use `absent` in the rule
  - eval_time: 15m
    alertname: "[STAGE] API responses are taking too long"
    exp_alerts:
    - exp_labels:
        service: smart-proxy
        severity: critical
      exp_annotations:
        message: "The response time of smart-proxy ({{ $labels.exported_endpoint }} endpoint) is taking too long in stage environment."
        runbook: "https://ccx.pages.redhat.com/ccx-docs/customer/sops/rest_api_gt_1_sec.html"
        # TODO: Update the link to the correct dashboard
        dashboard: "https://grafana.app-sre.devshift.net/d/Afpm4ku7k/ccx-processing-slo?orgId=1&viewPanel=8"

- interval: 5m
  input_series:
  - series: |
              sum(rate(api_endpoints_status_codes{namespace="ccx-data-pipeline-prod", service="ccx-smart-proxy", status_code="500"}[1m]))
              /
              sum(rate(api_endpoints_requests{namespace="ccx-data-pipeline-prod", service="ccx-smart-proxy"}[1m]))
    values: 0.01 0.05 0.1 0.5

  alert_rule_test:
  # Test the no alert case
  - eval_time: 5m
    alertname: "[PROD] API 500 responses are too frequent"
    exp_alerts:

  # Test the up < 200 case
  - eval_time: 10m
    alertname: "[PROD] API 500 responses are too frequent"
    exp_alerts:
    - exp_labels:
        service: smart-proxy
        severity: critical
      exp_annotations:
        message: "The response code in smart-proxy ({{ $labels.exported_endpoint }} endpoint) is 500 too often."
        runbook: "https://ccx.pages.redhat.com/ccx-docs/customer/sops/index.html"
        # TODO: Update the link to the correct dashboard
        dashboard: "https://grafana.app-sre.devshift.net/d/Afpm4ku7k/ccx-processing-slo?orgId=1&viewPanel=12"

  # TODO: Test the missing metric case will require to use `absent` in the rule
  - eval_time: 15m
    alertname: "[PROD] API 500 responses are too frequent"
    exp_alerts:
    - exp_labels:
        service: smart-proxy
        severity: critical
      exp_annotations:
        message: "The response code in smart-proxy ({{ $labels.exported_endpoint }} endpoint) is 500 too often."
        runbook: "https://ccx.pages.redhat.com/ccx-docs/customer/sops/index.html"
        # TODO: Update the link to the correct dashboard
        dashboard: "https://grafana.app-sre.devshift.net/d/Afpm4ku7k/ccx-processing-slo?orgId=1&viewPanel=12"

- interval: 5m
  input_series:
  - series: |
              sum(rate(api_endpoints_status_codes{namespace="ccx-data-pipeline-stage", service="ccx-smart-proxy", status_code="500"}[1m]))
              /
              sum(rate(api_endpoints_requests{namespace="ccx-data-pipeline-stage", service="ccx-smart-proxy"}[1m]))
    values: 0.01 0.05 0.1 0.5

  alert_rule_test:
  # Test the no alert case
  - eval_time: 5m
    alertname: "[STAGE] API 500 responses are too frequent"
    exp_alerts:

  # Test the up < 200 case
  - eval_time: 10m
    alertname: "[STAGE] API 500 responses are too frequent"
    exp_alerts:
    - exp_labels:
        service: smart-proxy
        severity: critical
      exp_annotations:
        message: "The response code in smart-proxy ({{ $labels.exported_endpoint }} endpoint) is 500 too often."
        runbook: "https://ccx.pages.redhat.com/ccx-docs/customer/sops/index.html"
        # TODO: Update the link to the correct dashboard
        dashboard: "https://grafana.app-sre.devshift.net/d/Afpm4ku7k/ccx-processing-slo?orgId=1&viewPanel=12"

  # TODO: Test the missing metric case will require to use `absent` in the rule
  - eval_time: 15m
    alertname: "[STAGE] API 500 responses are too frequent"
    exp_alerts:
    - exp_labels:
        service: smart-proxy
        severity: critical
      exp_annotations:
        message: "The response code in smart-proxy ({{ $labels.exported_endpoint }} endpoint) is 500 too often."
        runbook: "https://ccx.pages.redhat.com/ccx-docs/customer/sops/index.html"
        # TODO: Update the link to the correct dashboard
        dashboard: "https://grafana.app-sre.devshift.net/d/Afpm4ku7k/ccx-processing-slo?orgId=1&viewPanel=12"
