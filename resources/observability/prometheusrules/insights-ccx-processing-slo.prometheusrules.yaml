---
$schema: /openshift/prometheus-rule-1.yml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  labels:
    prometheus: app-sre
    role: alert-rules
  name: ccx-processing-slo
spec:
  groups:
  - name: ccx-processing-slo
    rules:
    - alert: Archive Handler Kafka lag is too high
      annotations:
        message: "The ccx-data-pipeline lag is too high."
        runbook: "https://ccx.pages.redhat.com/ccx-docs/customer/sops/cdp_kafka_lag_gt_100.html"
        dashboard: "https://grafana.app-sre.devshift.net/d/ccxprocessingslo/ccx-processing-slo?orgId=1&viewPanel=6"
      expr: |
              sum(kafka_consumergroup_group_lag{topic="platform.upload.announce",group="ccx_data_pipeline_app"}) > 200
      for: 5m
      labels:
        service: ccx-data-pipeline
        severity: high

    - alert: DB Writer Kafka lag is too high
      annotations:
        message: "The db-writer lag is too high."
        runbook: "https://ccx.pages.redhat.com/ccx-docs/customer/sops/irdw_kafka_lag_gt_100.html"
        dashboard: "https://grafana.app-sre.devshift.net/d/ccxprocessingslo/ccx-processing-slo?orgId=1&viewPanel=6"
      expr: |
              sum(kafka_consumergroup_group_lag{topic="ccx.ocp.results", group="ccx_data_pipeline_app"}) > 100
      for: 5m
      labels:
        service: db-writer
        severity: high

    - alert: "[PROD] Archive processing is taking too long"
      annotations:
        message: "The processing time of ccx-data-pipeline and db-writer is taking too long in production environment."
        runbook: "https://ccx.pages.redhat.com/ccx-docs/customer/sops/archives_are_not_processed.html"
        dashboard: "https://grafana.app-sre.devshift.net/d/ccxprocessingslo/ccx-processing-slo?orgId=1&viewPanel=14"
      expr: |
              (((((  
                  sum(
                      increase(successful_messages_processing_time_sum{namespace="ccx-data-pipeline-prod", service="ccx-insights-results-db-writer-prometheus-exporter"}[1m])
                  ) /  
                  sum(   
                      increase(successful_messages_processing_time_count{namespace="ccx-data-pipeline-prod", service="ccx-insights-results-db-writer-prometheus-exporter"}[1m])
                  )
              ) < 5) + 
              ((
                  sum(    
                      increase(ccx_process_duration_seconds_count{namespace="ccx-data-pipeline-prod", service="ccx-data-pipeline-prometheus-exporter"}[1m])  
                  ) /  
                  sum(   
                      increase(ccx_process_duration_seconds_count{namespace="ccx-data-pipeline-prod", service="ccx-data-pipeline-prometheus-exporter"}[1m])
                  )
              ) < 5))
              /
              ((  
                  sum(
                      increase(successful_messages_processing_time_sum{namespace="ccx-data-pipeline-prod", service="ccx-insights-results-db-writer-prometheus-exporter"}[1m])
                  ) /  
                  sum(   
                      increase(successful_messages_processing_time_count{namespace="ccx-data-pipeline-prod", service="ccx-insights-results-db-writer-prometheus-exporter"}[1m])
                  )
              )  + 
              (
                  sum(    
                      increase(ccx_process_duration_seconds_count{namespace="ccx-data-pipeline-stage", service="ccx-data-pipeline-prometheus-exporter"}[1m])  
                  ) /  
                  sum(   
                      increase(ccx_process_duration_seconds_count{namespace="ccx-data-pipeline-stage", service="ccx-data-pipeline-prometheus-exporter"}[1m])
                  )
              ))) OR on() vector(0)) < 0.95
      for: 5m
      labels:
        service: ccx-data-pipeline
        severity: high

    - alert: "[STAGE] Archive processing is taking too long"
      annotations:
        message: "The processing time of ccx-data-pipeline and db-writer is taking too long in stage environment."
        runbook: "https://ccx.pages.redhat.com/ccx-docs/customer/sops/archives_are_not_processed.html"
        dashboard: "https://grafana.app-sre.devshift.net/d/ccxprocessingslo/ccx-processing-slo?orgId=1&viewPanel=14"
      expr: |
              (((((  
                  sum(
                      increase(successful_messages_processing_time_sum{namespace="ccx-data-pipeline-stage", service="ccx-insights-results-db-writer-prometheus-exporter"}[1m])
                  ) /  
                  sum(   
                      increase(successful_messages_processing_time_count{namespace="ccx-data-pipeline-stage", service="ccx-insights-results-db-writer-prometheus-exporter"}[1m])
                  )
              ) < 5) + 
              ((
                  sum(    
                      increase(ccx_process_duration_seconds_count{namespace="ccx-data-pipeline-stage", service="ccx-data-pipeline-prometheus-exporter"}[1m])  
                  ) /  
                  sum(   
                      increase(ccx_process_duration_seconds_count{namespace="ccx-data-pipeline-stage", service="ccx-data-pipeline-prometheus-exporter"}[1m])
                  )
              ) < 5))
              /
              ((  
                  sum(
                      increase(successful_messages_processing_time_sum{namespace="ccx-data-pipeline-stage", service="ccx-insights-results-db-writer-prometheus-exporter"}[1m])
                  ) /  
                  sum(   
                      increase(successful_messages_processing_time_count{namespace="ccx-data-pipeline-stage", service="ccx-insights-results-db-writer-prometheus-exporter"}[1m])
                  )
              )  + 
              (
                  sum(    
                      increase(ccx_process_duration_seconds_count{namespace="ccx-data-pipeline-stage", service="ccx-data-pipeline-prometheus-exporter"}[1m])  
                  ) /  
                  sum(   
                      increase(ccx_process_duration_seconds_count{namespace="ccx-data-pipeline-stage", service="ccx-data-pipeline-prometheus-exporter"}[1m])
                  )
              ))) OR on() vector(0)) < 0.95
      for: 5m
      labels:
        service: ccx-data-pipeline
        severity: high

    - alert: "[PROD] API responses are taking too long"
      annotations:
        message: "The response time of smart-proxy is taking too long in production environment."
        runbook: "https://ccx.pages.redhat.com/ccx-docs/customer/sops/rest_api_gt_1_sec.html"
        dashboard: "https://grafana.app-sre.devshift.net/d/ccxprocessingslo/ccx-processing-slo?orgId=1&viewPanel=8"
      expr: |
              (( count ( rate(api_endpoints_response_time_sum{namespace="ccx-data-pipeline-prod", service="ccx-smart-proxy"}[5m]) < 0.5 ) 
              /
              count(rate(api_endpoints_response_time_sum{namespace="ccx-data-pipeline-prod", service="ccx-smart-proxy"}[5m])) ) OR on() vector(0)) < 0.95
      for: 5m
      labels:
        service: smart-proxy
        severity: critical

    - alert: "[STAGE] API responses are taking too long"
      annotations:
        message: "The response time of smart-proxy is taking too long in stage environment."
        runbook: "https://ccx.pages.redhat.com/ccx-docs/customer/sops/rest_api_gt_1_sec.html"
        dashboard: "https://grafana.app-sre.devshift.net/d/ccxprocessingslo/ccx-processing-slo?orgId=1&viewPanel=8"
      expr: |
              (( count ( rate(api_endpoints_response_time_sum{namespace="ccx-data-pipeline-stage", service="ccx-smart-proxy"}[1m]) < 0.5 ) 
              /
              count(rate(api_endpoints_response_time_sum{namespace="ccx-data-pipeline-stage", service="ccx-smart-proxy"}[1m])) ) OR on() vector(0)) < 0.95
      for: 5m
      labels:
        service: smart-proxy
        severity: critical

    - alert: "[PROD] API 500 responses are too frequent"
      annotations:
        message: "The response code in smart-proxy is 500 too often."
        runbook: "https://ccx.pages.redhat.com/ccx-docs/customer/sops/index.html"
        dashboard: "https://grafana.app-sre.devshift.net/d/ccxprocessingslo/ccx-processing-slo?orgId=1&viewPanel=12"
      expr: |
              (sum(rate(api_endpoints_status_codes{namespace="ccx-data-pipeline-prod", service="ccx-smart-proxy", status_code!="500"}[5m]))
              /
              sum(rate(api_endpoints_status_codes{namespace="ccx-data-pipeline-prod", service="ccx-smart-proxy"}[5m]))) < 0.95
      for: 5m
      labels:
        service: smart-proxy
        severity: critical

    - alert: "[STAGE] API 500 responses are too frequent"
      annotations:
        message: "The response code in smart-proxy is 500 too often."
        runbook: "https://ccx.pages.redhat.com/ccx-docs/customer/sops/index.html"
        dashboard: "https://grafana.app-sre.devshift.net/d/ccxprocessingslo/ccx-processing-slo?orgId=1&viewPanel=12"
      expr: |
              (sum(rate(api_endpoints_status_codes{namespace="ccx-data-pipeline-stage", service="ccx-smart-proxy", status_code!="500"}[5m]))
              /
              sum(rate(api_endpoints_status_codes{namespace="ccx-data-pipeline-stage", service="ccx-smart-proxy"}[5m]))) < 0.95
      for: 5m
      labels:
        service: smart-proxy
        severity: critical
