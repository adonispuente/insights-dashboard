---
$schema: /openshift/prometheus-rule-1.yml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  labels:
    prometheus: app-sre
    role: alert-rules
  name: prometheus-mixin
spec:
  groups:
  - name: prometheus.rules
    rules:
    - alert: PrometheusConfigReloadFailed
      annotations:
        description: Reloading Prometheus' configuration has failed for {{$labels.namespace}}/{{$labels.pod}}
        summary: Reloading Prometheus' configuration failed
        runbook: "https://gitlab.cee.redhat.com/service/app-interface/blob/master/docs/app-sre/sop/prometheus/prometheus-PrometheusConfigReloadFailed.md"
      expr: |
        prometheus_config_last_reload_successful == 0
      for: 10m
      labels:
        severity: high
    - alert: PrometheusNotificationQueueRunningFull
      annotations:
        description: Prometheus' alert notification queue is running full for {{$labels.namespace}}/{{
          $labels.pod}}
        summary: Prometheus' alert notification queue is running full
        runbook: "https://gitlab.cee.redhat.com/service/app-interface/blob/master/docs/app-sre/sop/prometheus/prometheus-PrometheusNotificationQueueRunningFull.md"
      expr: |
        predict_linear(prometheus_notifications_queue_length[5m], 60 * 30) > prometheus_notifications_queue_capacity
      for: 10m
      labels:
        severity: high
    - alert: PrometheusErrorSendingAlerts
      annotations:
        description: Errors while sending alerts from Prometheus {{$labels.namespace}}/{{
          $labels.pod}} to Alertmanager {{$labels.Alertmanager}}
        summary: Errors while sending alert from Prometheus
        runbook: "https://gitlab.cee.redhat.com/service/app-interface/blob/master/docs/app-sre/sop/prometheus/prometheus-PrometheusErrorSendingAlerts.md"
      expr: |
        rate(prometheus_notifications_errors_total[5m]) / rate(prometheus_notifications_sent_total[5m]) > 0.01
      for: 10m
      labels:
        severity: high
    - alert: PrometheusErrorSendingAlerts
      annotations:
        description: Errors while sending alerts from Prometheus {{$labels.namespace}}/{{
          $labels.pod}} to Alertmanager {{$labels.Alertmanager}}
        summary: Errors while sending alerts from Prometheus
        runbook: "https://gitlab.cee.redhat.com/service/app-interface/blob/master/docs/app-sre/sop/prometheus/prometheus-PrometheusErrorSendingAlerts.md"
      expr: |
        rate(prometheus_notifications_errors_total[5m]) / rate(prometheus_notifications_sent_total[5m]) > 0.03
      for: 10m
      labels:
        severity: critical
    # This is currently only the app-sre prometheus instance
    - alert: PrometheusNotConnectedToAlertmanagers
      annotations:
        description: Prometheus {{ $labels.namespace }}/{{ $labels.pod}} is not connected
          to any Alertmanagers
        summary: Prometheus is not connected to any Alertmanagers
        runbook: "https://gitlab.cee.redhat.com/service/app-interface/blob/master/docs/app-sre/sop/prometheus/prometheus-PrometheusNotConnectedToAlertmanagers.md"
      expr: |
        prometheus_notifications_alertmanagers_discovered{namespace="app-sre-observability-production"} < 1
      for: 10m
      labels:
        severity: high
    - alert: PrometheusTSDBReloadsFailing
      annotations:
        description: '{{$labels.job}} at {{$labels.instance}} had {{$value | humanize}}
          reload failures over the last four hours.'
        summary: Prometheus has issues reloading data blocks from disk
        runbook: "https://gitlab.cee.redhat.com/service/app-interface/blob/master/docs/app-sre/sop/prometheus/prometheus-PrometheusTSDBReloadsFailing.md"
      expr: |
        increase(prometheus_tsdb_reloads_failures_total[2h]) > 0
      for: 12h
      labels:
        severity: high
    - alert: PrometheusTSDBCompactionsFailing
      annotations:
        description: '{{$labels.job}} at {{$labels.instance}} had {{$value | humanize}}
          compaction failures over the last four hours.'
        summary: Prometheus has issues compacting sample blocks
        runbook: "https://gitlab.cee.redhat.com/service/app-interface/blob/master/docs/app-sre/sop/prometheus/prometheus-PrometheusTSDBCompactionsFailing.md"
      expr: |
        increase(prometheus_tsdb_compactions_failed_total[2h]) > 0
      for: 12h
      labels:
        severity: high
    - alert: PrometheusTSDBWALCorruptions
      annotations:
        description: '{{$labels.job}} at {{$labels.instance}} has a corrupted write-ahead
          log (WAL).'
        summary: Prometheus write-ahead log is corrupted
        runbook: "https://gitlab.cee.redhat.com/service/app-interface/blob/master/docs/app-sre/sop/prometheus/prometheus-PrometheusTSDBWALCorruptions.md"
      expr: |
        tsdb_wal_corruptions_total > 0
      for: 4h
      labels:
        severity: high
    - alert: PrometheusNotIngestingSamples
      annotations:
        description: Prometheus {{ $labels.namespace }}/{{ $labels.pod}} isn't ingesting
          samples.
        summary: Prometheus isn't ingesting samples
        runbook: "https://gitlab.cee.redhat.com/service/app-interface/blob/master/docs/app-sre/sop/prometheus/prometheus-PrometheusNotIngestingSamples.md"
      expr: |
        rate(prometheus_tsdb_head_samples_appended_total[5m]) <= 0
      for: 10m
      labels:
        severity: high
    - alert: PrometheusTargetScrapesDuplicate
      annotations:
        description: '{{$labels.namespace}}/{{$labels.pod}} has many samples rejected
          due to duplicate timestamps but different values'
        summary: Prometheus has many samples rejected
        runbook: "https://gitlab.cee.redhat.com/service/app-interface/blob/master/docs/app-sre/sop/prometheus/prometheus-PrometheusTargetScrapesDuplicate.md"
      expr: |
        increase(prometheus_target_scrapes_sample_duplicate_timestamp_total[5m]) > 0
      for: 10m
      labels:
        severity: high
    - alert: PrometheusRemoteStorageFailures
      annotations:
        message: "Prometheus {{$labels.instance}} failed to send {{ printf \"%.1f\" $value }}% of the samples to {{ $labels.remote_name}}:{{ $labels.url }}"
        runbook: "https://gitlab.cee.redhat.com/service/app-interface/blob/master/docs/app-sre/sop/prometheus/prometheus-PrometheusRemoteStorageFailures.md"
      expr: |
        (
          rate(prometheus_remote_storage_failed_samples_total{job="prometheus"}[5m])
        /
          (
            rate(prometheus_remote_storage_failed_samples_total{job="prometheus"}[5m])
          +
            rate(prometheus_remote_storage_succeeded_samples_total{job="prometheus"}[5m])
          )
        )
        * 100
        > 1
      for: 15m
      labels:
        severity: high
    - alert: PrometheusRemoteWriteBehind
      annotations:
        message: "Prometheus {{$labels.instance}} remote write is {{ printf \"%.1f\" $value }}s behind for {{ $labels.remote_name}}:{{ $labels.url }}."
        runbook: "https://gitlab.cee.redhat.com/service/app-interface/blob/master/docs/app-sre/sop/prometheus/prometheus-PrometheusRemoteStorageFailures.md"
      expr: |
        # Without max_over_time, failed scrapes could create false negatives, see
        # https://www.robustperception.io/alerting-on-gauges-in-prometheus-2-0 for details.
        (
          max_over_time(prometheus_remote_storage_highest_timestamp_in_seconds{job="prometheus"}[5m])
        - on(job, instance) group_right
          max_over_time(prometheus_remote_storage_queue_highest_sent_timestamp_seconds{job="prometheus"}[5m])
        )
        > 120
      for: 15m
      labels:
        severity: high

  - name: prometheus-operator
    rules:
    - alert: PrometheusOperatorReconcileErrors
      annotations:
        message: Errors while reconciling {{ $labels.controller }} in {{ $labels.namespace
          }} Namespace.
        runbook: "https://gitlab.cee.redhat.com/service/app-interface/blob/master/docs/app-sre/sop/prometheus/prometheus-operator-PrometheusOperatorReconcileErrors.md"
      expr: |
        rate(prometheus_operator_reconcile_errors_total[5m]) > 0.1
      for: 10m
      labels:
        severity: medium
    - alert: PrometheusOperatorNodeLookupErrors
      annotations:
        message: Errors while reconciling Prometheus in {{ $labels.namespace }} Namespace.
        runbook: "https://gitlab.cee.redhat.com/service/app-interface/blob/master/docs/app-sre/sop/prometheus/prometheus-operator-PrometheusOperatorNodeLookupErrors.md"
      expr: |
        rate(prometheus_operator_node_address_lookup_errors_total[5m]) > 0.1
      for: 10m
      labels:
        severity: high
