---
$schema: /openshift/prometheus-rule-1.yml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  labels:
    prometheus: app-sre
    role: alert-rules
  name: uhc-clusters-service-stage
spec:
  groups:
  - name: uhc-clusters-service-stage
    rules:
    - alert: UHC clusters service DOWN - stage
      annotations:
        message: "No targets found for UHC clusters service in namespace {{ $labels.namespace }}. clusters service is down."
        runbook: "https://gitlab.cee.redhat.com/service/app-interface/tree/master/docs/uhc/sop"
      expr: |
        absent(up{job="clusters-service-metrics",namespace="uhc-stage"} == 1)
      for: 5m
      labels:
        service: uhc-clusters-service
        severity: high
        email: service-development-a
    - alert: UHC clusters service 5xx Errors High - stage
      annotations:
        message: "UHC clusters service is returning errors for {{ $value | humanize }}% of requests."
        runbook: "https://gitlab.cee.redhat.com/service/app-interface/tree/master/docs/uhc/sop"
      expr: |
        sum(rate(haproxy_backend_http_responses_total{route="clusters-mgmt",exported_namespace="uhc-stage",code="5xx"}[5m]))
        /
        sum(rate(haproxy_backend_http_responses_total{route="clusters-mgmt",exported_namespace="uhc-stage"}[5m])) * 100 > 5
      for: 10m
      labels:
        service: uhc-clusters-service
        severity: medium
        email: service-development-a
    - alert: UHC clusters service Latency High - stage
      annotations:
        message: "UHC clusters service 50th percentile latency is greater than 2s. Current value: {{ $value | humanize }}"
        runbook: "https://gitlab.cee.redhat.com/service/app-interface/tree/master/docs/uhc/sop"
      expr: |
        histogram_quantile(0.50, sum(rate(api_inbound_request_duration_bucket{namespace="uhc-stage",service="clusters-service-metrics"}[1m])) by (le)) > 2
      for: 10m
      labels:
        service: uhc-clusters-service
        severity: medium

    - alert: OCM clusters service controller manager down - stage
      annotations:
        message: OCM clusters service controller manager '{{ $labels.name }}' is down.
        runbook: https://gitlab.cee.redhat.com/service/app-interface/tree/master/docs/uhc/sop
      expr: controller_manager_up{job="clusters-service-metrics", namespace="uhc-stage"} == 0
      for: 5m
      labels:
        service: uhc-clusters-service
        severity: high
        email: service-development-a

    - alert: OCM cluster installation failed - stage
      annotations:
        message: OCM clusters service cluster installation failed in '{{ $labels.namespace }}'.
        runbook: https://gitlab.cee.redhat.com/service/app-interface/tree/master/docs/uhc/sop
      expr: increase(cluster_installation_error{job="clusters-service-metrics", namespace="uhc-stage"}[5m]) > 0
      for: 5m
      labels:
        service: uhc-clusters-service
        severity: medium
        email: service-development-a

    - alert: OCM telemetry worker failed - stage
      annotations:
        message: "OCM telemetry worker got {{ $value }} errors in '{{ $labels.namespace }}'."
        runbook: https://gitlab.cee.redhat.com/service/app-interface/tree/master/docs/uhc/sop
      # Alert when at least 2 executions of the worker out of 3-4 had errors. (default TELEMETER_WORKER_PERIOD=8m between runs)
      expr: increase(telemetry_worker_metrics_error_total{job="clusters-service-metrics", namespace="uhc-production"}[25m]) > 0
      for: 30m
      labels:
        service: uhc-clusters-service
        severity: medium
        email: service-development-a

    - alert: OCMClustersMgmtRateLimits - stage
      annotations:
        message: OCM stage clusters management service is rejecting requests due to exceeded rate limits
        runbook: https://gitlab.cee.redhat.com/service/app-interface/tree/master/docs/uhc/sop
      expr: sum(increase(limited_calls{namespace="app-sre-rate-limiting",service="limitador",limitador_namespace="stage:clusters_mgmt"}[5m])) > 0
      labels:
        service: uhc-clusters-service
        severity: info
        email: service-development-a
