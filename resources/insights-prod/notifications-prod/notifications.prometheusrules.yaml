---
$schema: /openshift/prometheus-rule-1.yml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: notifications-prod
  labels:
    prometheus: app-sre
    role: alert-rules
spec:
  groups:
  - name: notifications-prod
    rules:
      - alert: NotificationsBackendDownProd
        expr: absent(up{service="notifications-backend-service", namespace="notifications-prod"}) or up{service="notifications-backend-service", namespace="notifications-prod"} == 0
        for: 5m
        labels:
          severity: medium
          service: insights
          env: prod
          app_team: notifications
        annotations:
          dashboard: "https://grafana.app-sre.devshift.net/d/KQIVyFuMk/notifications-dashboard?orgId=1&refresh=15m&var-datasource=crcp01ue1-prometheus"
          link_url: "https://console-openshift-console.apps.crcp01ue1.o9m8.p1.openshiftapps.com/k8s/ns/notifications-prod/deployments"
          message: "Notifications Backend Alert (Prod)"
          description: "Notifications Backend: Down in Prod for 5 minutes."
          runbook: "https://core-platform-apps.pages.redhat.com/notifications-docs/dev/SOPs/alerts/NotificationsBackendDownProd.html"
      - alert: notifications-connector-google-chat-down-prod
        expr: absent(up{service="notifications-connector-google-chat-service", namespace="notifications-prod"}) or up{service="notifications-connector-google-chat-service", namespace="notifications-prod"} == 0
        for: 5m
        labels:
          severity: medium
          service: insights
          env: prod
          app_team: notifications
        annotations:
          dashboard: "https://grafana.app-sre.devshift.net/d/KQIVyFuMk/notifications-dashboard?orgId=1&refresh=15m&var-datasource=crcp01ue1-prometheus"
          link_url: "https://console-openshift-console.apps.crcp01ue1.o9m8.p1.openshiftapps.com/k8s/ns/notifications-prod/deployments"
          message: "Pod down for 5 minutes [env=prod, service=notifications-connector-google-chat-service]"
          runbook: "https://core-platform-apps.pages.redhat.com/notifications-docs/dev/SOPs/alerts/notifications-connector-google-chat-down-prod.html"
      - alert: notifications-connector-microsoft-teams-down-prod
        expr: absent(up{service="notifications-connector-microsoft-teams-service", namespace="notifications-prod"}) or up{service="notifications-connector-microsoft-teams-service", namespace="notifications-prod"} == 0
        for: 5m
        labels:
          severity: medium
          service: insights
          env: prod
          app_team: notifications
        annotations:
          dashboard: "https://grafana.app-sre.devshift.net/d/KQIVyFuMk/notifications-dashboard?orgId=1&refresh=15m&var-datasource=crcp01ue1-prometheus"
          link_url: "https://console-openshift-console.apps.crcp01ue1.o9m8.p1.openshiftapps.com/k8s/ns/notifications-prod/deployments"
          message: "Pod down for 5 minutes [env=prod, service=notifications-connector-microsoft-teams-service]"
          runbook: "https://core-platform-apps.pages.redhat.com/notifications-docs/dev/SOPs/alerts/notifications-connector-microsoft-teams-down-prod.html"
      - alert: notifications-connector-slack-down-prod
        expr: absent(up{service="notifications-connector-slack-service", namespace="notifications-prod"}) or up{service="notifications-connector-slack-service", namespace="notifications-prod"} == 0
        for: 5m
        labels:
          severity: medium
          service: insights
          env: prod
          app_team: notifications
        annotations:
          dashboard: "https://grafana.app-sre.devshift.net/d/KQIVyFuMk/notifications-dashboard?orgId=1&refresh=15m&var-datasource=crcp01ue1-prometheus"
          link_url: "https://console-openshift-console.apps.crcp01ue1.o9m8.p1.openshiftapps.com/k8s/ns/notifications-prod/deployments"
          message: "Pod down for 5 minutes [env=prod, service=notifications-connector-slack-service]"
          runbook: "https://core-platform-apps.pages.redhat.com/notifications-docs/dev/SOPs/alerts/notifications-connector-slack-down-prod.html"
      - alert: notifications-connector-splunk-down-prod
        expr: absent(up{service="notifications-connector-splunk-service", namespace="notifications-prod"}) or up{service="notifications-connector-splunk-service", namespace="notifications-prod"} == 0
        for: 5m
        labels:
          severity: medium
          service: insights
          env: prod
          app_team: notifications
        annotations:
          dashboard: "https://grafana.app-sre.devshift.net/d/KQIVyFuMk/notifications-dashboard?orgId=1&refresh=15m&var-datasource=crcp01ue1-prometheus"
          link_url: "https://console-openshift-console.apps.crcp01ue1.o9m8.p1.openshiftapps.com/k8s/ns/notifications-prod/deployments"
          message: "Pod down for 5 minutes [env=prod, service=notifications-connector-splunk-service]"
          runbook: "https://core-platform-apps.pages.redhat.com/notifications-docs/dev/SOPs/alerts/notifications-connector-splunk-down-prod.html"
      - alert: NotificationsEngineDownProd
        expr: absent(up{service="notifications-engine-service", namespace="notifications-prod"}) or up{service="notifications-engine-service", namespace="notifications-prod"} == 0
        for: 5m
        labels:
          severity: medium
          service: insights
          env: prod
          app_team: notifications
        annotations:
          dashboard: "https://grafana.app-sre.devshift.net/d/KQIVyFuMk/notifications-dashboard?orgId=1&refresh=15m&var-datasource=crcp01ue1-prometheus"
          link_url: "https://console-openshift-console.apps.crcp01ue1.o9m8.p1.openshiftapps.com/k8s/ns/notifications-prod/deployments"
          message: "Notifications Engine Alert (Prod)"
          description: "Notifications Engine: Down in Prod for 5 minutes."
          runbook: "https://core-platform-apps.pages.redhat.com/notifications-docs/dev/SOPs/alerts/NotificationsEngineDownProd.html"
      - alert: NotificationsGWDownProd
        expr: absent(up{service="notifications-gw-service", namespace="notifications-prod"}) or up{service="notifications-gw-service", namespace="notifications-prod"} == 0
        for: 5m
        labels:
          severity: medium
          service: insights
          env: prod
          app_team: notifications
        annotations:
          dashboard: "https://grafana.app-sre.devshift.net/d/KQIVyFuMk/notifications-dashboard?orgId=1&refresh=15m&var-datasource=crcp01ue1-prometheus"
          link_url: "https://console-openshift-console.apps.crcp01ue1.o9m8.p1.openshiftapps.com/k8s/ns/notifications-prod/deployments"
          message: "Notifications GW Alert (Prod)"
          description: "Notifications GW: Down in Prod for 5 minutes."
          runbook: "https://core-platform-apps.pages.redhat.com/notifications-docs/dev/SOPs/alerts/NotificationsGWDownProd.html"
      - alert: NotificationsRestartsProd
        expr: sum(increase(kube_pod_container_status_restarts_total{namespace="notifications-prod"}[20m])) > 5
        labels:
          severity: medium
          service: insights
          env: prod
          app_team: notifications
        annotations:
          dashboard: "https://grafana.app-sre.devshift.net/d/KQIVyFuMk/notifications-dashboard?orgId=1&refresh=15m&var-datasource=crcp01ue1-prometheus"
          link_url: "https://console-openshift-console.apps.crcp01ue1.o9m8.p1.openshiftapps.com/k8s/ns/notifications-prod/deployments"
          message: "Notifications: Pod restarts occurring more than 5x in the past 20min in prod environment."
          runbook: "https://core-platform-apps.pages.redhat.com/notifications-docs/dev/SOPs/alerts/NotificationsRestartsProd.html"
      - alert: NoMessageBeingProcessedProd
        expr: sum(rate(input_consumed_seconds_count{service="notifications-backend-service"}[5m])) == 0
        for: 5m
        labels:
          severity: medium
          service: insights
          env: prod
          app_team: notifications
        annotations:
          dashboard: "https://grafana.app-sre.devshift.net/d/KQIVyFuMk/notifications-dashboard?orgId=1&viewPanel=172&refresh=15m&var-datasource=crcp01ue1-prometheus"
          link_url: "https://console-openshift-console.apps.crcp01ue1.o9m8.p1.openshiftapps.com/k8s/ns/notifications-prod/deployments"
          message: "Notifications: Stopped processing messages from Kafka"
          runbook: "https://core-platform-apps.pages.redhat.com/notifications-docs/dev/SOPs/alerts/NoMessageBeingProcessedProd.html"
      - alert: notifications-connector-google-chat-kafka-lag-prod
        expr: sum(kafka_consumergroup_group_lag{topic=~".*platform.notifications.tocamel", group="notifications-connector-google-chat"}) > 1000
        labels:
          severity: medium
          service: insights
          env: prod
          app_team: notifications
        annotations:
          dashboard: "https://grafana.app-sre.devshift.net/d/KQIVyFuMk/notifications-dashboard?orgId=1&refresh=15m&var-datasource=crcp01ue1-prometheus"
          link_url: "https://console-openshift-console.apps.crcp01ue1.o9m8.p1.openshiftapps.com/k8s/ns/notifications-prod/deployments"
          message: "Kafka lag detected [env=prod, topic=platform.notifications.tocamel, group=notifications-connector-google-chat]"
          runbook: "https://core-platform-apps.pages.redhat.com/notifications-docs/dev/SOPs/alerts/notifications-connector-google-chat-kafka-lag-prod.html"
      - alert: notifications-connector-microsoft-teams-kafka-lag-prod
        expr: sum(kafka_consumergroup_group_lag{topic=~".*platform.notifications.tocamel", group="notifications-connector-microsoft-teams"}) > 1000
        labels:
          severity: medium
          service: insights
          env: prod
          app_team: notifications
        annotations:
          dashboard: "https://grafana.app-sre.devshift.net/d/KQIVyFuMk/notifications-dashboard?orgId=1&refresh=15m&var-datasource=crcp01ue1-prometheus"
          link_url: "https://console-openshift-console.apps.crcp01ue1.o9m8.p1.openshiftapps.com/k8s/ns/notifications-prod/deployments"
          message: "Kafka lag detected [env=prod, topic=platform.notifications.tocamel, group=notifications-connector-microsoft-teams]"
          runbook: "https://core-platform-apps.pages.redhat.com/notifications-docs/dev/SOPs/alerts/notifications-connector-microsoft-teams-kafka-lag-prod.html"
      - alert: notifications-connector-slack-kafka-lag-prod
        expr: sum(kafka_consumergroup_group_lag{topic=~".*platform.notifications.tocamel", group="notifications-connector-slack"}) > 1000
        labels:
          severity: medium
          service: insights
          env: prod
          app_team: notifications
        annotations:
          dashboard: "https://grafana.app-sre.devshift.net/d/KQIVyFuMk/notifications-dashboard?orgId=1&refresh=15m&var-datasource=crcp01ue1-prometheus"
          link_url: "https://console-openshift-console.apps.crcp01ue1.o9m8.p1.openshiftapps.com/k8s/ns/notifications-prod/deployments"
          message: "Kafka lag detected [env=prod, topic=platform.notifications.tocamel, group=notifications-connector-slack]"
          runbook: "https://core-platform-apps.pages.redhat.com/notifications-docs/dev/SOPs/alerts/notifications-connector-slack-kafka-lag-prod.html"
      - alert: notifications-connector-splunk-kafka-lag-prod
        expr: sum(kafka_consumergroup_group_lag{topic=~".*platform.notifications.tocamel", group="notifications-connector-splunk"}) > 1000
        labels:
          severity: medium
          service: insights
          env: prod
          app_team: notifications
        annotations:
          dashboard: "https://grafana.app-sre.devshift.net/d/KQIVyFuMk/notifications-dashboard?orgId=1&refresh=15m&var-datasource=crcp01ue1-prometheus"
          link_url: "https://console-openshift-console.apps.crcp01ue1.o9m8.p1.openshiftapps.com/k8s/ns/notifications-prod/deployments"
          message: "Kafka lag detected [env=prod, topic=platform.notifications.tocamel, group=notifications-connector-splunk]"
          runbook: "https://core-platform-apps.pages.redhat.com/notifications-docs/dev/SOPs/alerts/notifications-connector-splunk-kafka-lag-prod.html"
      - alert: NotificationsEngineIngressTopicKafkaLagProd
        expr: sum(kafka_consumergroup_group_lag{topic="platform.notifications.ingress", group="integrations"}) > 1000
        labels:
          severity: medium
          service: insights
          env: prod
          app_team: notifications
        annotations:
          dashboard: "https://grafana.app-sre.devshift.net/d/KQIVyFuMk/notifications-dashboard?orgId=1&refresh=15m&var-datasource=crcp01ue1-prometheus"
          link_url: "https://console-openshift-console.apps.crcp01ue1.o9m8.p1.openshiftapps.com/k8s/ns/notifications-prod/deployments"
          message: "Notifications: Kafka lag of platform.notifications.ingress topic exceeded alert threshold in prod environment."
          runbook: "https://core-platform-apps.pages.redhat.com/notifications-docs/dev/SOPs/alerts/NotificationsEngineIngressTopicKafkaLagProd.html"
      ##################################
      # Alerts about external services #
      ##################################
      - alert: ITServiceFailuresThreshold
        expr: sum(rate(it_failures_total{namespace="notifications-prod"}[5m])) > 0.5
        for: 5m
        labels:
          severity: medium
          service: insights
          env: prod
          app_team: notifications
        annotations:
          message: "Requests to IT have been failing in production for 5 minutes."
      - alert: RbacIsDown
        expr: absent(up{service="rbac-service", namespace="rbac-prod"}) or up{service="rbac-service", namespace="rbac-prod"} == 0
        for: 5m
        labels:
          severity: medium
          service: insights
          env: prod
          app_team: notifications
        annotations:
          message: "RBAC service: down in production for 5 minutes."
      - alert: RBACServiceFailuresThreshold
        expr: sum(rate(rbac_failures_total{namespace="notifications-prod"}[5m])) > 0.5
        for: 5m
        labels:
          severity: medium
          service: insights
          env: prod
          app_team: notifications
        annotations:
          message: "RBAC requests have been failing in production for 5 minutes."
      - alert: SourcesIsDown
        expr: absent(up{service="sources-api-svc", namespace="sources-prod"}) or up{service="sources-api-svc", namespace="sources-prod"} == 0
        for: 5m
        labels:
          severity: medium
          service: insights
          env: prod
          app_team: notifications
        annotations:
          message: "Sources service: down in production for 5 minutes."
